{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e777680c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:49.967212Z",
     "iopub.status.busy": "2024-08-05T16:36:49.966825Z",
     "iopub.status.idle": "2024-08-05T16:36:50.858078Z",
     "shell.execute_reply": "2024-08-05T16:36:50.857048Z"
    },
    "papermill": {
     "duration": 0.900502,
     "end_time": "2024-08-05T16:36:50.860624",
     "exception": false,
     "start_time": "2024-08-05T16:36:49.960122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2024/sample_submission.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5b34159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:50.872196Z",
     "iopub.status.busy": "2024-08-05T16:36:50.871704Z",
     "iopub.status.idle": "2024-08-05T16:36:51.164003Z",
     "shell.execute_reply": "2024-08-05T16:36:51.162578Z"
    },
    "papermill": {
     "duration": 0.300749,
     "end_time": "2024-08-05T16:36:51.166459",
     "exception": false,
     "start_time": "2024-08-05T16:36:50.865710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "#load the data\n",
    "training_solutions = load_json('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json')\n",
    "evaluation_solutions = load_json('/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json')\n",
    "training_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json')\n",
    "evaluation_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json')\n",
    "test_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005f3379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:51.177876Z",
     "iopub.status.busy": "2024-08-05T16:36:51.177510Z",
     "iopub.status.idle": "2024-08-05T16:36:51.185455Z",
     "shell.execute_reply": "2024-08-05T16:36:51.184317Z"
    },
    "papermill": {
     "duration": 0.016784,
     "end_time": "2024-08-05T16:36:51.188208",
     "exception": false,
     "start_time": "2024-08-05T16:36:51.171424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Solutions:\n",
      "Key: 007bbfb7\n",
      "Sample Data: [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
      "\n",
      "Training Challenges:\n",
      "Key: 007bbfb7\n",
      "Sample Data: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "Evaluation Solutions:\n",
      "Key: 00576224\n",
      "Sample Data: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "\n",
      "Evaluation Challenges:\n",
      "Key: 00576224\n",
      "Sample Data: {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
      "\n",
      "Test Challenges:\n",
      "Key: 007bbfb7\n",
      "Sample Data: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect_data(data, num_samples=1):\n",
    "    for key, value in list(data.items())[:num_samples]:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"Sample Data: {value}\\n\")\n",
    "        \n",
    "print(\"Training Solutions:\")\n",
    "inspect_data(training_solutions)\n",
    "\n",
    "print(\"Training Challenges:\")\n",
    "inspect_data(training_challenges)\n",
    "\n",
    "print(\"Evaluation Solutions:\")\n",
    "inspect_data(evaluation_solutions)\n",
    "\n",
    "print(\"Evaluation Challenges:\")\n",
    "inspect_data(evaluation_challenges)\n",
    "\n",
    "print(\"Test Challenges:\")\n",
    "inspect_data(test_challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990410be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:51.200321Z",
     "iopub.status.busy": "2024-08-05T16:36:51.199527Z",
     "iopub.status.idle": "2024-08-05T16:36:51.369784Z",
     "shell.execute_reply": "2024-08-05T16:36:51.368457Z"
    },
    "papermill": {
     "duration": 0.178869,
     "end_time": "2024-08-05T16:36:51.372218",
     "exception": false,
     "start_time": "2024-08-05T16:36:51.193349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum height: 30\n",
      "Maximum width: 30\n",
      "X_train shape: (1302, 30, 30)\n",
      "y_train shape: (1302, 30, 30)\n",
      "Loaded X_train shape: (1302, 30, 30)\n",
      "Loaded y_train shape: (1302, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "#load training data\n",
    "with open('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json') as f:\n",
    "    training_challenges = json.load(f)\n",
    "with open('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json') as f:\n",
    "    training_solutions = json.load(f)\n",
    "\n",
    "def prepare_training_data_padded(challenges, solutions):\n",
    "    #calculate the maximum height and width for padding\n",
    "    max_height = max(\n",
    "        max(len(example['input']) for example in challenge['train'])\n",
    "        for challenge in challenges.values()\n",
    "    )\n",
    "    max_width = max(\n",
    "        max(len(row) for example in challenge['train'] for row in example['input'])\n",
    "        for challenge in challenges.values()\n",
    "    )\n",
    "    \n",
    "    print(f\"Maximum height: {max_height}\")\n",
    "    print(f\"Maximum width: {max_width}\")\n",
    "    \n",
    "    def pad_grid(grid, target_height, target_width):\n",
    "        padded_grid = np.zeros((target_height, target_width), dtype=int)\n",
    "        for i, row in enumerate(grid):\n",
    "            padded_grid[i, :len(row)] = row\n",
    "        return padded_grid\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for key in challenges.keys():\n",
    "        challenge = challenges[key]\n",
    "        solution = solutions[key]\n",
    "        \n",
    "        #add training data\n",
    "        for example in challenge['train']:\n",
    "            input_grid = example['input']\n",
    "            output_grid = example['output']\n",
    "            padded_input = pad_grid(input_grid, max_height, max_width)\n",
    "            padded_output = pad_grid(output_grid, max_height, max_width)\n",
    "            X_train.append(padded_input)\n",
    "            y_train.append(padded_output)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    \n",
    "    #save the arrays\n",
    "    np.save('X_train.npy', X_train)\n",
    "    np.save('y_train.npy', y_train)\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = prepare_training_data_padded(training_challenges, training_solutions)\n",
    "\n",
    "X_train_loaded = np.load('X_train.npy')\n",
    "y_train_loaded = np.load('y_train.npy')\n",
    "\n",
    "print(f\"Loaded X_train shape: {X_train_loaded.shape}\")\n",
    "print(f\"Loaded y_train shape: {y_train_loaded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "333869f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:51.384497Z",
     "iopub.status.busy": "2024-08-05T16:36:51.383722Z",
     "iopub.status.idle": "2024-08-05T16:36:54.870004Z",
     "shell.execute_reply": "2024-08-05T16:36:54.868770Z"
    },
    "papermill": {
     "duration": 3.495278,
     "end_time": "2024-08-05T16:36:54.872534",
     "exception": false,
     "start_time": "2024-08-05T16:36:51.377256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_loaded, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_loaded, dtype=torch.float32)\n",
    "\n",
    "#create a TensorDataset and DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77cd00be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:54.885349Z",
     "iopub.status.busy": "2024-08-05T16:36:54.884738Z",
     "iopub.status.idle": "2024-08-05T16:36:54.898439Z",
     "shell.execute_reply": "2024-08-05T16:36:54.897352Z"
    },
    "papermill": {
     "duration": 0.023019,
     "end_time": "2024-08-05T16:36:54.901054",
     "exception": false,
     "start_time": "2024-08-05T16:36:54.878035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Grid:\n",
      "[[4 0 5 2 6 1 0 3 2 6 5 1 2 3 5 5 4 2 8 5 6 0 1 4 5 8 8 1 2 0]\n",
      " [9 2 6 3 6 2 4 3 5 4 2 2 5 3 5 3 5 3 6 4 6 3 5 5 4 6 3 3 3 4]\n",
      " [9 6 5 5 5 5 3 7 4 3 5 5 2 4 2 4 3 5 5 5 5 6 3 4 6 2 4 3 4 5]\n",
      " [1 3 4 7 6 4 5 3 5 6 2 3 4 2 2 0 4 6 3 7 5 2 3 3 3 2 3 4 5 8]\n",
      " [0 2 6 5 5 5 4 3 5 2 6 3 3 2 1 3 3 2 6 4 4 3 1 2 3 3 3 4 4 6]\n",
      " [3 5 3 5 4 4 4 6 1 5 3 5 4 3 3 2 2 5 2 4 3 3 2 4 4 5 3 5 5 3]\n",
      " [9 3 5 3 2 5 4 3 6 3 3 5 3 4 3 3 5 2 5 3 4 2 4 3 5 5 5 3 3 3]\n",
      " [3 4 1 2 3 0 6 5 3 4 2 4 4 4 4 5 4 7 4 3 4 3 3 3 6 3 4 3 4 4]\n",
      " [1 3 5 1 2 5 2 5 4 1 5 2 6 4 4 4 5 5 6 5 2 4 5 5 4 7 3 3 3 6]\n",
      " [8 7 3 5 4 3 6 4 3 3 1 4 2 5 4 3 4 5 5 4 5 4 6 7 7 4 4 2 5 7]\n",
      " [3 4 6 3 3 5 4 3 4 2 1 2 5 3 5 6 3 7 6 5 3 6 3 8 5 6 4 3 3 0]\n",
      " [2 5 2 6 4 3 4 4 2 2 3 3 4 7 5 4 6 3 6 4 3 1 7 4 6 4 5 6 5 9]\n",
      " [5 3 7 4 6 4 4 2 3 3 3 4 6 5 6 5 3 4 4 4 3 3 3 6 5 4 4 4 6 3]\n",
      " [6 4 5 6 3 5 3 5 3 3 4 5 7 6 6 6 3 4 5 4 1 2 3 5 2 3 4 5 5 7]\n",
      " [0 5 4 4 2 2 4 2 4 3 4 5 3 6 7 7 4 5 3 5 4 1 3 4 5 4 2 4 7 9]\n",
      " [4 4 6 2 2 3 4 3 3 3 2 4 4 5 6 6 6 3 7 4 5 4 4 4 4 3 5 4 4 3]\n",
      " [4 5 5 3 2 3 4 4 2 1 4 2 4 3 7 6 5 7 5 5 4 6 5 4 3 3 3 3 4 4]\n",
      " [1 4 4 4 2 5 4 3 1 3 1 4 3 4 3 7 5 6 5 4 4 4 6 5 2 5 2 4 3 3]\n",
      " [9 6 6 3 3 4 4 3 4 2 4 4 4 4 5 3 5 6 4 4 3 4 5 6 4 1 6 4 4 4]\n",
      " [5 5 6 5 2 3 6 3 5 5 4 4 5 3 4 4 6 3 6 2 3 4 5 5 3 6 4 3 4 1]\n",
      " [1 5 5 4 3 5 4 5 6 4 5 2 4 2 2 5 4 5 2 4 3 3 3 5 5 4 3 4 1 3]\n",
      " [3 4 6 3 4 4 6 6 2 5 3 6 1 3 2 2 5 5 3 2 2 2 5 3 5 5 5 2 3 5]\n",
      " [1 4 4 5 4 6 5 2 5 3 4 4 4 2 3 3 3 2 3 3 2 1 1 4 5 5 6 3 5 7]\n",
      " [7 4 6 5 4 4 5 4 1 4 5 3 4 5 3 1 2 4 5 2 2 1 3 3 5 4 4 7 2 4]\n",
      " [1 4 4 5 6 4 5 3 6 3 5 5 4 3 5 6 2 3 4 5 2 3 3 6 2 7 5 4 5 8]\n",
      " [1 4 4 5 2 6 3 5 4 7 4 4 3 6 5 3 4 4 5 4 5 5 7 3 7 3 8 5 6 7]\n",
      " [4 5 3 2 3 1 4 4 5 4 4 4 2 2 4 6 2 6 3 6 5 6 6 7 4 7 6 8 4 6]\n",
      " [9 4 4 1 3 3 3 4 7 5 5 1 3 2 5 3 5 2 4 4 4 5 5 5 5 6 6 4 8 9]\n",
      " [1 3 3 6 3 5 4 5 7 7 4 4 2 4 3 6 4 4 2 1 2 2 4 3 5 3 5 6 3 2]\n",
      " [9 2 8 9 3 4 7 1 6 5 6 2 6 5 7 8 5 8 1 3 0 2 3 1 1 3 6 6 6 4]]\n"
     ]
    }
   ],
   "source": [
    "class CellularAutomataLayer:\n",
    "    \"\"\"\n",
    "    Cellular Automata inspired layer that processes input grids using local interaction rules.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, grid_size):\n",
    "        \"\"\"\n",
    "        Initializes the CellularAutomataLayer.\n",
    "\n",
    "        Parameters:\n",
    "        - grid_size (int): The size of the grid.\n",
    "        \"\"\"\n",
    "        self.grid_size = grid_size\n",
    "\n",
    "    def step(self, grid):\n",
    "        \"\"\"\n",
    "        Applies the cellular automata rules to the grid for one time step.\n",
    "\n",
    "        Parameters:\n",
    "        - grid (np.ndarray): The input grid to process.\n",
    "\n",
    "        Returns:\n",
    "        - new_grid (np.ndarray): The grid after applying the cellular automata rules.\n",
    "        \"\"\"\n",
    "        new_grid = np.copy(grid)\n",
    "        for i in range(1, self.grid_size-1):\n",
    "            for j in range(1, self.grid_size-1):\n",
    "                #example rule: average of neighbors\n",
    "                new_grid[i, j] = (grid[i-1, j] + grid[i+1, j] + grid[i, j-1] + grid[i, j+1]) / 4\n",
    "        return new_grid\n",
    "\n",
    "#test Cellular Automata Layer\n",
    "if __name__ == \"__main__\":\n",
    "    #initialize CellularAutomataLayer with a grid size of 30\n",
    "    ca_layer = CellularAutomataLayer(grid_size=30)\n",
    "    \n",
    "    #create a random test grid with values between 0 and 10\n",
    "    test_grid = np.random.randint(0, 10, (30, 30))\n",
    "    \n",
    "    #process the grid using the CellularAutomataLayer\n",
    "    processed_grid = ca_layer.step(test_grid)\n",
    "    \n",
    "    #print the processed grid\n",
    "    print(\"Processed Grid:\")\n",
    "    print(processed_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b4885f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:54.913760Z",
     "iopub.status.busy": "2024-08-05T16:36:54.913325Z",
     "iopub.status.idle": "2024-08-05T16:36:55.886767Z",
     "shell.execute_reply": "2024-08-05T16:36:55.885551Z"
    },
    "papermill": {
     "duration": 0.982752,
     "end_time": "2024-08-05T16:36:55.889286",
     "exception": false,
     "start_time": "2024-08-05T16:36:54.906534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed node (0, 0) value: 2.5\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "class GraphBasedRepresentation:\n",
    "    \"\"\"\n",
    "    Converts the grid into a graph representation and processes it using graph-based techniques.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the GraphBasedRepresentation.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def grid_to_graph(self, grid):\n",
    "        \"\"\"\n",
    "        Converts the input grid to a graph.\n",
    "\n",
    "        Parameters:\n",
    "        - grid (np.ndarray): The input grid to convert.\n",
    "\n",
    "        Returns:\n",
    "        - G (nx.Graph): The graph representation of the grid.\n",
    "        \"\"\"\n",
    "        G = nx.grid_2d_graph(len(grid), len(grid[0]))\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                G.nodes[(i, j)]['value'] = grid[i][j]\n",
    "        return G\n",
    "\n",
    "    def process_graph(self, graph):\n",
    "        \"\"\"\n",
    "        Example processing: average the values of each node's neighbors.\n",
    "\n",
    "        Parameters:\n",
    "        - graph (nx.Graph): The graph to process.\n",
    "\n",
    "        Returns:\n",
    "        - new_graph (nx.Graph): The graph with updated node values.\n",
    "        \"\"\"\n",
    "        new_graph = graph.copy()\n",
    "        for node in graph.nodes:\n",
    "            neighbors = list(graph.neighbors(node))\n",
    "            if neighbors:\n",
    "                values = [graph.nodes[n]['value'] for n in neighbors]\n",
    "                new_graph.nodes[node]['value'] = np.mean(values)\n",
    "        return new_graph\n",
    "\n",
    "#test Graph-Based Representation\n",
    "if __name__ == \"__main__\":\n",
    "    #create a sample grid for testing\n",
    "    test_grid = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "    #initialize GraphBasedRepresentation\n",
    "    graph_repr = GraphBasedRepresentation()\n",
    "\n",
    "    #convert grid to graph\n",
    "    test_graph = graph_repr.grid_to_graph(test_grid)\n",
    "\n",
    "    #process the graph\n",
    "    processed_graph = graph_repr.process_graph(test_graph)\n",
    "\n",
    "    #print node values for the (0, 0) node\n",
    "    print(\"Processed node (0, 0) value:\", processed_graph.nodes[(0, 0)]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e35776a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:55.902082Z",
     "iopub.status.busy": "2024-08-05T16:36:55.901689Z",
     "iopub.status.idle": "2024-08-05T16:36:55.911914Z",
     "shell.execute_reply": "2024-08-05T16:36:55.910635Z"
    },
    "papermill": {
     "duration": 0.019361,
     "end_time": "2024-08-05T16:36:55.914400",
     "exception": false,
     "start_time": "2024-08-05T16:36:55.895039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Grid:\n",
      "[[5 5]\n",
      " [5 5]]\n"
     ]
    }
   ],
   "source": [
    "class SymbolicRuleInduction:\n",
    "    \"\"\"\n",
    "    Extracts symbolic rules from input-output pairs and applies them to new inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the SymbolicRuleInduction with an empty rule set.\"\"\"\n",
    "        self.rules = []\n",
    "\n",
    "    def extract_rules(self, input_grid, output_grid):\n",
    "        \"\"\"\n",
    "        Extracts rules based on input and output grids.\n",
    "        \n",
    "        Parameters:\n",
    "        - input_grid (np.ndarray): The input grid used to extract rules.\n",
    "        - output_grid (np.ndarray): The output grid corresponding to the input grid.\n",
    "        \"\"\"\n",
    "        #for simplicity, we use sum of grid values as the rule.\n",
    "        rule = {\"input_sum\": np.sum(input_grid), \"output_sum\": np.sum(output_grid)}\n",
    "        self.rules.append(rule)\n",
    "\n",
    "    def apply_rules(self, input_grid):\n",
    "        \"\"\"\n",
    "        Applies extracted rules to the input grid.\n",
    "        \n",
    "        Parameters:\n",
    "        - input_grid (np.ndarray): The input grid to which the rules are applied.\n",
    "\n",
    "        Returns:\n",
    "        - np.ndarray: The transformed grid after applying the rules.\n",
    "        \"\"\"\n",
    "        input_sum = np.sum(input_grid)\n",
    "        for rule in self.rules:\n",
    "            if input_sum == rule['input_sum']:\n",
    "                return np.ones_like(input_grid) * (rule['output_sum'] // np.size(input_grid))\n",
    "        return input_grid\n",
    "\n",
    "#test SymbolicRuleInduction\n",
    "if __name__ == \"__main__\":\n",
    "    #create sample grids for testing\n",
    "    test_grid = np.array([[1, 2], [3, 4]])\n",
    "    processed_grid = np.array([[2, 4], [6, 8]])\n",
    "\n",
    "    #initialize SymbolicRuleInduction\n",
    "    symbolic_rule = SymbolicRuleInduction()\n",
    "\n",
    "    #extract rules based on sample grids\n",
    "    symbolic_rule.extract_rules(test_grid, processed_grid)\n",
    "\n",
    "    #apply rules to the test grid\n",
    "    transformed_grid = symbolic_rule.apply_rules(test_grid)\n",
    "\n",
    "    print(\"Transformed Grid:\")\n",
    "    print(transformed_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8455bbaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:55.927195Z",
     "iopub.status.busy": "2024-08-05T16:36:55.926496Z",
     "iopub.status.idle": "2024-08-05T16:36:55.942135Z",
     "shell.execute_reply": "2024-08-05T16:36:55.940734Z"
    },
    "papermill": {
     "duration": 0.02475,
     "end_time": "2024-08-05T16:36:55.944499",
     "exception": false,
     "start_time": "2024-08-05T16:36:55.919749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved Memories:\n",
      "{'description': 'Completed a marathon.', 'timestamp': '2024-08-05T16:36:55.936647', 'metadata': {'event': 'Marathon', 'distance': '42 km'}}\n",
      "{'description': 'Visited a historical site.', 'timestamp': '2024-08-05T16:36:55.936681', 'metadata': {'location': 'Mountain Burkhan Khaldun, Mongolia', 'type': 'Historical Monument'}}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "class EpisodicMemory:\n",
    "    \"\"\"Class for managing episodic memories with metadata and timestamps.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the episodic memory store.\"\"\"\n",
    "        self.memory_store = []\n",
    "    \n",
    "    def add_memory(self, description, timestamp=None, metadata=None):\n",
    "        \"\"\"\n",
    "        Add a memory with optional timestamp and metadata.\n",
    "\n",
    "        Parameters:\n",
    "        - description (str): Description of the memory.\n",
    "        - timestamp (str, optional): Timestamp of when the memory was created in ISO format.\n",
    "        - metadata (dict, optional): Additional metadata related to the memory.\n",
    "        \"\"\"\n",
    "        memory = {\n",
    "            \"description\": description,\n",
    "            \"timestamp\": timestamp or datetime.datetime.now().isoformat(),\n",
    "            \"metadata\": metadata or {}\n",
    "        }\n",
    "        self.memory_store.append(memory)\n",
    "    \n",
    "    def get_memories(self, start_time=None, end_time=None, keywords=None):\n",
    "        \"\"\"\n",
    "        Retrieve memories based on time range and keywords.\n",
    "\n",
    "        Parameters:\n",
    "        - start_time (datetime, optional): Start of the time range.\n",
    "        - end_time (datetime, optional): End of the time range.\n",
    "        - keywords (list of str, optional): Keywords to search for in memory descriptions.\n",
    "\n",
    "        Returns:\n",
    "        - list of dict: Matching memories.\n",
    "        \"\"\"\n",
    "        start_time = start_time or datetime.datetime.min\n",
    "        end_time = end_time or datetime.datetime.max\n",
    "        keywords = keywords or []\n",
    "        \n",
    "        def memory_matches(memory):\n",
    "            desc_match = any(keyword.lower() in memory['description'].lower() for keyword in keywords)\n",
    "            timestamp_match = start_time <= datetime.datetime.fromisoformat(memory['timestamp']) <= end_time\n",
    "            return desc_match and timestamp_match\n",
    "        \n",
    "        return [mem for mem in self.memory_store if memory_matches(mem)]\n",
    "    \n",
    "    def save_memory_store(self, filename):\n",
    "        \"\"\"Save the memory store to a file.\"\"\"\n",
    "        with open(filename, 'w') as file:\n",
    "            json.dump(self.memory_store, file, indent=4)\n",
    "    \n",
    "    def load_memory_store(self, filename):\n",
    "        \"\"\"Load the memory store from a file.\"\"\"\n",
    "        with open(filename, 'r') as file:\n",
    "            self.memory_store = json.load(file)\n",
    "\n",
    "#test EpisodicMemory Class\n",
    "memory = EpisodicMemory()\n",
    "\n",
    "#add memories with different metadata types\n",
    "memory.add_memory(\"Learned a new programming language.\", metadata={\"skill\": \"Python\", \"difficulty\": \"Medium\"})\n",
    "memory.add_memory(\"Completed a marathon.\", metadata={\"event\": \"Marathon\", \"distance\": \"42 km\"})\n",
    "memory.add_memory(\"Visited a historical site.\", metadata={\"location\": \"Mountain Burkhan Khaldun, Mongolia\", \"type\": \"Historical Monument\"})\n",
    "\n",
    "#retrieve memories\n",
    "start_time = datetime.datetime(2024, 1, 1)\n",
    "end_time = datetime.datetime(2024, 12, 31)\n",
    "keywords = [\"marathon\", \"historical\"]\n",
    "memories = memory.get_memories(start_time=start_time, end_time=end_time, keywords=keywords)\n",
    "print(\"\\nRetrieved Memories:\")\n",
    "for mem in memories:\n",
    "    print(mem)\n",
    "\n",
    "#save and load memory store\n",
    "memory.save_memory_store('memory_store.json')\n",
    "memory.load_memory_store('memory_store.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa68ca1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:55.958220Z",
     "iopub.status.busy": "2024-08-05T16:36:55.957067Z",
     "iopub.status.idle": "2024-08-05T16:36:55.967825Z",
     "shell.execute_reply": "2024-08-05T16:36:55.966831Z"
    },
    "papermill": {
     "duration": 0.020003,
     "end_time": "2024-08-05T16:36:55.970047",
     "exception": false,
     "start_time": "2024-08-05T16:36:55.950044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values:\n",
      "Respect for Others: Valuing the perspectives and dignity of individuals in all interactions.\n",
      "Community Harmony: Emphasis on maintaining cooperation and positive relationships within the community.\n",
      "Respect for Nature: A deep respect for nature and the environment, recognizing the interconnectedness of all living things.\n",
      "Hospitality: Generosity and kindness towards others, especially guests and newcomers.\n",
      "Family Bond: Strong family ties and the importance of supporting and caring for family members.\n",
      "Honor and Integrity: Maintaining personal honor and integrity, and acting with honesty and ethical principles.\n",
      "\n",
      "Integration Recommendations:\n",
      "['Emphasis on maintaining cooperation and positive relationships within the community.', 'A deep respect for nature and the environment, recognizing the interconnectedness of all living things.']\n"
     ]
    }
   ],
   "source": [
    "class Ethics:\n",
    "    \"\"\"\n",
    "    Provides a dictionary of values and methods to access and integrate these values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.values = self._initialize_values()\n",
    "\n",
    "    def _initialize_values(self):\n",
    "        \"\"\"\n",
    "        Initializes a dictionary with general values.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'Respect for Others': 'Valuing the perspectives and dignity of individuals in all interactions.',\n",
    "            'Community Harmony': 'Emphasis on maintaining cooperation and positive relationships within the community.',\n",
    "            'Respect for Nature': 'A deep respect for nature and the environment, recognizing the interconnectedness of all living things.',\n",
    "            'Hospitality': 'Generosity and kindness towards others, especially guests and newcomers.',\n",
    "            'Family Bond': 'Strong family ties and the importance of supporting and caring for family members.',\n",
    "            'Honor and Integrity': 'Maintaining personal honor and integrity, and acting with honesty and ethical principles.'\n",
    "        }\n",
    "\n",
    "    def get_values(self):\n",
    "        \"\"\"\n",
    "        Returns the dictionary of values.\n",
    "        \"\"\"\n",
    "        return self.values\n",
    "\n",
    "    def integrate_values(self, action):\n",
    "        \"\"\"\n",
    "        Provides recommendations on how to integrate values into a specific action or decision.\n",
    "        \n",
    "        :param action: The action or decision to be considered.\n",
    "        :return: Recommendations on integrating values into the action or decision.\n",
    "        \"\"\"\n",
    "        #example of integrating values into decision-making\n",
    "        recommendations = []\n",
    "        if 'community' in action.lower():\n",
    "            recommendations.append(self.values['Community Harmony'])\n",
    "        if 'nature' in action.lower():\n",
    "            recommendations.append(self.values['Respect for Nature'])\n",
    "        if 'family' in action.lower():\n",
    "            recommendations.append(self.values['Family Bond'])\n",
    "        \n",
    "        return recommendations if recommendations else \"No specific value integration available for the given action.\"\n",
    "\n",
    "#test Ethics Class\n",
    "ethics = Ethics()\n",
    "\n",
    "#get values\n",
    "values = ethics.get_values()\n",
    "print(\"Values:\")\n",
    "for key, value in values.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "#integrate values into a specific action\n",
    "action = \"Community project involving nature preservation\"\n",
    "integration_recommendations = ethics.integrate_values(action)\n",
    "print(\"\\nIntegration Recommendations:\")\n",
    "print(integration_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9455035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:55.983382Z",
     "iopub.status.busy": "2024-08-05T16:36:55.982379Z",
     "iopub.status.idle": "2024-08-05T16:36:55.994250Z",
     "shell.execute_reply": "2024-08-05T16:36:55.993153Z"
    },
    "papermill": {
     "duration": 0.020634,
     "end_time": "2024-08-05T16:36:55.996334",
     "exception": false,
     "start_time": "2024-08-05T16:36:55.975700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disability Information:\n",
      "Visual Impairment: {'Description': 'Includes blindness or low vision.', 'Assistive Technologies': ['Screen Readers: Software that reads the text on the screen aloud.', 'Braille Displays: Devices that convert screen text to Braille.', 'Magnification Software: Programs that enlarge text and images on the screen.']}\n",
      "Auditory Impairment: {'Description': 'Includes deafness or hearing loss.', 'Assistive Technologies': ['Hearing Aids: Devices that amplify sound for individuals with hearing loss.', 'Captioning: Subtitles or text displayed on screen to represent spoken content.', 'Speech-to-Text: Software that converts spoken words into text.']}\n",
      "Speech Impairment: {'Description': 'Includes conditions that affect the ability to speak clearly.', 'Assistive Technologies': ['Speech Generating Devices: Devices that help individuals generate speech through text or symbols.', 'Text-to-Speech Software: Converts written text into spoken words.', 'Alternative Communication Systems: Systems that use pictures, symbols, or electronic devices for communication.']}\n",
      "\n",
      "Assistive Technologies for Visual Impairment:\n",
      "['Screen Readers: Software that reads the text on the screen aloud.', 'Braille Displays: Devices that convert screen text to Braille.', 'Magnification Software: Programs that enlarge text and images on the screen.']\n",
      "\n",
      "Assistive Technologies for Auditory Impairment:\n",
      "['Hearing Aids: Devices that amplify sound for individuals with hearing loss.', 'Captioning: Subtitles or text displayed on screen to represent spoken content.', 'Speech-to-Text: Software that converts spoken words into text.']\n",
      "\n",
      "Assistive Technologies for Speech Impairment:\n",
      "['Speech Generating Devices: Devices that help individuals generate speech through text or symbols.', 'Text-to-Speech Software: Converts written text into spoken words.', 'Alternative Communication Systems: Systems that use pictures, symbols, or electronic devices for communication.']\n"
     ]
    }
   ],
   "source": [
    "class Disabilities:\n",
    "    \"\"\"\n",
    "    Provides support and information for individuals with disabilities such as visual, auditory, and speech impairments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.disability_info = self._initialize_disabilities()\n",
    "\n",
    "    def _initialize_disabilities(self):\n",
    "        \"\"\"\n",
    "        Initializes a dictionary with information about various disabilities and possible assistive technologies.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'Visual Impairment': {\n",
    "                'Description': 'Includes blindness or low vision.',\n",
    "                'Assistive Technologies': [\n",
    "                    'Screen Readers: Software that reads the text on the screen aloud.',\n",
    "                    'Braille Displays: Devices that convert screen text to Braille.',\n",
    "                    'Magnification Software: Programs that enlarge text and images on the screen.'\n",
    "                ]\n",
    "            },\n",
    "            'Auditory Impairment': {\n",
    "                'Description': 'Includes deafness or hearing loss.',\n",
    "                'Assistive Technologies': [\n",
    "                    'Hearing Aids: Devices that amplify sound for individuals with hearing loss.',\n",
    "                    'Captioning: Subtitles or text displayed on screen to represent spoken content.',\n",
    "                    'Speech-to-Text: Software that converts spoken words into text.'\n",
    "                ]\n",
    "            },\n",
    "            'Speech Impairment': {\n",
    "                'Description': 'Includes conditions that affect the ability to speak clearly.',\n",
    "                'Assistive Technologies': [\n",
    "                    'Speech Generating Devices: Devices that help individuals generate speech through text or symbols.',\n",
    "                    'Text-to-Speech Software: Converts written text into spoken words.',\n",
    "                    'Alternative Communication Systems: Systems that use pictures, symbols, or electronic devices for communication.'\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_disability_info(self):\n",
    "        \"\"\"\n",
    "        Returns information about different types of disabilities and assistive technologies.\n",
    "        \"\"\"\n",
    "        return self.disability_info\n",
    "\n",
    "    def assistive_technology_for_disability(self, disability_type):\n",
    "        \"\"\"\n",
    "        Provides assistive technologies available for a specific type of disability.\n",
    "        \n",
    "        :param disability_type: Type of disability (e.g., 'Visual Impairment', 'Auditory Impairment', 'Speech Impairment').\n",
    "        :return: List of assistive technologies for the specified disability type.\n",
    "        \"\"\"\n",
    "        if disability_type in self.disability_info:\n",
    "            return self.disability_info[disability_type]['Assistive Technologies']\n",
    "        else:\n",
    "            return \"Disability type not recognized.\"\n",
    "\n",
    "#test Disabilities Class\n",
    "disabilities = Disabilities()\n",
    "\n",
    "#get information about all disabilities\n",
    "disability_info = disabilities.get_disability_info()\n",
    "print(\"Disability Information:\")\n",
    "for key, value in disability_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "#get assistive technologies for a specific disability\n",
    "visual_assistive_tech = disabilities.assistive_technology_for_disability('Visual Impairment')\n",
    "print(\"\\nAssistive Technologies for Visual Impairment:\")\n",
    "print(visual_assistive_tech)\n",
    "\n",
    "auditory_assistive_tech = disabilities.assistive_technology_for_disability('Auditory Impairment')\n",
    "print(\"\\nAssistive Technologies for Auditory Impairment:\")\n",
    "print(auditory_assistive_tech)\n",
    "\n",
    "speech_assistive_tech = disabilities.assistive_technology_for_disability('Speech Impairment')\n",
    "print(\"\\nAssistive Technologies for Speech Impairment:\")\n",
    "print(speech_assistive_tech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "daea0872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:56.009389Z",
     "iopub.status.busy": "2024-08-05T16:36:56.008648Z",
     "iopub.status.idle": "2024-08-05T16:36:59.034549Z",
     "shell.execute_reply": "2024-08-05T16:36:59.033398Z"
    },
    "papermill": {
     "duration": 3.034996,
     "end_time": "2024-08-05T16:36:59.036912",
     "exception": false,
     "start_time": "2024-08-05T16:36:56.001916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Info:\n",
      "{'CPU': 0.0, 'Memory': 3.8, 'Disk': 71.6, 'OS': 'Linux', 'Architecture': ('64bit', '')}\n",
      "Detected Issues:\n",
      "[]\n",
      "Machine Language Info:\n",
      "{'Assembler': 'Low-level language used for direct hardware manipulation.', 'BIOS': 'Firmware used to initialize hardware during the booting process.', 'C': 'High-level language used for system programming and applications.', 'Python': 'High-level language used for a wide range of applications including ML.', 'Machine Learning': 'Advanced techniques for data-driven problem solving.'}\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import platform\n",
    "import logging\n",
    "\n",
    "class ITDeviceMonitor:\n",
    "    \"\"\"\n",
    "    Monitors IT devices for performance and issues, detects potential problems,\n",
    "    takes preventive measures, and knows about different levels of machine languages.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.system_info = self._get_system_info()\n",
    "        self.languages = self._initialize_languages()\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    def _get_system_info(self):\n",
    "        \"\"\"\n",
    "        Gathers system information including CPU, memory, and disk usage.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'CPU': psutil.cpu_percent(interval=1),\n",
    "            'Memory': psutil.virtual_memory().percent,\n",
    "            'Disk': psutil.disk_usage('/').percent,\n",
    "            'OS': platform.system(),\n",
    "            'Architecture': platform.architecture()\n",
    "        }\n",
    "\n",
    "    def _initialize_languages(self):\n",
    "        \"\"\"\n",
    "        Initializes information about machine languages from assembler to high-level ML.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'Assembler': 'Low-level language used for direct hardware manipulation.',\n",
    "            'BIOS': 'Firmware used to initialize hardware during the booting process.',\n",
    "            'C': 'High-level language used for system programming and applications.',\n",
    "            'Python': 'High-level language used for a wide range of applications including ML.',\n",
    "            'Machine Learning': 'Advanced techniques for data-driven problem solving.'\n",
    "        }\n",
    "\n",
    "    def monitor(self):\n",
    "        \"\"\"\n",
    "        Monitors the IT device and logs system performance metrics.\n",
    "        \"\"\"\n",
    "        info = self._get_system_info()\n",
    "        logging.info(f\"System Info: {info}\")\n",
    "        return info\n",
    "\n",
    "    def detect_issues(self):\n",
    "        \"\"\"\n",
    "        Detects potential issues based on system metrics.\n",
    "        \"\"\"\n",
    "        issues = []\n",
    "        info = self._get_system_info()\n",
    "        if info['CPU'] > 85:\n",
    "            issues.append('High CPU usage detected.')\n",
    "        if info['Memory'] > 85:\n",
    "            issues.append('High memory usage detected.')\n",
    "        if info['Disk'] > 85:\n",
    "            issues.append('High disk usage detected.')\n",
    "        if not info['OS']:\n",
    "            issues.append('Operating System not detected.')\n",
    "        if not info['Architecture']:\n",
    "            issues.append('System architecture not detected.')\n",
    "\n",
    "        if issues:\n",
    "            logging.warning(f\"Detected Issues: {issues}\")\n",
    "        else:\n",
    "            logging.info(\"No issues detected.\")\n",
    "        \n",
    "        return issues\n",
    "\n",
    "    def take_preventive_measures(self, issues):\n",
    "        \"\"\"\n",
    "        Takes preventive measures based on detected issues.\n",
    "        \"\"\"\n",
    "        if 'High CPU usage detected.' in issues:\n",
    "            logging.info(\"Preventive measure: Consider closing unused applications or increasing CPU resources.\")\n",
    "        if 'High memory usage detected.' in issues:\n",
    "            logging.info(\"Preventive measure: Consider increasing memory resources or closing unused applications.\")\n",
    "        if 'High disk usage detected.' in issues:\n",
    "            logging.info(\"Preventive measure: Consider freeing up disk space or increasing disk resources.\")\n",
    "        if not issues:\n",
    "            logging.info(\"No preventive measures needed.\")\n",
    "\n",
    "    def get_machine_language_info(self):\n",
    "        \"\"\"\n",
    "        Returns information about machine languages.\n",
    "        \"\"\"\n",
    "        return self.languages\n",
    "\n",
    "#test Enhanced ITDeviceMonitor\n",
    "monitor = ITDeviceMonitor()\n",
    "\n",
    "#monitor the system\n",
    "system_info = monitor.monitor()\n",
    "print(\"System Info:\")\n",
    "print(system_info)\n",
    "\n",
    "#detect issues\n",
    "issues = monitor.detect_issues()\n",
    "print(\"Detected Issues:\")\n",
    "print(issues)\n",
    "\n",
    "#take preventive measures\n",
    "monitor.take_preventive_measures(issues)\n",
    "\n",
    "#get machine language information\n",
    "languages_info = monitor.get_machine_language_info()\n",
    "print(\"Machine Language Info:\")\n",
    "print(languages_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73fa91d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:36:59.049978Z",
     "iopub.status.busy": "2024-08-05T16:36:59.049596Z",
     "iopub.status.idle": "2024-08-05T16:37:00.736171Z",
     "shell.execute_reply": "2024-08-05T16:37:00.735112Z"
    },
    "papermill": {
     "duration": 1.698353,
     "end_time": "2024-08-05T16:37:00.741161",
     "exception": false,
     "start_time": "2024-08-05T16:36:59.042808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Problem Solution:\n",
      "{'optimization_result':   message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 3.765566073215498e-16\n",
      "        x: [-3.517e-09 -4.454e-09 -9.230e-09 -1.246e-08 -1.019e-08]\n",
      "      nit: 2\n",
      "      jac: [ 7.868e-09  5.993e-09 -3.558e-09 -1.002e-08 -5.486e-09]\n",
      " hess_inv: [[ 7.656e-01 -8.614e-02 ... -1.253e-01 -1.014e-01]\n",
      "            [-8.614e-02  9.683e-01 ... -4.604e-02 -3.726e-02]\n",
      "            ...\n",
      "            [-1.253e-01 -4.604e-02 ...  9.331e-01 -5.418e-02]\n",
      "            [-1.014e-01 -3.726e-02 ... -5.418e-02  9.561e-01]]\n",
      "     nfev: 18\n",
      "     njev: 3, 'reduced_data': array([[-0.04605163, -0.66784076],\n",
      "       [ 0.36235654, -0.45089948],\n",
      "       [-0.49839496,  0.18343828],\n",
      "       [-0.19204654,  0.18913756],\n",
      "       [ 0.31135329,  0.12943753],\n",
      "       [-0.22200511,  0.03275022],\n",
      "       [-0.0305351 ,  0.55674593],\n",
      "       [ 0.34875355,  0.26515969],\n",
      "       [ 0.01284706, -0.73789337],\n",
      "       [ 0.06819426,  0.5527721 ],\n",
      "       [ 0.31258596,  0.35898596],\n",
      "       [ 0.58096512, -0.05274118],\n",
      "       [ 0.36028528, -0.36869053],\n",
      "       [ 0.22789545, -0.39755196],\n",
      "       [ 0.38738449, -0.22416093],\n",
      "       [ 0.09630719, -0.02032143],\n",
      "       [-0.3172592 ,  0.18589573],\n",
      "       [ 0.46963152,  0.25431982],\n",
      "       [-0.42710368,  0.07926707],\n",
      "       [-0.65616328, -0.20653454],\n",
      "       [ 0.08993679,  0.13941449],\n",
      "       [ 0.27785421,  0.28266561],\n",
      "       [ 0.07910234, -0.58894295],\n",
      "       [ 0.21403219, -0.35692857],\n",
      "       [ 0.17649324,  0.16623297],\n",
      "       [-0.65532293,  0.03838829],\n",
      "       [-0.32453641, -0.41499543],\n",
      "       [-0.25818679,  0.62793263],\n",
      "       [ 0.18592194,  0.23543011],\n",
      "       [ 0.21935278, -0.33657489],\n",
      "       [ 0.12830859, -0.50889364],\n",
      "       [-0.51065825, -0.22661887],\n",
      "       [-0.48973459,  0.17323083],\n",
      "       [ 0.12832098, -0.3618558 ],\n",
      "       [ 0.34751791,  0.51601708],\n",
      "       [-0.55765107, -0.20663884],\n",
      "       [ 0.32757705, -0.02730851],\n",
      "       [-0.1204256 , -0.32300448],\n",
      "       [-0.2286487 , -0.27711362],\n",
      "       [ 0.27647725, -0.17137698],\n",
      "       [ 0.03975682,  0.50719804],\n",
      "       [-0.22663651, -0.2971034 ],\n",
      "       [-0.14672083,  0.30247475],\n",
      "       [-0.5468709 , -0.35955979],\n",
      "       [ 0.37476258,  0.36644204],\n",
      "       [-0.36209978,  0.04563745],\n",
      "       [ 0.02462054, -0.0452593 ],\n",
      "       [-0.24119826, -0.22416413],\n",
      "       [-0.04516919, -0.46149396],\n",
      "       [-0.65931848, -0.1260938 ],\n",
      "       [-0.27788469,  0.37918514],\n",
      "       [ 0.42219787, -0.38466066],\n",
      "       [-0.14869026, -0.34931906],\n",
      "       [ 0.65758049,  0.13390517],\n",
      "       [ 0.45261852,  0.07486806],\n",
      "       [-0.01201087,  0.14433868],\n",
      "       [ 0.64223435, -0.00468653],\n",
      "       [ 0.18832395,  0.14453639],\n",
      "       [-0.17717445,  0.0616323 ],\n",
      "       [-0.7316828 ,  0.1692664 ],\n",
      "       [ 0.5077617 ,  0.39143041],\n",
      "       [-0.13910039,  0.62437975],\n",
      "       [-0.07332919, -0.23967674],\n",
      "       [ 0.00497401,  0.15777735],\n",
      "       [-0.00403828, -0.00517724],\n",
      "       [ 0.58131236,  0.10480833],\n",
      "       [-0.10684214,  0.06755111],\n",
      "       [ 0.28018133,  0.73190434],\n",
      "       [ 0.13724143, -0.08936023],\n",
      "       [ 0.75196688, -0.13066134],\n",
      "       [-0.31898211, -0.46318869],\n",
      "       [-0.02805482, -0.43725246],\n",
      "       [-0.24879187, -0.40232848],\n",
      "       [-0.02853137,  0.14116329],\n",
      "       [ 0.55485688, -0.36970096],\n",
      "       [ 0.17613282, -0.60273811],\n",
      "       [-0.14180544,  0.571818  ],\n",
      "       [-0.07995371,  0.0513042 ],\n",
      "       [ 0.60622407,  0.16357352],\n",
      "       [-0.26062014,  0.75937586],\n",
      "       [ 0.09459987, -0.17304182],\n",
      "       [-0.27637401, -0.10134417],\n",
      "       [-0.71646681,  0.21708372],\n",
      "       [-0.27163864, -0.10060777],\n",
      "       [ 0.04678048, -0.15130298],\n",
      "       [ 0.0376785 , -0.16894242],\n",
      "       [ 0.26974917, -0.02100136],\n",
      "       [ 0.10259606,  0.33986954],\n",
      "       [-0.02013781,  0.01387091],\n",
      "       [ 0.15109597, -0.20069376],\n",
      "       [ 0.14528897, -0.00973011],\n",
      "       [-0.39870036, -0.35754969],\n",
      "       [ 0.21185967,  0.35499005],\n",
      "       [-0.25235392, -0.19847247],\n",
      "       [-0.06722789,  0.24752504],\n",
      "       [-0.44670438,  0.42877364],\n",
      "       [ 0.58457213,  0.01691849],\n",
      "       [-0.59735825,  0.14265302],\n",
      "       [-0.03875056,  0.14258039],\n",
      "       [-0.41047944,  0.43594091]]), 'clusters': array([0, 0, 2, 2, 1, 2, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 2, 2, 1, 1,\n",
      "       0, 0, 1, 2, 0, 2, 1, 0, 0, 2, 2, 0, 1, 2, 1, 0, 0, 0, 1, 0, 2, 0,\n",
      "       1, 2, 0, 0, 0, 2, 2, 0, 0, 1, 1, 2, 1, 1, 2, 2, 1, 2, 0, 2, 0, 1,\n",
      "       2, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 2, 1, 2, 0, 2, 2, 2, 0, 0, 1, 1,\n",
      "       2, 0, 1, 0, 1, 0, 2, 2, 1, 2, 2, 2], dtype=int32)}\n",
      "Text Problem Solution:\n",
      "Solved text problem with heuristic: Example text problem\n",
      "PCA Result:\n",
      "[[-0.04605163 -0.66784076]\n",
      " [ 0.36235654 -0.45089948]\n",
      " [-0.49839496  0.18343828]\n",
      " [-0.19204654  0.18913756]\n",
      " [ 0.31135329  0.12943753]\n",
      " [-0.22200511  0.03275022]\n",
      " [-0.0305351   0.55674593]\n",
      " [ 0.34875355  0.26515969]\n",
      " [ 0.01284706 -0.73789337]\n",
      " [ 0.06819426  0.5527721 ]\n",
      " [ 0.31258596  0.35898596]\n",
      " [ 0.58096512 -0.05274118]\n",
      " [ 0.36028528 -0.36869053]\n",
      " [ 0.22789545 -0.39755196]\n",
      " [ 0.38738449 -0.22416093]\n",
      " [ 0.09630719 -0.02032143]\n",
      " [-0.3172592   0.18589573]\n",
      " [ 0.46963152  0.25431982]\n",
      " [-0.42710368  0.07926707]\n",
      " [-0.65616328 -0.20653454]\n",
      " [ 0.08993679  0.13941449]\n",
      " [ 0.27785421  0.28266561]\n",
      " [ 0.07910234 -0.58894295]\n",
      " [ 0.21403219 -0.35692857]\n",
      " [ 0.17649324  0.16623297]\n",
      " [-0.65532293  0.03838829]\n",
      " [-0.32453641 -0.41499543]\n",
      " [-0.25818679  0.62793263]\n",
      " [ 0.18592194  0.23543011]\n",
      " [ 0.21935278 -0.33657489]\n",
      " [ 0.12830859 -0.50889364]\n",
      " [-0.51065825 -0.22661887]\n",
      " [-0.48973459  0.17323083]\n",
      " [ 0.12832098 -0.3618558 ]\n",
      " [ 0.34751791  0.51601708]\n",
      " [-0.55765107 -0.20663884]\n",
      " [ 0.32757705 -0.02730851]\n",
      " [-0.1204256  -0.32300448]\n",
      " [-0.2286487  -0.27711362]\n",
      " [ 0.27647725 -0.17137698]\n",
      " [ 0.03975682  0.50719804]\n",
      " [-0.22663651 -0.2971034 ]\n",
      " [-0.14672083  0.30247475]\n",
      " [-0.5468709  -0.35955979]\n",
      " [ 0.37476258  0.36644204]\n",
      " [-0.36209978  0.04563745]\n",
      " [ 0.02462054 -0.0452593 ]\n",
      " [-0.24119826 -0.22416413]\n",
      " [-0.04516919 -0.46149396]\n",
      " [-0.65931848 -0.1260938 ]\n",
      " [-0.27788469  0.37918514]\n",
      " [ 0.42219787 -0.38466066]\n",
      " [-0.14869026 -0.34931906]\n",
      " [ 0.65758049  0.13390517]\n",
      " [ 0.45261852  0.07486806]\n",
      " [-0.01201087  0.14433868]\n",
      " [ 0.64223435 -0.00468653]\n",
      " [ 0.18832395  0.14453639]\n",
      " [-0.17717445  0.0616323 ]\n",
      " [-0.7316828   0.1692664 ]\n",
      " [ 0.5077617   0.39143041]\n",
      " [-0.13910039  0.62437975]\n",
      " [-0.07332919 -0.23967674]\n",
      " [ 0.00497401  0.15777735]\n",
      " [-0.00403828 -0.00517724]\n",
      " [ 0.58131236  0.10480833]\n",
      " [-0.10684214  0.06755111]\n",
      " [ 0.28018133  0.73190434]\n",
      " [ 0.13724143 -0.08936023]\n",
      " [ 0.75196688 -0.13066134]\n",
      " [-0.31898211 -0.46318869]\n",
      " [-0.02805482 -0.43725246]\n",
      " [-0.24879187 -0.40232848]\n",
      " [-0.02853137  0.14116329]\n",
      " [ 0.55485688 -0.36970096]\n",
      " [ 0.17613282 -0.60273811]\n",
      " [-0.14180544  0.571818  ]\n",
      " [-0.07995371  0.0513042 ]\n",
      " [ 0.60622407  0.16357352]\n",
      " [-0.26062014  0.75937586]\n",
      " [ 0.09459987 -0.17304182]\n",
      " [-0.27637401 -0.10134417]\n",
      " [-0.71646681  0.21708372]\n",
      " [-0.27163864 -0.10060777]\n",
      " [ 0.04678048 -0.15130298]\n",
      " [ 0.0376785  -0.16894242]\n",
      " [ 0.26974917 -0.02100136]\n",
      " [ 0.10259606  0.33986954]\n",
      " [-0.02013781  0.01387091]\n",
      " [ 0.15109597 -0.20069376]\n",
      " [ 0.14528897 -0.00973011]\n",
      " [-0.39870036 -0.35754969]\n",
      " [ 0.21185967  0.35499005]\n",
      " [-0.25235392 -0.19847247]\n",
      " [-0.06722789  0.24752504]\n",
      " [-0.44670438  0.42877364]\n",
      " [ 0.58457213  0.01691849]\n",
      " [-0.59735825  0.14265302]\n",
      " [-0.03875056  0.14258039]\n",
      " [-0.41047944  0.43594091]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class ComplexSolver:\n",
    "    \"\"\"\n",
    "    Solves complex problems using a variety of algorithms including optimization,\n",
    "    dimensionality reduction, clustering, and classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        #initialize any necessary attributes here\n",
    "        self.pca = PCA(n_components=2)\n",
    "        self.kmeans = KMeans(n_clusters=3)\n",
    "        self.classifier = RandomForestClassifier()\n",
    "\n",
    "    def solve(self, problem):\n",
    "        \"\"\"\n",
    "        Solves a complex problem using multiple techniques.\n",
    "        \"\"\"\n",
    "        if isinstance(problem, np.ndarray):\n",
    "            return self._solve_numerical_problem(problem)\n",
    "        elif isinstance(problem, str):\n",
    "            return self._solve_text_problem(problem)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported problem type\")\n",
    "\n",
    "    def _solve_numerical_problem(self, problem_data):\n",
    "        \"\"\"\n",
    "        Solves numerical problems using optimization, PCA, clustering, or classification.\n",
    "        \"\"\"\n",
    "        #example: Optimization\n",
    "        result = minimize(self._objective_function, x0=np.random.rand(problem_data.shape[1]))\n",
    "\n",
    "        #example: Dimensionality Reduction\n",
    "        reduced_data = self.pca.fit_transform(problem_data)\n",
    "\n",
    "        #example: Clustering\n",
    "        clusters = self.kmeans.fit_predict(reduced_data)\n",
    "\n",
    "        #example: Classification (assuming problem_data has labels for training)\n",
    "        #self.classifier.fit(problem_data, labels)  #labeled data needed\n",
    "        #predictions = self.classifier.predict(problem_data)\n",
    "\n",
    "        return {\n",
    "            'optimization_result': result,\n",
    "            'reduced_data': reduced_data,\n",
    "            'clusters': clusters\n",
    "            # 'predictions': predictions\n",
    "        }\n",
    "\n",
    "    def _solve_text_problem(self, text_problem):\n",
    "        \"\"\"\n",
    "        Solves text-based problems using natural language processing or heuristics.\n",
    "        \"\"\"\n",
    "        #example: Simple heuristic approach\n",
    "        return f\"Solved text problem with heuristic: {text_problem}\"\n",
    "\n",
    "    def _objective_function(self, x):\n",
    "        \"\"\"\n",
    "        Example objective function for optimization.\n",
    "        \"\"\"\n",
    "        #simple quadratic objective function\n",
    "        return np.sum(x ** 2)\n",
    "\n",
    "    def apply_algorithm(self, problem_data, algorithm):\n",
    "        \"\"\"\n",
    "        Applies a specified algorithm to the problem data.\n",
    "        \"\"\"\n",
    "        if algorithm == 'pca':\n",
    "            return self.pca.fit_transform(problem_data)\n",
    "        elif algorithm == 'kmeans':\n",
    "            return self.kmeans.fit_predict(problem_data)\n",
    "        elif algorithm == 'random_forest':\n",
    "            return self.classifier.predict(problem_data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported algorithm\")\n",
    "\n",
    "#test Enhanced ComplexSolver\n",
    "solver = ComplexSolver()\n",
    "\n",
    "#numerical problem example\n",
    "problem_data = np.random.rand(100, 5)  #example data\n",
    "solution_numerical = solver.solve(problem_data)\n",
    "print(\"Numerical Problem Solution:\")\n",
    "print(solution_numerical)\n",
    "\n",
    "#text problem example\n",
    "text_problem = \"Example text problem\"\n",
    "solution_text = solver.solve(text_problem)\n",
    "print(\"Text Problem Solution:\")\n",
    "print(solution_text)\n",
    "\n",
    "#apply specific algorithm\n",
    "algorithm_result = solver.apply_algorithm(problem_data, 'pca')\n",
    "print(\"PCA Result:\")\n",
    "print(algorithm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15379660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T16:37:00.755293Z",
     "iopub.status.busy": "2024-08-05T16:37:00.754928Z",
     "iopub.status.idle": "2024-08-05T16:37:03.964307Z",
     "shell.execute_reply": "2024-08-05T16:37:03.963249Z"
    },
    "papermill": {
     "duration": 3.219751,
     "end_time": "2024-08-05T16:37:03.966900",
     "exception": false,
     "start_time": "2024-08-05T16:37:00.747149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Grid:\n",
      "[[5 2 4 6 0 4 1 4 1 3 2 8 9 3 8 6 2 4 8 8 2 4 3 5 2 2 2 0 2 2]\n",
      " [7 5 4 4 3 4 3 3 3 3 4 6 6 5 6 5 4 4 7 6 5 4 3 2 4 2 5 5 4 6]\n",
      " [3 4 6 4 4 4 6 3 2 7 5 3 3 4 5 4 5 5 5 6 6 4 3 3 1 6 5 5 5 5]\n",
      " [5 6 4 4 4 7 4 4 4 3 3 3 4 3 4 5 3 3 4 6 4 3 1 1 4 3 4 4 1 1]\n",
      " [6 4 6 4 5 6 5 3 1 4 4 4 3 5 2 3 2 2 4 1 3 3 2 2 3 3 4 2 4 7]\n",
      " [1 4 3 5 6 5 4 3 5 4 5 4 5 4 4 1 2 3 1 5 2 4 3 4 4 4 2 4 4 8]\n",
      " [1 3 5 5 4 6 4 3 5 5 5 4 6 3 4 3 4 3 6 1 5 2 5 6 5 3 5 3 4 7]\n",
      " [3 3 5 5 6 4 4 6 3 5 5 4 2 5 4 4 3 7 3 7 2 5 3 5 6 6 3 5 3 0]\n",
      " [6 6 5 6 3 6 4 4 5 4 3 4 4 2 4 4 5 6 6 5 5 5 5 6 6 3 6 5 3 0]\n",
      " [5 3 6 5 3 1 5 4 5 4 4 5 3 5 4 4 6 6 5 3 6 4 5 7 5 5 4 4 5 7]\n",
      " [8 5 5 2 3 1 2 6 5 5 5 7 7 5 5 5 6 4 4 4 3 5 6 5 6 5 3 4 3 5]\n",
      " [5 4 3 5 2 3 3 5 4 6 6 7 8 7 6 6 5 6 3 4 6 4 2 6 4 4 4 2 5 7]\n",
      " [7 5 4 4 3 5 7 3 8 4 6 8 5 7 6 6 7 4 4 5 2 3 4 3 5 2 3 3 2 2]\n",
      " [3 2 3 4 6 7 5 6 3 5 6 4 7 3 6 6 5 5 1 3 3 2 3 6 3 3 3 4 4 1]\n",
      " [1 3 4 4 6 5 7 5 3 4 2 7 5 5 4 6 6 3 5 2 4 4 5 4 4 3 3 4 3 1]\n",
      " [5 4 4 8 5 7 5 4 4 2 4 5 4 4 5 5 5 4 2 4 5 3 5 5 5 1 5 5 3 1]\n",
      " [2 4 6 7 5 6 5 5 4 3 4 4 6 2 3 3 5 4 1 4 2 6 5 5 3 6 4 3 4 1]\n",
      " [9 6 4 5 8 4 5 6 4 5 4 6 3 3 3 4 3 4 5 1 5 3 4 5 4 2 3 4 3 6]\n",
      " [6 4 6 6 4 4 6 4 4 5 3 3 4 3 1 2 4 2 3 4 2 2 4 4 2 4 1 2 3 7]\n",
      " [4 6 6 6 4 4 4 5 5 3 5 4 3 4 3 2 3 5 4 3 2 3 3 4 6 3 6 1 3 3]\n",
      " [2 5 7 5 6 2 5 5 5 4 4 3 5 3 3 4 5 5 5 5 4 1 4 6 5 6 4 4 4 8]\n",
      " [5 4 5 6 2 6 4 5 4 6 2 3 2 3 3 3 6 3 6 3 1 2 5 4 5 5 3 3 3 2]\n",
      " [5 3 3 4 5 2 5 6 6 3 4 2 3 6 1 4 3 6 3 3 2 5 1 6 3 5 4 3 1 2]\n",
      " [0 2 2 3 2 5 3 5 3 8 3 4 5 2 5 3 3 4 4 5 3 3 8 1 4 2 5 3 4 8]\n",
      " [2 2 5 2 2 1 5 3 6 4 7 4 4 6 2 4 5 3 6 4 6 7 2 4 1 4 5 4 4 4]\n",
      " [1 5 3 4 1 3 3 5 4 4 6 6 4 2 6 6 3 5 4 7 5 4 6 2 2 4 6 5 4 6]\n",
      " [6 6 4 4 2 2 5 3 2 5 4 3 6 4 3 4 6 3 4 3 5 5 3 3 4 4 6 4 5 3]\n",
      " [6 4 7 3 5 4 2 4 2 3 5 7 3 5 4 5 3 3 4 4 5 5 4 5 2 4 5 6 3 4]\n",
      " [3 5 3 6 5 5 4 3 5 5 6 4 5 6 5 4 4 4 3 4 5 4 6 3 3 3 3 4 3 0]\n",
      " [3 3 1 5 8 7 3 4 9 4 8 5 0 9 7 6 1 3 6 5 5 2 4 5 3 0 3 3 1 8]]\n",
      "Processed Graph Nodes (0, 0):\n",
      "{'value': 4.5}\n",
      "Problem Solution:\n",
      "Complex solver not enabled.\n",
      "Ethics Values:\n",
      "{'Respect for Others': 'Valuing the perspectives and dignity of individuals in all interactions.', 'Community Harmony': 'Emphasis on maintaining cooperation and positive relationships within the community.', 'Respect for Nature': 'A deep respect for nature and the environment, recognizing the interconnectedness of all living things.', 'Hospitality': 'Generosity and kindness towards others, especially guests and newcomers.', 'Family Bond': 'Strong family ties and the importance of supporting and caring for family members.', 'Honor and Integrity': 'Maintaining personal honor and integrity, and acting with honesty and ethical principles.'}\n",
      "Disabilities Considerations:\n",
      "{'Visual Impairment': {'Description': 'Includes blindness or low vision.', 'Assistive Technologies': ['Screen Readers: Software that reads the text on the screen aloud.', 'Braille Displays: Devices that convert screen text to Braille.', 'Magnification Software: Programs that enlarge text and images on the screen.']}, 'Auditory Impairment': {'Description': 'Includes deafness or hearing loss.', 'Assistive Technologies': ['Hearing Aids: Devices that amplify sound for individuals with hearing loss.', 'Captioning: Subtitles or text displayed on screen to represent spoken content.', 'Speech-to-Text: Software that converts spoken words into text.']}, 'Speech Impairment': {'Description': 'Includes conditions that affect the ability to speak clearly.', 'Assistive Technologies': ['Speech Generating Devices: Devices that help individuals generate speech through text or symbols.', 'Text-to-Speech Software: Converts written text into spoken words.', 'Alternative Communication Systems: Systems that use pictures, symbols, or electronic devices for communication.']}}\n"
     ]
    }
   ],
   "source": [
    "#define the Yambi (which means \"Welcome\" in kikongo) model\n",
    "class Yambi:\n",
    "    \"\"\"\n",
    "    Integrates various components into Yambi model, using only the necessary ones based on the input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, use_symbolic_rule=True, use_graph_based=True, use_ca_layer=True, \n",
    "                 use_ethics=True, use_disabilities=True, use_it_monitor=True, use_complex_solver=True):\n",
    "        self.use_symbolic_rule = use_symbolic_rule\n",
    "        self.use_graph_based = use_graph_based\n",
    "        self.use_ca_layer = use_ca_layer\n",
    "        self.use_ethics = use_ethics\n",
    "        self.use_disabilities = use_disabilities\n",
    "        self.use_it_monitor = use_it_monitor\n",
    "        self.use_complex_solver = use_complex_solver\n",
    "\n",
    "        if self.use_symbolic_rule:\n",
    "            self.symbolic_rule_induction = SymbolicRuleInduction()\n",
    "        if self.use_graph_based:\n",
    "            self.graph_based_representation = GraphBasedRepresentation()\n",
    "        if self.use_ca_layer:\n",
    "            self.cellular_automata_layer = CellularAutomataLayer(grid_size=30)\n",
    "        if self.use_ethics:\n",
    "            self.ethics = Ethics()\n",
    "        if self.use_disabilities:\n",
    "            self.disabilities = Disabilities()\n",
    "        if self.use_it_monitor:\n",
    "            self.it_device_monitor = ITDeviceMonitor()\n",
    "        if self.use_complex_solver:\n",
    "            self.complex_solver = ComplexSolver()\n",
    "\n",
    "    def process_input(self, input_grid):\n",
    "        \"\"\"\n",
    "        Processes the input grid using various techniques based on enabled components.\n",
    "        \"\"\"\n",
    "        processed_graph = None\n",
    "\n",
    "        if self.use_graph_based:\n",
    "            graph = self.graph_based_representation.grid_to_graph(input_grid)\n",
    "            processed_graph = self.graph_based_representation.process_graph(graph)\n",
    "        \n",
    "        if self.use_ca_layer:\n",
    "            processed_grid = self.cellular_automata_layer.step(input_grid)\n",
    "        else:\n",
    "            processed_grid = input_grid\n",
    "\n",
    "        return processed_grid, processed_graph\n",
    "\n",
    "    def solve_problem(self, problem):\n",
    "        \"\"\"\n",
    "        Uses complex solver to tackle a problem if enabled.\n",
    "        \"\"\"\n",
    "        if self.use_complex_solver:\n",
    "            return self.complex_solver.solve(problem)\n",
    "        else:\n",
    "            return \"Complex solver not enabled.\"\n",
    "\n",
    "    def get_ethics(self):\n",
    "        \"\"\"\n",
    "        Returns ethical values if enabled.\n",
    "        \"\"\"\n",
    "        if self.use_ethics:\n",
    "            return self.ethics.get_values()\n",
    "        else:\n",
    "            return \"Ethics not enabled.\"\n",
    "\n",
    "    def get_disabilities_considerations(self):\n",
    "        \"\"\"\n",
    "        Returns information about disabilities and assistive technologies if enabled.\n",
    "        \"\"\"\n",
    "        if self.use_disabilities:\n",
    "            return self.disabilities.get_disability_info()\n",
    "        else:\n",
    "            return \"Disabilities considerations not enabled.\"\n",
    "\n",
    "    def monitor_it_devices(self):\n",
    "        \"\"\"\n",
    "        Monitors IT devices and performs preventive measures if enabled.\n",
    "        \"\"\"\n",
    "        if self.use_it_monitor:\n",
    "            system_info = self.it_device_monitor.monitor()\n",
    "            issues = self.it_device_monitor.detect_issues()\n",
    "            self.it_device_monitor.take_preventive_measures(issues)\n",
    "            return system_info, issues\n",
    "        else:\n",
    "            print(\"IT device monitoring not enabled.\")\n",
    "            return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # instantiate Yambi with the desired components enabled or disabled\n",
    "    yambi_model = Yambi(use_symbolic_rule=True, use_graph_based=True, use_ca_layer=True, \n",
    "                        use_ethics=True, use_disabilities=True, use_it_monitor=True, \n",
    "                        use_complex_solver=False)\n",
    "    \n",
    "    #test process_input\n",
    "    test_grid = np.random.randint(0, 10, (30, 30))\n",
    "    processed_grid, processed_graph = yambi_model.process_input(test_grid)\n",
    "    print(\"Processed Grid:\")\n",
    "    print(processed_grid)\n",
    "    print(\"Processed Graph Nodes (0, 0):\")\n",
    "    print(processed_graph.nodes[(0, 0)] if processed_graph else \"No graph processed\")\n",
    "    \n",
    "    #test solving a problem\n",
    "    problem_solution = yambi_model.solve_problem(\"Complex problem example\")\n",
    "    print(\"Problem Solution:\")\n",
    "    print(problem_solution)\n",
    "    \n",
    "    #test ethics\n",
    "    ethics_values = yambi_model.get_ethics()\n",
    "    print(\"Ethics Values:\")\n",
    "    print(ethics_values)\n",
    "    \n",
    "    #test disabilities considerations\n",
    "    disabilities_considerations = yambi_model.get_disabilities_considerations()\n",
    "    print(\"Disabilities Considerations:\")\n",
    "    print(disabilities_considerations)\n",
    "    \n",
    "    #test IT device monitoring\n",
    "    system_info, issues = yambi_model.monitor_it_devices()\n",
    "    if system_info and issues:\n",
    "        print(\"System Info:\")\n",
    "        print(system_info)\n",
    "        print(\"Detected Issues:\")\n",
    "        print(issues)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.92301,
   "end_time": "2024-08-05T16:37:05.097047",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-05T16:36:47.174037",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
