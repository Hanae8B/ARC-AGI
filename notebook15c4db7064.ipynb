{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "132c10dd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-03T20:33:57.740992Z",
     "iopub.status.busy": "2024-08-03T20:33:57.740413Z",
     "iopub.status.idle": "2024-08-03T20:33:58.813496Z",
     "shell.execute_reply": "2024-08-03T20:33:58.811987Z"
    },
    "papermill": {
     "duration": 1.085671,
     "end_time": "2024-08-03T20:33:58.816991",
     "exception": false,
     "start_time": "2024-08-03T20:33:57.731320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2024/sample_submission.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c364b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:33:58.833905Z",
     "iopub.status.busy": "2024-08-03T20:33:58.833228Z",
     "iopub.status.idle": "2024-08-03T20:33:59.242126Z",
     "shell.execute_reply": "2024-08-03T20:33:59.240754Z"
    },
    "papermill": {
     "duration": 0.420909,
     "end_time": "2024-08-03T20:33:59.245456",
     "exception": false,
     "start_time": "2024-08-03T20:33:58.824547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "#load the data\n",
    "training_solutions = load_json('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json')\n",
    "evaluation_solutions = load_json('/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json')\n",
    "training_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json')\n",
    "evaluation_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json')\n",
    "test_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52134d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:33:59.260560Z",
     "iopub.status.busy": "2024-08-03T20:33:59.260087Z",
     "iopub.status.idle": "2024-08-03T20:33:59.271302Z",
     "shell.execute_reply": "2024-08-03T20:33:59.269872Z"
    },
    "papermill": {
     "duration": 0.02238,
     "end_time": "2024-08-03T20:33:59.274439",
     "exception": false,
     "start_time": "2024-08-03T20:33:59.252059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Solutions:\n",
      "Key: 007bbfb7\n",
      "Sample Data: [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
      "\n",
      "Training Challenges:\n",
      "Key: 007bbfb7\n",
      "Sample Data: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "Evaluation Solutions:\n",
      "Key: 00576224\n",
      "Sample Data: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "\n",
      "Evaluation Challenges:\n",
      "Key: 00576224\n",
      "Sample Data: {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
      "\n",
      "Test Challenges:\n",
      "Key: 007bbfb7\n",
      "Sample Data: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect_data(data, num_samples=1):\n",
    "    for key, value in list(data.items())[:num_samples]:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"Sample Data: {value}\\n\")\n",
    "        \n",
    "print(\"Training Solutions:\")\n",
    "inspect_data(training_solutions)\n",
    "\n",
    "print(\"Training Challenges:\")\n",
    "inspect_data(training_challenges)\n",
    "\n",
    "print(\"Evaluation Solutions:\")\n",
    "inspect_data(evaluation_solutions)\n",
    "\n",
    "print(\"Evaluation Challenges:\")\n",
    "inspect_data(evaluation_challenges)\n",
    "\n",
    "print(\"Test Challenges:\")\n",
    "inspect_data(test_challenges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9fb6df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:33:59.290307Z",
     "iopub.status.busy": "2024-08-03T20:33:59.289904Z",
     "iopub.status.idle": "2024-08-03T20:33:59.521595Z",
     "shell.execute_reply": "2024-08-03T20:33:59.520261Z"
    },
    "papermill": {
     "duration": 0.243499,
     "end_time": "2024-08-03T20:33:59.524601",
     "exception": false,
     "start_time": "2024-08-03T20:33:59.281102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum height: 30\n",
      "Maximum width: 30\n",
      "X_train shape: (1302, 30, 30)\n",
      "y_train shape: (1302, 30, 30)\n",
      "Loaded X_train shape: (1302, 30, 30)\n",
      "Loaded y_train shape: (1302, 30, 30)\n"
     ]
    }
   ],
   "source": [
    "#load training data\n",
    "with open('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json') as f:\n",
    "    training_challenges = json.load(f)\n",
    "with open('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json') as f:\n",
    "    training_solutions = json.load(f)\n",
    "\n",
    "def prepare_training_data_padded(challenges, solutions):\n",
    "    #calculate the maximum height and width for padding\n",
    "    max_height = max(\n",
    "        max(len(example['input']) for example in challenge['train'])\n",
    "        for challenge in challenges.values()\n",
    "    )\n",
    "    max_width = max(\n",
    "        max(len(row) for example in challenge['train'] for row in example['input'])\n",
    "        for challenge in challenges.values()\n",
    "    )\n",
    "    \n",
    "    print(f\"Maximum height: {max_height}\")\n",
    "    print(f\"Maximum width: {max_width}\")\n",
    "    \n",
    "    def pad_grid(grid, target_height, target_width):\n",
    "        padded_grid = np.zeros((target_height, target_width), dtype=int)\n",
    "        for i, row in enumerate(grid):\n",
    "            padded_grid[i, :len(row)] = row\n",
    "        return padded_grid\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for key in challenges.keys():\n",
    "        challenge = challenges[key]\n",
    "        solution = solutions[key]\n",
    "        \n",
    "        #add training data\n",
    "        for example in challenge['train']:\n",
    "            input_grid = example['input']\n",
    "            output_grid = example['output']\n",
    "            padded_input = pad_grid(input_grid, max_height, max_width)\n",
    "            padded_output = pad_grid(output_grid, max_height, max_width)\n",
    "            X_train.append(padded_input)\n",
    "            y_train.append(padded_output)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    \n",
    "    #save the arrays\n",
    "    np.save('X_train.npy', X_train)\n",
    "    np.save('y_train.npy', y_train)\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "X_train, y_train = prepare_training_data_padded(training_challenges, training_solutions)\n",
    "\n",
    "X_train_loaded = np.load('X_train.npy')\n",
    "y_train_loaded = np.load('y_train.npy')\n",
    "\n",
    "print(f\"Loaded X_train shape: {X_train_loaded.shape}\")\n",
    "print(f\"Loaded y_train shape: {y_train_loaded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8ad2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:33:59.541197Z",
     "iopub.status.busy": "2024-08-03T20:33:59.540733Z",
     "iopub.status.idle": "2024-08-03T20:34:03.765418Z",
     "shell.execute_reply": "2024-08-03T20:34:03.763704Z"
    },
    "papermill": {
     "duration": 4.237294,
     "end_time": "2024-08-03T20:34:03.768983",
     "exception": false,
     "start_time": "2024-08-03T20:33:59.531689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"A neural network that processes sequences of data using attention mechanisms to understand context and relationships.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, output_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        #embedding layer for input sequences\n",
    "        self.embedding = nn.Embedding(input_dim, model_dim)\n",
    "        \n",
    "        #Transformer module\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=model_dim, \n",
    "            nhead=num_heads, \n",
    "            num_encoder_layers=num_layers, \n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=True  #set batch_first to True\n",
    "        )\n",
    "        \n",
    "        #output linear layer to transform the transformer output to desired output dimensions\n",
    "        self.fc_out = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "        \n",
    "        Parameters:\n",
    "        src (torch.Tensor): Source input tensor of shape (batch_size, seq_len, input_dim)\n",
    "        tgt (torch.Tensor): Target input tensor of shape (batch_size, seq_len, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor of shape (batch_size, seq_len, output_dim)\n",
    "        \"\"\"\n",
    "        #apply embeddings to the source and target sequences\n",
    "        src_embedded = self.embedding(src) \n",
    "        tgt_embedded = self.embedding(tgt)\n",
    "        \n",
    "        #pass through the Transformer\n",
    "        transformer_output = self.transformer(src_embedded, tgt_embedded)\n",
    "        \n",
    "        #pass through the final linear layer\n",
    "        output = self.fc_out(transformer_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd129631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:03.786119Z",
     "iopub.status.busy": "2024-08-03T20:34:03.785416Z",
     "iopub.status.idle": "2024-08-03T20:34:03.797894Z",
     "shell.execute_reply": "2024-08-03T20:34:03.796612Z"
    },
    "papermill": {
     "duration": 0.024475,
     "end_time": "2024-08-03T20:34:03.800735",
     "exception": false,
     "start_time": "2024-08-03T20:34:03.776260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \"\"\"A neural network designed for graph data that processes nodes and edges to learn relationships in graphs.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        #define layers\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)  #first graph convolution layer\n",
    "        self.conv2 = nn.Linear(hidden_dim, hidden_dim)  #second graph convolution layer\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)  #output layer\n",
    "\n",
    "    def forward(self, graph_data):\n",
    "        \"\"\"\n",
    "        Forward pass through the model.\n",
    "\n",
    "        Parameters:\n",
    "        graph_data (dict): A dictionary containing 'nodes' and 'edges'.\n",
    "                           - 'nodes' (torch.Tensor): Node features of shape (num_nodes, input_dim)\n",
    "                           - 'edges' (torch.Tensor): Edge list of shape (num_edges, 2), indicating connections between nodes\n",
    "\n",
    "        Returns:\n",
    "        torch.Tensor: Output tensor with node-level features transformed by the model\n",
    "        \"\"\"\n",
    "        nodes = graph_data['nodes']\n",
    "        edges = graph_data['edges'] \n",
    "\n",
    "        #pass node features through the first graph convolution layer\n",
    "        x = F.relu(self.conv1(nodes))\n",
    "        \n",
    "        #pass through the second graph convolution layer\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        #mean pooling\n",
    "        x = x.mean(dim=0, keepdim=True)\n",
    "\n",
    "        #pass through the final linear layer\n",
    "        x = self.fc_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f46fd91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:03.816433Z",
     "iopub.status.busy": "2024-08-03T20:34:03.815481Z",
     "iopub.status.idle": "2024-08-03T20:34:03.827217Z",
     "shell.execute_reply": "2024-08-03T20:34:03.825894Z"
    },
    "papermill": {
     "duration": 0.022648,
     "end_time": "2024-08-03T20:34:03.830009",
     "exception": false,
     "start_time": "2024-08-03T20:34:03.807361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    \"\"\"A class that defines a symbolic rule for transforming an input grid.\"\"\"\n",
    "    \n",
    "    def __init__(self, rule_func):\n",
    "        \"\"\"\n",
    "        Initialize a rule with a transformation function.\n",
    "\n",
    "        Parameters:\n",
    "        rule_func (function): A function that takes output_grid and input_grid, and returns a transformed output_grid.\n",
    "        \"\"\"\n",
    "        self.rule_func = rule_func\n",
    "\n",
    "    def apply(self, output_grid, input_grid):\n",
    "        \"\"\"\n",
    "        Apply the rule to transform the input grid.\n",
    "\n",
    "        Parameters:\n",
    "        output_grid (numpy.ndarray): The current output grid to be transformed.\n",
    "        input_grid (numpy.ndarray): The input grid that will be used for transformation.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: The transformed output grid after applying the rule.\n",
    "        \"\"\"\n",
    "        return self.rule_func(output_grid, input_grid)\n",
    "\n",
    "\n",
    "class SymbolicRuleModel:\n",
    "    \"\"\"A model that applies predefined rules to process input data and generate outputs based on symbolic logic.\"\"\"\n",
    "\n",
    "    def __init__(self, rules):\n",
    "        \"\"\"\n",
    "        Initialize the symbolic rule model with a list of rules.\n",
    "\n",
    "        Parameters:\n",
    "        rules (list of Rule): A list of Rule objects to be applied in sequence.\n",
    "        \"\"\"\n",
    "        self.rules = rules  #a list of Rule objects\n",
    "\n",
    "    def apply_rules(self, input_grid):\n",
    "        \"\"\"\n",
    "        Applies predefined rules to the input grid.\n",
    "\n",
    "        Parameters:\n",
    "        input_grid (numpy.ndarray): The input grid to which rules will be applied.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: The output grid after applying all the rules.\n",
    "        \"\"\"\n",
    "        output_grid = np.zeros_like(input_grid)  #initialize output grid with zeros\n",
    "        for rule in self.rules:\n",
    "            output_grid = rule.apply(output_grid, input_grid)\n",
    "        return output_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56593b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:03.845529Z",
     "iopub.status.busy": "2024-08-03T20:34:03.845019Z",
     "iopub.status.idle": "2024-08-03T20:34:03.868502Z",
     "shell.execute_reply": "2024-08-03T20:34:03.866986Z"
    },
    "papermill": {
     "duration": 0.034848,
     "end_time": "2024-08-03T20:34:03.871414",
     "exception": false,
     "start_time": "2024-08-03T20:34:03.836566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EvolutionaryOptimizer:\n",
    "    \"\"\"An optimizer that adjusts model parameters using evolutionary algorithms to refine performance.\"\"\"\n",
    "\n",
    "    def __init__(self, model, population_size, generations, mutation_rate):\n",
    "        \"\"\"\n",
    "        Initialize the evolutionary optimizer.\n",
    "\n",
    "        Parameters:\n",
    "        model (torch.nn.Module): The model to optimize.\n",
    "        population_size (int): Number of solutions in the population.\n",
    "        generations (int): Number of generations to evolve.\n",
    "        mutation_rate (float): Probability of mutation for each parameter.\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.population_size = population_size\n",
    "        self.generations = generations\n",
    "        self.mutation_rate = mutation_rate\n",
    "\n",
    "    def initialize_population(self):\n",
    "        \"\"\"Initialize the population with random model parameters.\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            params = [torch.randn_like(p) for p in self.model.parameters()]\n",
    "            population.append(params)\n",
    "        return population\n",
    "\n",
    "    def evaluate_fitness(self, population, X_train, y_train):\n",
    "        \"\"\"Evaluate the fitness of each solution in the population.\"\"\"\n",
    "        fitness_scores = []\n",
    "        for params in population:\n",
    "            self.set_params(params)\n",
    "            outputs = self.model(X_train, X_train, {})  #use X_train as dummy input\n",
    "            loss = F.mse_loss(outputs, y_train)\n",
    "            fitness_scores.append(-loss.item())  #negate loss to maximize fitness\n",
    "        return fitness_scores\n",
    "\n",
    "    def set_params(self, params):\n",
    "        \"\"\"Set the model parameters.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for param, new_param in zip(self.model.parameters(), params):\n",
    "                param.copy_(new_param)\n",
    "\n",
    "    def select_parents(self, population, fitness_scores):\n",
    "        \"\"\"Select parents based on fitness scores.\"\"\"\n",
    "        indices = np.argsort(fitness_scores)[-self.population_size // 2:]\n",
    "        parents = [population[i] for i in indices]\n",
    "        return parents\n",
    "\n",
    "    def crossover(self, parents):\n",
    "        \"\"\"Create offspring by combining parents.\"\"\"\n",
    "        offspring = []\n",
    "        for _ in range(self.population_size - len(parents)):\n",
    "            p1, p2 = np.random.choice(parents, 2, replace=False)\n",
    "            child = [torch.where(torch.rand_like(p1[0]) < 0.5, p1[i], p2[i]) for i in range(len(p1))]\n",
    "            offspring.append(child)\n",
    "        return offspring\n",
    "\n",
    "    def mutate(self, population):\n",
    "        \"\"\"Apply mutation to the population.\"\"\"\n",
    "        for i in range(len(population)):\n",
    "            if np.random.rand() < self.mutation_rate:\n",
    "                for j in range(len(population[i])):\n",
    "                    if np.random.rand() < self.mutation_rate:\n",
    "                        mutation = torch.randn_like(population[i][j]) * 0.1  #small mutation\n",
    "                        population[i][j] += mutation\n",
    "\n",
    "    def optimize(self, X_train, y_train):\n",
    "        \"\"\"Run the evolutionary optimization algorithm.\"\"\"\n",
    "        population = self.initialize_population()\n",
    "        for generation in range(self.generations):\n",
    "            fitness_scores = self.evaluate_fitness(population, X_train, y_train)\n",
    "            parents = self.select_parents(population, fitness_scores)\n",
    "            offspring = self.crossover(parents)\n",
    "            self.mutate(parents + offspring)\n",
    "            population = parents + offspring\n",
    "            \n",
    "            best_fitness = max(fitness_scores)\n",
    "            print(f\"Generation {generation + 1}: Best Fitness = {best_fitness}\")\n",
    "\n",
    "        #return the best solution from the last generation\n",
    "        best_index = np.argmax(fitness_scores)\n",
    "        best_params = population[best_index]\n",
    "        self.set_params(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f732e222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:03.886840Z",
     "iopub.status.busy": "2024-08-03T20:34:03.886327Z",
     "iopub.status.idle": "2024-08-03T20:34:03.897207Z",
     "shell.execute_reply": "2024-08-03T20:34:03.895756Z"
    },
    "papermill": {
     "duration": 0.022243,
     "end_time": "2024-08-03T20:34:03.900279",
     "exception": false,
     "start_time": "2024-08-03T20:34:03.878036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    \"\"\"A model integrating Transformer, GNN, and Neuro-Symbolic methods for diverse data processing and reasoning.\"\"\"\n",
    "\n",
    "    def __init__(self, transformer_model, gnn_model, neuro_symbolic_model):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.gnn = gnn_model\n",
    "        self.neuro_symbolic = neuro_symbolic_model\n",
    "\n",
    "    def forward(self, src, tgt, graph_data):\n",
    "        transformer_output = self.transformer(src, tgt)  #Transformer output\n",
    "        gnn_output = self.gnn(graph_data)  #GNN output\n",
    "\n",
    "        #apply symbolic rules to the transformer output\n",
    "        transformer_output_np = transformer_output.detach().cpu().numpy()  #convert to numpy for rule application\n",
    "        neuro_symbolic_output_np = self.neuro_symbolic.apply_rules(transformer_output_np)\n",
    "        neuro_symbolic_output = torch.tensor(neuro_symbolic_output_np, dtype=torch.float32, device=transformer_output.device)\n",
    "\n",
    "        return transformer_output, gnn_output, neuro_symbolic_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c76539d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:03.916118Z",
     "iopub.status.busy": "2024-08-03T20:34:03.915431Z",
     "iopub.status.idle": "2024-08-03T20:34:03.926118Z",
     "shell.execute_reply": "2024-08-03T20:34:03.924677Z"
    },
    "papermill": {
     "duration": 0.022509,
     "end_time": "2024-08-03T20:34:03.929395",
     "exception": false,
     "start_time": "2024-08-03T20:34:03.906886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Yambi (which means \"Welcome\" in kikongo) Model\n",
    "class Yambi(nn.Module):\n",
    "    \"\"\"A model that combines TransformerModel, GNNModel, and NeuroSymbolicModel to process and integrate different types of data.\"\"\"\n",
    "\n",
    "    def __init__(self, transformer_model, gnn_model, neuro_symbolic_model):\n",
    "        super(Yambi, self).__init__()\n",
    "        self.hybrid_model = HybridModel(transformer_model, gnn_model, neuro_symbolic_model)\n",
    "        self.optimizer = EvolutionaryOptimizer(self, population_size=10, generations=5, mutation_rate=0.01)\n",
    "\n",
    "    def forward(self, src, tgt, graph_data):\n",
    "        \"\"\"Process input data through the hybrid model.\"\"\"\n",
    "        return self.hybrid_model(src, tgt, graph_data)\n",
    "\n",
    "    def optimize(self, X_train, y_train):\n",
    "        \"\"\"Optimize model parameters using evolutionary algorithms.\"\"\"\n",
    "        self.optimizer.optimize(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd33d913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:03.945041Z",
     "iopub.status.busy": "2024-08-03T20:34:03.944529Z",
     "iopub.status.idle": "2024-08-03T20:34:03.953230Z",
     "shell.execute_reply": "2024-08-03T20:34:03.951660Z"
    },
    "papermill": {
     "duration": 0.020313,
     "end_time": "2024-08-03T20:34:03.956489",
     "exception": false,
     "start_time": "2024-08-03T20:34:03.936176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define Symbolic Rules\n",
    "def rule_example1(output_grid, input_grid):\n",
    "    \"\"\"An example rule that fills the output grid with the mean value of the input grid.\"\"\"\n",
    "    mean_value = np.mean(input_grid)\n",
    "    output_grid[:] = mean_value\n",
    "    return output_grid\n",
    "\n",
    "def rule_example2(output_grid, input_grid):\n",
    "    \"\"\"An example rule that sets the output grid to be the square of the input grid.\"\"\"\n",
    "    output_grid[:] = np.square(input_grid)\n",
    "    return output_grid\n",
    "\n",
    "rules = [\n",
    "    Rule(rule_func=rule_example1),\n",
    "    Rule(rule_func=rule_example2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80bb0bbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:03.972988Z",
     "iopub.status.busy": "2024-08-03T20:34:03.972503Z",
     "iopub.status.idle": "2024-08-03T20:34:04.103261Z",
     "shell.execute_reply": "2024-08-03T20:34:04.100964Z"
    },
    "papermill": {
     "duration": 0.143059,
     "end_time": "2024-08-03T20:34:04.106543",
     "exception": false,
     "start_time": "2024-08-03T20:34:03.963484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#instantiate SymbolicRuleModel with Rules\n",
    "neuro_symbolic_model = SymbolicRuleModel(rules=rules)\n",
    "\n",
    "#instantiate the Yambi model\n",
    "transformer_model = TransformerModel(input_dim=100, model_dim=64, num_heads=8, num_layers=4, output_dim=30)\n",
    "gnn_model = GNNModel(input_dim=100, hidden_dim=64, output_dim=30)\n",
    "\n",
    "yambi_model = Yambi(transformer_model, gnn_model, neuro_symbolic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08746827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:04.124402Z",
     "iopub.status.busy": "2024-08-03T20:34:04.122917Z",
     "iopub.status.idle": "2024-08-03T20:34:04.152273Z",
     "shell.execute_reply": "2024-08-03T20:34:04.150699Z"
    },
    "papermill": {
     "duration": 0.041933,
     "end_time": "2024-08-03T20:34:04.155665",
     "exception": false,
     "start_time": "2024-08-03T20:34:04.113732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#convert the data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_loaded, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_loaded, dtype=torch.float32)\n",
    "\n",
    "#create a TensorDataset and DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f930427",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-03T20:34:04.172430Z",
     "iopub.status.busy": "2024-08-03T20:34:04.171939Z",
     "iopub.status.idle": "2024-08-03T20:34:05.910506Z",
     "shell.execute_reply": "2024-08-03T20:34:05.909077Z"
    },
    "papermill": {
     "duration": 1.750708,
     "end_time": "2024-08-03T20:34:05.913665",
     "exception": false,
     "start_time": "2024-08-03T20:34:04.162957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#define the loss function and optimizer\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = optim.Adam(yambi_model.parameters(), lr=0.001)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13.222727,
   "end_time": "2024-08-03T20:34:07.548273",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-03T20:33:54.325546",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
