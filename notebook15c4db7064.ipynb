{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91b5808e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:45.330072Z",
     "iopub.status.busy": "2024-07-13T13:01:45.329648Z",
     "iopub.status.idle": "2024-07-13T13:01:46.436021Z",
     "shell.execute_reply": "2024-07-13T13:01:46.434768Z"
    },
    "papermill": {
     "duration": 1.118471,
     "end_time": "2024-07-13T13:01:46.439546",
     "exception": false,
     "start_time": "2024-07-13T13:01:45.321075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2024/sample_submission.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6813547a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:46.461486Z",
     "iopub.status.busy": "2024-07-13T13:01:46.460491Z",
     "iopub.status.idle": "2024-07-13T13:01:46.854676Z",
     "shell.execute_reply": "2024-07-13T13:01:46.853479Z"
    },
    "papermill": {
     "duration": 0.408561,
     "end_time": "2024-07-13T13:01:46.858264",
     "exception": false,
     "start_time": "2024-07-13T13:01:46.449703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "evaluation_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
    "evaluation_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "sample_submission_path = '/kaggle/input/arc-prize-2024/sample_submission.json'\n",
    "training_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "test_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "\n",
    "#function to load JSON data\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "#load each dataset\n",
    "training_solutions = load_json_data(training_solutions_path)\n",
    "evaluation_solutions = load_json_data(evaluation_solutions_path)\n",
    "evaluation_challenges = load_json_data(evaluation_challenges_path)\n",
    "sample_submission = load_json_data(sample_submission_path)\n",
    "training_challenges = load_json_data(training_challenges_path)\n",
    "test_challenges = load_json_data(test_challenges_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93947f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:46.876827Z",
     "iopub.status.busy": "2024-07-13T13:01:46.876308Z",
     "iopub.status.idle": "2024-07-13T13:01:46.890103Z",
     "shell.execute_reply": "2024-07-13T13:01:46.888832Z"
    },
    "papermill": {
     "duration": 0.026159,
     "end_time": "2024-07-13T13:01:46.893871",
     "exception": false,
     "start_time": "2024-07-13T13:01:46.867712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Training Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
      "\n",
      "\n",
      "Inspecting Sample Submission:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': [{'attempt_1': [[0, 0], [0, 0]], 'attempt_2': [[0, 0], [0, 0]]}]\n",
      "\n",
      "\n",
      "Inspecting Training Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n",
      "Inspecting Test Challenges:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inspect the structure of the data\n",
    "def inspect_data(data, name):\n",
    "    print(f\"Inspecting {name}:\")\n",
    "    if isinstance(data, list):\n",
    "        print(f\"Number of items: {len(data)}\")\n",
    "        if len(data) > 0:\n",
    "            print(f\"Example item: {data[0]}\")\n",
    "    elif isinstance(data, dict):\n",
    "        print(f\"Number of keys: {len(data.keys())}\")\n",
    "        if len(data.keys()) > 0:\n",
    "            first_key = list(data.keys())[0]\n",
    "            print(f\"Example item under key '{first_key}': {data[first_key]}\")\n",
    "    else:\n",
    "        print(\"Unknown data type\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "inspect_data(training_solutions, \"Training Solutions\")\n",
    "inspect_data(evaluation_solutions, \"Evaluation Solutions\")\n",
    "inspect_data(evaluation_challenges, \"Evaluation Challenges\")\n",
    "inspect_data(sample_submission, \"Sample Submission\")\n",
    "inspect_data(training_challenges, \"Training Challenges\")\n",
    "inspect_data(test_challenges, \"Test Challenges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "244fad28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:46.910241Z",
     "iopub.status.busy": "2024-07-13T13:01:46.908895Z",
     "iopub.status.idle": "2024-07-13T13:01:46.928762Z",
     "shell.execute_reply": "2024-07-13T13:01:46.927431Z"
    },
    "papermill": {
     "duration": 0.030647,
     "end_time": "2024-07-13T13:01:46.931345",
     "exception": false,
     "start_time": "2024-07-13T13:01:46.900698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input size: 30x30, Max output size: 30x30\n"
     ]
    }
   ],
   "source": [
    "def get_max_grid_size(challenges, solutions):\n",
    "    max_input_height, max_input_width = 0, 0\n",
    "    max_output_height, max_output_width = 0, 0\n",
    "    \n",
    "    for key in challenges.keys():\n",
    "        challenge = challenges[key]\n",
    "        for example in challenge['train']:\n",
    "            input_grid = example['input']\n",
    "            output_grid = example['output']\n",
    "            max_input_height = max(max_input_height, len(input_grid))\n",
    "            max_input_width = max(max_input_width, len(input_grid[0]))\n",
    "            max_output_height = max(max_output_height, len(output_grid))\n",
    "            max_output_width = max(max_output_width, len(output_grid[0]))\n",
    "        for test_case in challenge['test']:\n",
    "            test_input = test_case['input']\n",
    "            max_input_height = max(max_input_height, len(test_input))\n",
    "            max_input_width = max(max_input_width, len(test_input[0]))\n",
    "            #assuming test_output size can be derived similarly\n",
    "\n",
    "    return max_input_height, max_input_width, max_output_height, max_output_width\n",
    "\n",
    "max_input_height, max_input_width, max_output_height, max_output_width = get_max_grid_size(training_challenges, training_solutions)\n",
    "print(f\"Max input size: {max_input_height}x{max_input_width}, Max output size: {max_output_height}x{max_output_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32930ac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:46.948299Z",
     "iopub.status.busy": "2024-07-13T13:01:46.947822Z",
     "iopub.status.idle": "2024-07-13T13:01:52.984242Z",
     "shell.execute_reply": "2024-07-13T13:01:52.982955Z"
    },
    "papermill": {
     "duration": 6.048436,
     "end_time": "2024-07-13T13:01:52.987154",
     "exception": false,
     "start_time": "2024-07-13T13:01:46.938718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class ARCDataset(Dataset):\n",
    "    def __init__(self, challenges, solutions, max_size, transform=None):\n",
    "        self.data = []\n",
    "        self.max_size = max_size\n",
    "        self.transform = transform\n",
    "        for key in challenges.keys():\n",
    "            challenge = challenges[key]\n",
    "            solution = solutions[key]\n",
    "            for example in challenge['train']:\n",
    "                input_grid = example['input']\n",
    "                output_grid = example['output']\n",
    "                self.data.append((input_grid, output_grid))\n",
    "            for test_case in challenge['test']:\n",
    "                test_input = test_case['input']\n",
    "                #use the corresponding solution as the target output\n",
    "                test_output = solution[len(self.data) % len(solution)]\n",
    "                self.data.append((test_input, test_output))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def pad_grid(self, grid):\n",
    "        padded_grid = np.zeros(self.max_size)\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                padded_grid[i][j] = grid[i][j]\n",
    "        return padded_grid\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_grid, output_grid = self.data[idx]\n",
    "        input_grid = self.pad_grid(input_grid)\n",
    "        output_grid = self.pad_grid(output_grid)\n",
    "        input_grid = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        output_grid = torch.tensor(output_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        if self.transform:\n",
    "            input_grid = self.transform(input_grid)\n",
    "            output_grid = self.transform(output_grid)\n",
    "        return input_grid, output_grid\n",
    "\n",
    "#define the maximum size\n",
    "max_size = (30, 30)\n",
    "\n",
    "#create datasets with padding\n",
    "transform = transforms.Compose([transforms.Lambda(lambda x: x)])  #no additional transform needed\n",
    "training_dataset = ARCDataset(training_challenges, training_solutions, max_size, transform=transform)\n",
    "evaluation_dataset = ARCDataset(evaluation_challenges, evaluation_solutions, max_size, transform=transform)\n",
    "\n",
    "#create dataloaders\n",
    "training_loader = DataLoader(training_dataset, batch_size=1, shuffle=True)\n",
    "evaluation_loader = DataLoader(evaluation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1a11c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.003030Z",
     "iopub.status.busy": "2024-07-13T13:01:53.002441Z",
     "iopub.status.idle": "2024-07-13T13:01:53.097415Z",
     "shell.execute_reply": "2024-07-13T13:01:53.096358Z"
    },
    "papermill": {
     "duration": 0.105964,
     "end_time": "2024-07-13T13:01:53.100135",
     "exception": false,
     "start_time": "2024-07-13T13:01:52.994171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#perception module\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class PerceptionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptionModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "#instantiate and test the module\n",
    "perception_model = PerceptionModule()\n",
    "inputs = torch.randn(1, 1, 8, 8)\n",
    "outputs = perception_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "596bd452",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.117456Z",
     "iopub.status.busy": "2024-07-13T13:01:53.117022Z",
     "iopub.status.idle": "2024-07-13T13:01:53.277913Z",
     "shell.execute_reply": "2024-07-13T13:01:53.276771Z"
    },
    "papermill": {
     "duration": 0.172908,
     "end_time": "2024-07-13T13:01:53.280868",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.107960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#memory module\n",
    "class MemoryModule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(MemoryModule, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        #LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        #fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #reshape x to (batch_size, seq_len, features)\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, height * width, channels)  #(batch_size, seq_len, features)\n",
    "        \n",
    "        #LSTM input: (batch_size, seq_len, input_size)\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        #take the last time step's output\n",
    "        x = self.fc(x[:, -1, :])  #(batch_size, output_size)\n",
    "        \n",
    "        return x\n",
    "\n",
    "memory_module = MemoryModule(input_size=32, hidden_size=64, num_layers=1, output_size=30*30)\n",
    "inputs = torch.randn(1, 32, 4, 4)\n",
    "outputs = memory_module(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be80ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.297021Z",
     "iopub.status.busy": "2024-07-13T13:01:53.296639Z",
     "iopub.status.idle": "2024-07-13T13:01:53.307618Z",
     "shell.execute_reply": "2024-07-13T13:01:53.306635Z"
    },
    "papermill": {
     "duration": 0.022256,
     "end_time": "2024-07-13T13:01:53.310117",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.287861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creativity module\n",
    "class CreativityModule(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CreativityModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "creativity_model = CreativityModule(input_size=128)\n",
    "inputs = torch.randn(1, 128) \n",
    "outputs = creativity_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6be9abda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.325825Z",
     "iopub.status.busy": "2024-07-13T13:01:53.325378Z",
     "iopub.status.idle": "2024-07-13T13:01:53.333497Z",
     "shell.execute_reply": "2024-07-13T13:01:53.332335Z"
    },
    "papermill": {
     "duration": 0.01896,
     "end_time": "2024-07-13T13:01:53.335997",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.317037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reasoning module\n",
    "class ReasoningModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReasoningModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 30 * 30)  #output grid size is 30x30\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 30, 30)  #reshape to match output grid size\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8714ef06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.351743Z",
     "iopub.status.busy": "2024-07-13T13:01:53.351350Z",
     "iopub.status.idle": "2024-07-13T13:01:53.359013Z",
     "shell.execute_reply": "2024-07-13T13:01:53.357762Z"
    },
    "papermill": {
     "duration": 0.018686,
     "end_time": "2024-07-13T13:01:53.361696",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.343010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compassionate module\n",
    "class CompassionateModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CompassionateModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(30*30, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59573fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.377343Z",
     "iopub.status.busy": "2024-07-13T13:01:53.376953Z",
     "iopub.status.idle": "2024-07-13T13:01:53.387464Z",
     "shell.execute_reply": "2024-07-13T13:01:53.386237Z"
    },
    "papermill": {
     "duration": 0.02159,
     "end_time": "2024-07-13T13:01:53.390235",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.368645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combine the modules above into the Yambi Model\n",
    "class Yambi(nn.Module):\n",
    "    \"\"\"\n",
    "    Yambi is an AI model designed to solve abstract reasoning tasks by integrating various cognitive abilities. \n",
    "    It consists of five main modules:\n",
    "    \n",
    "    1. Perception Module: Processes and understands input grids using convolutional neural networks.\n",
    "    2. Memory Module: Stores and recalls information about previously seen tasks using LSTM networks.\n",
    "    3. Creativity Module: Generates creative solutions and explores novel approaches using a latent space.\n",
    "    4. Reasoning Module: Applies logical reasoning to infer solutions based on perceived information.\n",
    "    5. Compassionate Module: Analyzes emotional context and adjusts responses accordingly.\n",
    "\n",
    "    These modules work together to perceive, remember, create, reason, and empathize, aiming to solve abstract reasoning tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, perception_model, memory_model, creativity_model, reasoning_model, compassionate_model):\n",
    "        super(Yambi, self).__init__()\n",
    "        self.perception_model = perception_model\n",
    "        self.memory_model = memory_model\n",
    "        self.creativity_model = creativity_model\n",
    "        self.reasoning_model = reasoning_model\n",
    "        self.compassionate_model = compassionate_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Perception Module\n",
    "        perception_output = self.perception_model(x)\n",
    "\n",
    "        #Memory Module\n",
    "        memory_output = self.memory_model(perception_output)\n",
    "\n",
    "        #Creativity Module\n",
    "        creativity_output = self.creativity_model(memory_output)\n",
    "\n",
    "        #Reasoning Module\n",
    "        reasoning_output = self.reasoning_model(creativity_output)\n",
    "\n",
    "        #Compassionate Module\n",
    "        compassionate_output = self.compassionate_model(reasoning_output)\n",
    "\n",
    "        return reasoning_output, compassionate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8525ebf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.405786Z",
     "iopub.status.busy": "2024-07-13T13:01:53.405366Z",
     "iopub.status.idle": "2024-07-13T13:01:53.411429Z",
     "shell.execute_reply": "2024-07-13T13:01:53.410137Z"
    },
    "papermill": {
     "duration": 0.017064,
     "end_time": "2024-07-13T13:01:53.414194",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.397130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bfa64b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.429951Z",
     "iopub.status.busy": "2024-07-13T13:01:53.429525Z",
     "iopub.status.idle": "2024-07-13T13:01:53.451525Z",
     "shell.execute_reply": "2024-07-13T13:01:53.450453Z"
    },
    "papermill": {
     "duration": 0.033186,
     "end_time": "2024-07-13T13:01:53.454339",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.421153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#instantiate Perception Module\n",
    "perception_model = PerceptionModule()\n",
    "\n",
    "#instantiate Memory Module with appropriate input_size based on Perception Module output\n",
    "perception_output_size = 32\n",
    "memory_model = MemoryModule(input_size=perception_output_size, hidden_size=128, num_layers=1, output_size=10)\n",
    "\n",
    "#instantiate Creativity Module with appropriate input_size based on Memory Module output\n",
    "creativity_input_size = 10 \n",
    "creativity_model = CreativityModule(input_size=creativity_input_size)\n",
    "\n",
    "#instantiate Reasoning Module\n",
    "reasoning_model = ReasoningModule()\n",
    "\n",
    "#instantiate Compassionate Module\n",
    "compassionate_model = CompassionateModule()\n",
    "\n",
    "#instantiate the Yambi model\n",
    "yambi_model = Yambi(perception_model, memory_model, creativity_model, reasoning_model, compassionate_model).to(device)\n",
    "\n",
    "#test the Yambi model with dummy input to check the flow and shape\n",
    "dummy_input = torch.randn(1, 1, 6, 7).to(device)\n",
    "output_reasoning, output_compassionate = yambi_model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62628955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.471056Z",
     "iopub.status.busy": "2024-07-13T13:01:53.470629Z",
     "iopub.status.idle": "2024-07-13T13:01:53.475661Z",
     "shell.execute_reply": "2024-07-13T13:01:53.474482Z"
    },
    "papermill": {
     "duration": 0.015945,
     "end_time": "2024-07-13T13:01:53.478017",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.462072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5b49d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:01:53.493348Z",
     "iopub.status.busy": "2024-07-13T13:01:53.492935Z",
     "iopub.status.idle": "2024-07-13T13:13:57.748121Z",
     "shell.execute_reply": "2024-07-13T13:13:57.746948Z"
    },
    "papermill": {
     "duration": 724.26591,
     "end_time": "2024-07-13T13:13:57.750682",
     "exception": false,
     "start_time": "2024-07-13T13:01:53.484772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 23.22827790195298\n",
      "Epoch [2/30], Loss: 21.127534937126534\n",
      "Epoch [3/30], Loss: 20.592264998699857\n",
      "Epoch [4/30], Loss: 20.43893636666169\n",
      "Epoch [5/30], Loss: 20.36795857850987\n",
      "Epoch [6/30], Loss: 20.325896390339704\n",
      "Epoch [7/30], Loss: 20.29301555284079\n",
      "Epoch [8/30], Loss: 20.260717333267348\n",
      "Epoch [9/30], Loss: 20.233371241733742\n",
      "Epoch [10/30], Loss: 20.203766885542066\n",
      "Epoch [11/30], Loss: 20.16666042998572\n",
      "Epoch [12/30], Loss: 20.143667442268747\n",
      "Epoch [13/30], Loss: 20.121581258130835\n",
      "Epoch [14/30], Loss: 20.107264555708806\n",
      "Epoch [15/30], Loss: 20.097204805907985\n",
      "Epoch [16/30], Loss: 20.083505067939633\n",
      "Epoch [17/30], Loss: 20.074498046822715\n",
      "Epoch [18/30], Loss: 20.06775835139744\n",
      "Epoch [19/30], Loss: 20.054122216912795\n",
      "Epoch [20/30], Loss: 20.035099843521284\n",
      "Epoch [21/30], Loss: 20.039191389170163\n",
      "Epoch [22/30], Loss: 20.02384718035687\n",
      "Epoch [23/30], Loss: 20.02839695344808\n",
      "Epoch [24/30], Loss: 20.010518088054273\n",
      "Epoch [25/30], Loss: 20.006338095554824\n",
      "Epoch [26/30], Loss: 20.004404152529933\n",
      "Epoch [27/30], Loss: 19.997950047063743\n",
      "Epoch [28/30], Loss: 19.986811872274636\n",
      "Epoch [29/30], Loss: 19.992538478615778\n",
      "Epoch [30/30], Loss: 19.97602374743935\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#number of epochs for training\n",
    "num_epochs = 30\n",
    "\n",
    "#define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(yambi_model.parameters(), lr=0.00001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  #reduce LR by 0.1 every 10 epochs\n",
    "\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    #iterate over the data in the training loader\n",
    "    for inputs, labels in training_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass\n",
    "        reasoning_output, compassionate_output = yambi_model(inputs)\n",
    "        \n",
    "        #squeeze the labels to remove the extra dimension if needed\n",
    "        labels = labels.squeeze(1)\n",
    "        \n",
    "        #compute the CrossEntropyLoss\n",
    "        loss = criterion(reasoning_output, labels)\n",
    "        \n",
    "        #backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    #print the average loss for the epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(training_loader)}\")\n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11d0b894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T13:13:57.771874Z",
     "iopub.status.busy": "2024-07-13T13:13:57.771432Z",
     "iopub.status.idle": "2024-07-13T13:14:06.188419Z",
     "shell.execute_reply": "2024-07-13T13:14:06.187221Z"
    },
    "papermill": {
     "duration": 8.430994,
     "end_time": "2024-07-13T13:14:06.191453",
     "exception": false,
     "start_time": "2024-07-13T13:13:57.760459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARC Score: 4.91%\n"
     ]
    }
   ],
   "source": [
    "#evaluate the Yambi model and calculate the ARC score\n",
    "def calculate_arc_score(model, evaluation_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in evaluation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            reasoning_output, compassionate_output = model(inputs)\n",
    "            predicted_output = torch.argmax(reasoning_output, dim=1)\n",
    "            labels = labels.squeeze(1)\n",
    "            \n",
    "            correct += (predicted_output == labels).sum().item()\n",
    "            total += labels.numel()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "#evaluate the model on the evaluation dataset\n",
    "arc_score = calculate_arc_score(yambi_model, evaluation_loader, device)\n",
    "print(f'ARC Score: {arc_score * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 745.353256,
   "end_time": "2024-07-13T13:14:07.428468",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-13T13:01:42.075212",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
