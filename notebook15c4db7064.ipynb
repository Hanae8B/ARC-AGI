{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10ac51ee",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:19.525306Z",
     "iopub.status.busy": "2024-07-13T15:25:19.524852Z",
     "iopub.status.idle": "2024-07-13T15:25:20.364364Z",
     "shell.execute_reply": "2024-07-13T15:25:20.362876Z"
    },
    "papermill": {
     "duration": 0.849122,
     "end_time": "2024-07-13T15:25:20.367101",
     "exception": false,
     "start_time": "2024-07-13T15:25:19.517979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2024/sample_submission.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda1d826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:20.379201Z",
     "iopub.status.busy": "2024-07-13T15:25:20.378691Z",
     "iopub.status.idle": "2024-07-13T15:25:20.695074Z",
     "shell.execute_reply": "2024-07-13T15:25:20.694018Z"
    },
    "papermill": {
     "duration": 0.325218,
     "end_time": "2024-07-13T15:25:20.697571",
     "exception": false,
     "start_time": "2024-07-13T15:25:20.372353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "evaluation_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
    "evaluation_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "sample_submission_path = '/kaggle/input/arc-prize-2024/sample_submission.json'\n",
    "training_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "test_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "\n",
    "#function to load JSON data\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "#load each dataset\n",
    "training_solutions = load_json_data(training_solutions_path)\n",
    "evaluation_solutions = load_json_data(evaluation_solutions_path)\n",
    "evaluation_challenges = load_json_data(evaluation_challenges_path)\n",
    "sample_submission = load_json_data(sample_submission_path)\n",
    "training_challenges = load_json_data(training_challenges_path)\n",
    "test_challenges = load_json_data(test_challenges_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3852def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:20.708969Z",
     "iopub.status.busy": "2024-07-13T15:25:20.708596Z",
     "iopub.status.idle": "2024-07-13T15:25:20.717745Z",
     "shell.execute_reply": "2024-07-13T15:25:20.716725Z"
    },
    "papermill": {
     "duration": 0.017995,
     "end_time": "2024-07-13T15:25:20.720440",
     "exception": false,
     "start_time": "2024-07-13T15:25:20.702445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Training Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
      "\n",
      "\n",
      "Inspecting Sample Submission:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': [{'attempt_1': [[0, 0], [0, 0]], 'attempt_2': [[0, 0], [0, 0]]}]\n",
      "\n",
      "\n",
      "Inspecting Training Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n",
      "Inspecting Test Challenges:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inspect the structure of the data\n",
    "def inspect_data(data, name):\n",
    "    print(f\"Inspecting {name}:\")\n",
    "    if isinstance(data, list):\n",
    "        print(f\"Number of items: {len(data)}\")\n",
    "        if len(data) > 0:\n",
    "            print(f\"Example item: {data[0]}\")\n",
    "    elif isinstance(data, dict):\n",
    "        print(f\"Number of keys: {len(data.keys())}\")\n",
    "        if len(data.keys()) > 0:\n",
    "            first_key = list(data.keys())[0]\n",
    "            print(f\"Example item under key '{first_key}': {data[first_key]}\")\n",
    "    else:\n",
    "        print(\"Unknown data type\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "inspect_data(training_solutions, \"Training Solutions\")\n",
    "inspect_data(evaluation_solutions, \"Evaluation Solutions\")\n",
    "inspect_data(evaluation_challenges, \"Evaluation Challenges\")\n",
    "inspect_data(sample_submission, \"Sample Submission\")\n",
    "inspect_data(training_challenges, \"Training Challenges\")\n",
    "inspect_data(test_challenges, \"Test Challenges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22b35e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:20.732046Z",
     "iopub.status.busy": "2024-07-13T15:25:20.731693Z",
     "iopub.status.idle": "2024-07-13T15:25:20.743970Z",
     "shell.execute_reply": "2024-07-13T15:25:20.742673Z"
    },
    "papermill": {
     "duration": 0.020551,
     "end_time": "2024-07-13T15:25:20.746061",
     "exception": false,
     "start_time": "2024-07-13T15:25:20.725510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input size: 30x30, Max output size: 30x30\n"
     ]
    }
   ],
   "source": [
    "def get_max_grid_size(challenges, solutions):\n",
    "    max_input_height, max_input_width = 0, 0\n",
    "    max_output_height, max_output_width = 0, 0\n",
    "    \n",
    "    for key in challenges.keys():\n",
    "        challenge = challenges[key]\n",
    "        for example in challenge['train']:\n",
    "            input_grid = example['input']\n",
    "            output_grid = example['output']\n",
    "            max_input_height = max(max_input_height, len(input_grid))\n",
    "            max_input_width = max(max_input_width, len(input_grid[0]))\n",
    "            max_output_height = max(max_output_height, len(output_grid))\n",
    "            max_output_width = max(max_output_width, len(output_grid[0]))\n",
    "        for test_case in challenge['test']:\n",
    "            test_input = test_case['input']\n",
    "            max_input_height = max(max_input_height, len(test_input))\n",
    "            max_input_width = max(max_input_width, len(test_input[0]))\n",
    "            #assuming test_output size can be derived similarly\n",
    "\n",
    "    return max_input_height, max_input_width, max_output_height, max_output_width\n",
    "\n",
    "max_input_height, max_input_width, max_output_height, max_output_width = get_max_grid_size(training_challenges, training_solutions)\n",
    "print(f\"Max input size: {max_input_height}x{max_input_width}, Max output size: {max_output_height}x{max_output_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bea58d7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:20.757810Z",
     "iopub.status.busy": "2024-07-13T15:25:20.757448Z",
     "iopub.status.idle": "2024-07-13T15:25:25.877628Z",
     "shell.execute_reply": "2024-07-13T15:25:25.876268Z"
    },
    "papermill": {
     "duration": 5.130224,
     "end_time": "2024-07-13T15:25:25.881292",
     "exception": false,
     "start_time": "2024-07-13T15:25:20.751068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class ARCDataset(Dataset):\n",
    "    def __init__(self, challenges, solutions, max_size, transform=None):\n",
    "        self.data = []\n",
    "        self.max_size = max_size\n",
    "        self.transform = transform\n",
    "        for key in challenges.keys():\n",
    "            challenge = challenges[key]\n",
    "            solution = solutions[key]\n",
    "            for example in challenge['train']:\n",
    "                input_grid = example['input']\n",
    "                output_grid = example['output']\n",
    "                self.data.append((input_grid, output_grid))\n",
    "            for test_case in challenge['test']:\n",
    "                test_input = test_case['input']\n",
    "                #use the corresponding solution as the target output\n",
    "                test_output = solution[len(self.data) % len(solution)]\n",
    "                self.data.append((test_input, test_output))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def pad_grid(self, grid):\n",
    "        padded_grid = np.zeros(self.max_size)\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                padded_grid[i][j] = grid[i][j]\n",
    "        return padded_grid\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_grid, output_grid = self.data[idx]\n",
    "        input_grid = self.pad_grid(input_grid)\n",
    "        output_grid = self.pad_grid(output_grid)\n",
    "        input_grid = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        output_grid = torch.tensor(output_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        if self.transform:\n",
    "            input_grid = self.transform(input_grid)\n",
    "            output_grid = self.transform(output_grid)\n",
    "        return input_grid, output_grid\n",
    "\n",
    "#define the maximum size\n",
    "max_size = (30, 30)\n",
    "\n",
    "#create datasets with padding\n",
    "transform = transforms.Compose([transforms.Lambda(lambda x: x)])  #no additional transform needed\n",
    "training_dataset = ARCDataset(training_challenges, training_solutions, max_size, transform=transform)\n",
    "evaluation_dataset = ARCDataset(evaluation_challenges, evaluation_solutions, max_size, transform=transform)\n",
    "\n",
    "#create dataloaders\n",
    "training_loader = DataLoader(training_dataset, batch_size=1, shuffle=True)\n",
    "evaluation_loader = DataLoader(evaluation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90b788db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:25.895078Z",
     "iopub.status.busy": "2024-07-13T15:25:25.894201Z",
     "iopub.status.idle": "2024-07-13T15:25:25.902329Z",
     "shell.execute_reply": "2024-07-13T15:25:25.901256Z"
    },
    "papermill": {
     "duration": 0.016956,
     "end_time": "2024-07-13T15:25:25.904557",
     "exception": false,
     "start_time": "2024-07-13T15:25:25.887601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#perception module\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class PerceptionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptionModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a007730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:25.917294Z",
     "iopub.status.busy": "2024-07-13T15:25:25.916532Z",
     "iopub.status.idle": "2024-07-13T15:25:25.926033Z",
     "shell.execute_reply": "2024-07-13T15:25:25.925000Z"
    },
    "papermill": {
     "duration": 0.018611,
     "end_time": "2024-07-13T15:25:25.928393",
     "exception": false,
     "start_time": "2024-07-13T15:25:25.909782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#memory module\n",
    "class MemoryModule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(MemoryModule, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        #LSTM layer without dropout\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        #fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        x = x.view(batch_size, height * width, channels)\n",
    "        \n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  #take the last time step's output\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a20b12f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:25.940502Z",
     "iopub.status.busy": "2024-07-13T15:25:25.940055Z",
     "iopub.status.idle": "2024-07-13T15:25:25.948828Z",
     "shell.execute_reply": "2024-07-13T15:25:25.947279Z"
    },
    "papermill": {
     "duration": 0.017582,
     "end_time": "2024-07-13T15:25:25.951139",
     "exception": false,
     "start_time": "2024-07-13T15:25:25.933557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creativity module\n",
    "class CreativityModule(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CreativityModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)  #increase to 256\n",
    "        self.fc2 = nn.Linear(256, 128)  #adjust to 128\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c9f5f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:25.963416Z",
     "iopub.status.busy": "2024-07-13T15:25:25.962623Z",
     "iopub.status.idle": "2024-07-13T15:25:25.969536Z",
     "shell.execute_reply": "2024-07-13T15:25:25.968484Z"
    },
    "papermill": {
     "duration": 0.015468,
     "end_time": "2024-07-13T15:25:25.971750",
     "exception": false,
     "start_time": "2024-07-13T15:25:25.956282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reasoning module\n",
    "class ReasoningModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReasoningModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(128, 256)  #increase to 256\n",
    "        self.fc2 = nn.Linear(256, 128)  #adjust to 128\n",
    "        self.fc3 = nn.Linear(128, 30 * 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = x.view(-1, 30, 30)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b3140a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:25.983822Z",
     "iopub.status.busy": "2024-07-13T15:25:25.982910Z",
     "iopub.status.idle": "2024-07-13T15:25:25.990123Z",
     "shell.execute_reply": "2024-07-13T15:25:25.989097Z"
    },
    "papermill": {
     "duration": 0.015576,
     "end_time": "2024-07-13T15:25:25.992335",
     "exception": false,
     "start_time": "2024-07-13T15:25:25.976759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compassionate module\n",
    "class CompassionateModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CompassionateModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(30 * 30, 128)  #increase to 128\n",
    "        self.fc2 = nn.Linear(128, 64)  #adjust to 64\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c8460df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:26.004121Z",
     "iopub.status.busy": "2024-07-13T15:25:26.003688Z",
     "iopub.status.idle": "2024-07-13T15:25:26.011635Z",
     "shell.execute_reply": "2024-07-13T15:25:26.010625Z"
    },
    "papermill": {
     "duration": 0.016384,
     "end_time": "2024-07-13T15:25:26.013687",
     "exception": false,
     "start_time": "2024-07-13T15:25:25.997303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#combine the modules above into the Yambi Model\n",
    "class Yambi(nn.Module):\n",
    "    \"\"\"\n",
    "    Yambi is an AI model designed to solve abstract reasoning tasks by integrating various cognitive abilities. \n",
    "    It consists of five main modules:\n",
    "    \n",
    "    1. Perception Module: Processes and understands input grids using convolutional neural networks.\n",
    "    2. Memory Module: Stores and recalls information about previously seen tasks using LSTM networks.\n",
    "    3. Creativity Module: Generates creative solutions and explores novel approaches using a latent space.\n",
    "    4. Reasoning Module: Applies logical reasoning to infer solutions based on perceived information.\n",
    "    5. Compassionate Module: Analyzes emotional context and adjusts responses accordingly.\n",
    "\n",
    "    These modules work together to perceive, remember, create, reason, and empathize, aiming to solve abstract reasoning tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, perception_model, memory_model, creativity_model, reasoning_model, compassionate_model):\n",
    "        super(Yambi, self).__init__()\n",
    "        self.perception_model = perception_model\n",
    "        self.memory_model = memory_model\n",
    "        self.creativity_model = creativity_model\n",
    "        self.reasoning_model = reasoning_model\n",
    "        self.compassionate_model = compassionate_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Perception Module\n",
    "        perception_output = self.perception_model(x)\n",
    "\n",
    "        #Memory Module\n",
    "        memory_output = self.memory_model(perception_output)\n",
    "\n",
    "        #Creativity Module\n",
    "        creativity_output = self.creativity_model(memory_output)\n",
    "\n",
    "        #Reasoning Module\n",
    "        reasoning_output = self.reasoning_model(creativity_output)\n",
    "\n",
    "        #Compassionate Module\n",
    "        compassionate_output = self.compassionate_model(reasoning_output)\n",
    "\n",
    "        return reasoning_output, compassionate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8e12424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:26.025481Z",
     "iopub.status.busy": "2024-07-13T15:25:26.024741Z",
     "iopub.status.idle": "2024-07-13T15:25:26.029557Z",
     "shell.execute_reply": "2024-07-13T15:25:26.028520Z"
    },
    "papermill": {
     "duration": 0.013029,
     "end_time": "2024-07-13T15:25:26.031721",
     "exception": false,
     "start_time": "2024-07-13T15:25:26.018692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1627c5b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:26.043721Z",
     "iopub.status.busy": "2024-07-13T15:25:26.042969Z",
     "iopub.status.idle": "2024-07-13T15:25:26.091202Z",
     "shell.execute_reply": "2024-07-13T15:25:26.090122Z"
    },
    "papermill": {
     "duration": 0.057108,
     "end_time": "2024-07-13T15:25:26.093805",
     "exception": false,
     "start_time": "2024-07-13T15:25:26.036697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#instantiate Perception Module\n",
    "perception_model = PerceptionModule()\n",
    "\n",
    "#instantiate Memory Module with appropriate input_size based on Perception Module output\n",
    "perception_output_size = 32\n",
    "memory_model = MemoryModule(input_size=perception_output_size, hidden_size=128, num_layers=1, output_size=10)\n",
    "\n",
    "#instantiate Creativity Module with appropriate input_size based on Memory Module output\n",
    "creativity_input_size = 10 \n",
    "creativity_model = CreativityModule(input_size=creativity_input_size)\n",
    "\n",
    "#instantiate Reasoning Module\n",
    "reasoning_model = ReasoningModule()\n",
    "\n",
    "#instantiate Compassionate Module\n",
    "compassionate_model = CompassionateModule()\n",
    "\n",
    "#instantiate the Yambi model\n",
    "yambi_model = Yambi(perception_model, memory_model, creativity_model, reasoning_model, compassionate_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298f80ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:26.105307Z",
     "iopub.status.busy": "2024-07-13T15:25:26.104914Z",
     "iopub.status.idle": "2024-07-13T15:25:26.109879Z",
     "shell.execute_reply": "2024-07-13T15:25:26.108719Z"
    },
    "papermill": {
     "duration": 0.013727,
     "end_time": "2024-07-13T15:25:26.112442",
     "exception": false,
     "start_time": "2024-07-13T15:25:26.098715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad8db9f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:25:26.124463Z",
     "iopub.status.busy": "2024-07-13T15:25:26.123970Z",
     "iopub.status.idle": "2024-07-13T15:43:55.542686Z",
     "shell.execute_reply": "2024-07-13T15:43:55.541548Z"
    },
    "papermill": {
     "duration": 1109.434863,
     "end_time": "2024-07-13T15:43:55.552396",
     "exception": false,
     "start_time": "2024-07-13T15:25:26.117533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 21.217687762859555\n",
      "Epoch [2/50], Loss: 20.481637644552222\n",
      "Epoch [3/50], Loss: 20.301732273076308\n",
      "Epoch [4/50], Loss: 20.214812884068202\n",
      "Epoch [5/50], Loss: 20.14843281682004\n",
      "Epoch [6/50], Loss: 20.09357298324069\n",
      "Epoch [7/50], Loss: 20.04167580659847\n",
      "Epoch [8/50], Loss: 19.995458468996482\n",
      "Epoch [9/50], Loss: 19.947621122334365\n",
      "Epoch [10/50], Loss: 19.917856230863453\n",
      "Epoch [11/50], Loss: 19.871445656108982\n",
      "Epoch [12/50], Loss: 19.835940143158517\n",
      "Epoch [13/50], Loss: 19.797684812757844\n",
      "Epoch [14/50], Loss: 19.741336046610726\n",
      "Epoch [15/50], Loss: 19.714370664241653\n",
      "Epoch [16/50], Loss: 19.653084645004416\n",
      "Epoch [17/50], Loss: 19.620469629092355\n",
      "Epoch [18/50], Loss: 19.569566426933143\n",
      "Epoch [19/50], Loss: 19.542717834201678\n",
      "Epoch [20/50], Loss: 19.506412388917333\n",
      "Epoch [21/50], Loss: 19.481253173109035\n",
      "Epoch [22/50], Loss: 19.469499631493207\n",
      "Epoch [23/50], Loss: 19.434601376789413\n",
      "Epoch [24/50], Loss: 19.42099199143517\n",
      "Epoch [25/50], Loss: 19.402840526557686\n",
      "Epoch [26/50], Loss: 19.393754056846774\n",
      "Epoch [27/50], Loss: 19.368922219064185\n",
      "Epoch [28/50], Loss: 19.338624350498925\n",
      "Epoch [29/50], Loss: 19.336327904143626\n",
      "Epoch [30/50], Loss: 19.3107405701225\n",
      "Epoch [31/50], Loss: 19.316147145000965\n",
      "Epoch [32/50], Loss: 19.298100724111595\n",
      "Epoch [33/50], Loss: 19.288921714607493\n",
      "Epoch [34/50], Loss: 19.259599404632873\n",
      "Epoch [35/50], Loss: 19.259718049161474\n",
      "Epoch [36/50], Loss: 19.248101449694065\n",
      "Epoch [37/50], Loss: 19.234921048641446\n",
      "Epoch [38/50], Loss: 19.224674869411135\n",
      "Epoch [39/50], Loss: 19.213724565810423\n",
      "Epoch [40/50], Loss: 19.19807389087333\n",
      "Epoch [41/50], Loss: 19.19740381857274\n",
      "Epoch [42/50], Loss: 19.17543058122299\n",
      "Epoch [43/50], Loss: 19.159652827949426\n",
      "Epoch [44/50], Loss: 19.16474345028487\n",
      "Epoch [45/50], Loss: 19.140896963595267\n",
      "Epoch [46/50], Loss: 19.129317293401126\n",
      "Epoch [47/50], Loss: 19.101318565751313\n",
      "Epoch [48/50], Loss: 19.11305949469211\n",
      "Epoch [49/50], Loss: 19.122509453380623\n",
      "Epoch [50/50], Loss: 19.0908970273836\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "#number of epochs for training\n",
    "num_epochs = 50\n",
    "\n",
    "#define the criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(yambi_model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  #reduce LR by 0.1 every 10 epochs\n",
    "\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    #iterate over the data in the training loader\n",
    "    for inputs, labels in training_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device).squeeze(1)  #ensure labels are of type torch.long\n",
    "        \n",
    "        #zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward pass\n",
    "        reasoning_output, compassionate_output = yambi_model(inputs)\n",
    "        \n",
    "        #convert reasoning_output to float type\n",
    "        reasoning_output = reasoning_output.float()\n",
    "        \n",
    "        #compute the CrossEntropyLoss\n",
    "        loss = criterion(reasoning_output, labels)\n",
    "        \n",
    "        #backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    #print the average loss for the epoch\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(training_loader)}\")\n",
    "\n",
    "print('Training complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "030efd5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-13T15:43:55.569929Z",
     "iopub.status.busy": "2024-07-13T15:43:55.569554Z",
     "iopub.status.idle": "2024-07-13T15:44:02.193390Z",
     "shell.execute_reply": "2024-07-13T15:44:02.192200Z"
    },
    "papermill": {
     "duration": 6.635325,
     "end_time": "2024-07-13T15:44:02.195679",
     "exception": false,
     "start_time": "2024-07-13T15:43:55.560354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARC Score: 3.23%\n"
     ]
    }
   ],
   "source": [
    "#evaluate the Yambi model and calculate the ARC score\n",
    "def calculate_arc_score(model, evaluation_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in evaluation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            reasoning_output, compassionate_output = model(inputs)\n",
    "            predicted_output = torch.argmax(reasoning_output, dim=1)\n",
    "            labels = labels.squeeze(1)\n",
    "            \n",
    "            correct += (predicted_output == labels).sum().item()\n",
    "            total += labels.numel()\n",
    "\n",
    "    return correct / total\n",
    "\n",
    "#evaluate the model on the evaluation dataset\n",
    "arc_score = calculate_arc_score(yambi_model, evaluation_loader, device)\n",
    "print(f'ARC Score: {arc_score * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1126.520392,
   "end_time": "2024-07-13T15:44:03.328279",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-13T15:25:16.807887",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
