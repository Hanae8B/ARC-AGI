{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f12e73b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:37.090946Z",
     "iopub.status.busy": "2024-07-31T22:10:37.090496Z",
     "iopub.status.idle": "2024-07-31T22:10:38.075415Z",
     "shell.execute_reply": "2024-07-31T22:10:38.073816Z"
    },
    "papermill": {
     "duration": 0.993773,
     "end_time": "2024-07-31T22:10:38.077946",
     "exception": false,
     "start_time": "2024-07-31T22:10:37.084173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2024/sample_submission.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdf0001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:38.088558Z",
     "iopub.status.busy": "2024-07-31T22:10:38.088025Z",
     "iopub.status.idle": "2024-07-31T22:10:38.399603Z",
     "shell.execute_reply": "2024-07-31T22:10:38.398350Z"
    },
    "papermill": {
     "duration": 0.319913,
     "end_time": "2024-07-31T22:10:38.402303",
     "exception": false,
     "start_time": "2024-07-31T22:10:38.082390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "evaluation_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
    "evaluation_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "sample_submission_path = '/kaggle/input/arc-prize-2024/sample_submission.json'\n",
    "training_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "test_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "\n",
    "#function to load JSON data\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "#load each dataset\n",
    "training_solutions = load_json_data(training_solutions_path)\n",
    "evaluation_solutions = load_json_data(evaluation_solutions_path)\n",
    "evaluation_challenges = load_json_data(evaluation_challenges_path)\n",
    "sample_submission = load_json_data(sample_submission_path)\n",
    "training_challenges = load_json_data(training_challenges_path)\n",
    "test_challenges = load_json_data(test_challenges_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e7ff5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:38.412561Z",
     "iopub.status.busy": "2024-07-31T22:10:38.412164Z",
     "iopub.status.idle": "2024-07-31T22:10:38.421467Z",
     "shell.execute_reply": "2024-07-31T22:10:38.420232Z"
    },
    "papermill": {
     "duration": 0.018164,
     "end_time": "2024-07-31T22:10:38.424745",
     "exception": false,
     "start_time": "2024-07-31T22:10:38.406581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Training Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
      "\n",
      "\n",
      "Inspecting Sample Submission:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': [{'attempt_1': [[0, 0], [0, 0]], 'attempt_2': [[0, 0], [0, 0]]}]\n",
      "\n",
      "\n",
      "Inspecting Training Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n",
      "Inspecting Test Challenges:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inspect the structure of the data\n",
    "def inspect_data(data, name):\n",
    "    print(f\"Inspecting {name}:\")\n",
    "    if isinstance(data, list):\n",
    "        print(f\"Number of items: {len(data)}\")\n",
    "        if len(data) > 0:\n",
    "            print(f\"Example item: {data[0]}\")\n",
    "    elif isinstance(data, dict):\n",
    "        print(f\"Number of keys: {len(data.keys())}\")\n",
    "        if len(data.keys()) > 0:\n",
    "            first_key = list(data.keys())[0]\n",
    "            print(f\"Example item under key '{first_key}': {data[first_key]}\")\n",
    "    else:\n",
    "        print(\"Unknown data type\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "inspect_data(training_solutions, \"Training Solutions\")\n",
    "inspect_data(evaluation_solutions, \"Evaluation Solutions\")\n",
    "inspect_data(evaluation_challenges, \"Evaluation Challenges\")\n",
    "inspect_data(sample_submission, \"Sample Submission\")\n",
    "inspect_data(training_challenges, \"Training Challenges\")\n",
    "inspect_data(test_challenges, \"Test Challenges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4703b56b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:38.435415Z",
     "iopub.status.busy": "2024-07-31T22:10:38.435054Z",
     "iopub.status.idle": "2024-07-31T22:10:38.448147Z",
     "shell.execute_reply": "2024-07-31T22:10:38.446975Z"
    },
    "papermill": {
     "duration": 0.021724,
     "end_time": "2024-07-31T22:10:38.450906",
     "exception": false,
     "start_time": "2024-07-31T22:10:38.429182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input size: 30x30, Max output size: 30x30\n"
     ]
    }
   ],
   "source": [
    "def get_max_grid_size(challenges, solutions):\n",
    "    max_input_height, max_input_width = 0, 0\n",
    "    max_output_height, max_output_width = 0, 0\n",
    "    \n",
    "    for key in challenges.keys():\n",
    "        challenge = challenges[key]\n",
    "        for example in challenge['train']:\n",
    "            input_grid = example['input']\n",
    "            output_grid = example['output']\n",
    "            max_input_height = max(max_input_height, len(input_grid))\n",
    "            max_input_width = max(max_input_width, len(input_grid[0]))\n",
    "            max_output_height = max(max_output_height, len(output_grid))\n",
    "            max_output_width = max(max_output_width, len(output_grid[0]))\n",
    "        for test_case in challenge['test']:\n",
    "            test_input = test_case['input']\n",
    "            max_input_height = max(max_input_height, len(test_input))\n",
    "            max_input_width = max(max_input_width, len(test_input[0]))\n",
    "            #assuming test_output size can be derived similarly\n",
    "\n",
    "    return max_input_height, max_input_width, max_output_height, max_output_width\n",
    "\n",
    "max_input_height, max_input_width, max_output_height, max_output_width = get_max_grid_size(training_challenges, training_solutions)\n",
    "print(f\"Max input size: {max_input_height}x{max_input_width}, Max output size: {max_output_height}x{max_output_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da9e1336",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:38.461742Z",
     "iopub.status.busy": "2024-07-31T22:10:38.461363Z",
     "iopub.status.idle": "2024-07-31T22:10:44.296878Z",
     "shell.execute_reply": "2024-07-31T22:10:44.295188Z"
    },
    "papermill": {
     "duration": 5.844246,
     "end_time": "2024-07-31T22:10:44.299552",
     "exception": false,
     "start_time": "2024-07-31T22:10:38.455306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class ARCDataset(Dataset):\n",
    "    def __init__(self, challenges, solutions, max_size, transform=None):\n",
    "        self.data = []\n",
    "        self.max_size = max_size\n",
    "        self.transform = transform\n",
    "        for key in challenges.keys():\n",
    "            challenge = challenges[key]\n",
    "            solution = solutions[key]\n",
    "            for example in challenge['train']:\n",
    "                input_grid = example['input']\n",
    "                output_grid = example['output']\n",
    "                self.data.append((input_grid, output_grid))\n",
    "            for test_case in challenge['test']:\n",
    "                test_input = test_case['input']\n",
    "                test_output = solution[len(self.data) % len(solution)]\n",
    "                self.data.append((test_input, test_output))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def pad_grid(self, grid):\n",
    "        padded_grid = np.zeros(self.max_size)\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                padded_grid[i][j] = grid[i][j]\n",
    "        return padded_grid\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_grid, output_grid = self.data[idx]\n",
    "        input_grid = self.pad_grid(input_grid)\n",
    "        output_grid = self.pad_grid(output_grid)\n",
    "        input_grid = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        output_grid = torch.tensor(output_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        if self.transform:\n",
    "            input_grid = self.transform(input_grid)\n",
    "            output_grid = self.transform(output_grid)\n",
    "        \n",
    "        #create dummy text, audio, and context inputs\n",
    "        text_input = torch.zeros((10,))  #example dummy text input\n",
    "        audio_input = torch.zeros((20,))  #example dummy audio input\n",
    "        context_input = torch.zeros((5,))  #example dummy context input\n",
    "        \n",
    "        return (input_grid, text_input, audio_input, context_input), output_grid\n",
    "\n",
    "#define the maximum size\n",
    "max_size = (30, 30)\n",
    "\n",
    "#create datasets with padding\n",
    "transform = transforms.Compose([transforms.Lambda(lambda x: x)]) \n",
    "training_dataset = ARCDataset(training_challenges, training_solutions, max_size, transform=transform)\n",
    "evaluation_dataset = ARCDataset(evaluation_challenges, evaluation_solutions, max_size, transform=transform)\n",
    "\n",
    "#create dataloaders\n",
    "training_loader = DataLoader(training_dataset, batch_size=8, shuffle=True)\n",
    "evaluation_loader = DataLoader(evaluation_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493b0a89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:44.310481Z",
     "iopub.status.busy": "2024-07-31T22:10:44.309948Z",
     "iopub.status.idle": "2024-07-31T22:10:44.377438Z",
     "shell.execute_reply": "2024-07-31T22:10:44.375793Z"
    },
    "papermill": {
     "duration": 0.07597,
     "end_time": "2024-07-31T22:10:44.380057",
     "exception": false,
     "start_time": "2024-07-31T22:10:44.304087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed tensor shape: torch.Size([8, 1, 28, 28])\n",
      "Channels: 1, Height: 28, Width: 28\n",
      "Preprocessed tensor shape: torch.Size([8, 3, 32, 32])\n",
      "Channels: 3, Height: 32, Width: 32\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input(x, normalize=False, mean=0.5, std=0.5):\n",
    "    \"\"\"\n",
    "    Preprocesses the input tensor `x` and returns it along with dimensions needed by subsequent modules.\n",
    "    \n",
    "    Args:\n",
    "    - x (torch.Tensor): Input tensor with shape (batch_size, channels, height, width).\n",
    "    - normalize (bool): Whether to normalize the input tensor.\n",
    "    - mean (float or list): Mean for normalization (scalar or list for each channel).\n",
    "    - std (float or list): Standard deviation for normalization (scalar or list for each channel).\n",
    "    \n",
    "    Returns:\n",
    "    - x (torch.Tensor): Preprocessed input tensor.\n",
    "    - input_channels (int): Number of channels in the input tensor.\n",
    "    - input_height (int): Height of the input tensor.\n",
    "    - input_width (int): Width of the input tensor.\n",
    "    \n",
    "    Raises:\n",
    "    - ValueError: If the input tensor `x` does not have the expected number of dimensions or channels.\n",
    "    \"\"\"\n",
    "    #ensure the input tensor has 4 dimensions (batch_size, channels, height, width)\n",
    "    if x.dim() != 4:\n",
    "        raise ValueError(f\"Expected input tensor with 4 dimensions (batch_size, channels, height, width), got {x.dim()} dimensions instead.\")\n",
    "    \n",
    "    #check the number of channels\n",
    "    input_channels = x.size(1)\n",
    "    \n",
    "    #ensure that the number of channels is 1 or 3 (grayscale or RGB)\n",
    "    if input_channels not in [1, 3]:\n",
    "        raise ValueError(f\"Expected input tensor with 1 or 3 channels, got {input_channels} channels instead.\")\n",
    "    \n",
    "    #extract input dimensions\n",
    "    input_height = x.size(2)\n",
    "    input_width = x.size(3)\n",
    "    \n",
    "    #normalize the input tensor if required\n",
    "    if normalize:\n",
    "        if isinstance(mean, list) and isinstance(std, list):\n",
    "            if len(mean) != input_channels or len(std) != input_channels:\n",
    "                raise ValueError(\"Mean and std lists must have the same length as the number of channels.\")\n",
    "            mean = torch.tensor(mean).view(1, input_channels, 1, 1)\n",
    "            std = torch.tensor(std).view(1, input_channels, 1, 1)\n",
    "        else:\n",
    "            mean = torch.tensor([mean] * input_channels).view(1, input_channels, 1, 1)\n",
    "            std = torch.tensor([std] * input_channels).view(1, input_channels, 1, 1)\n",
    "        x = (x - mean) / std\n",
    "    \n",
    "    return x, input_channels, input_height, input_width\n",
    "\n",
    "#example usage\n",
    "x1 = torch.randn(8, 1, 28, 28)  # Grayscale input tensor\n",
    "x2 = torch.randn(8, 3, 32, 32)  # RGB input tensor\n",
    "\n",
    "#without normalization\n",
    "preprocessed_x1, channels1, height1, width1 = preprocess_input(x1)\n",
    "print(f\"Preprocessed tensor shape: {preprocessed_x1.shape}\")\n",
    "print(f\"Channels: {channels1}, Height: {height1}, Width: {width1}\")\n",
    "\n",
    "#with normalization\n",
    "preprocessed_x2, channels2, height2, width2 = preprocess_input(x2, normalize=True, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "print(f\"Preprocessed tensor shape: {preprocessed_x2.shape}\")\n",
    "print(f\"Channels: {channels2}, Height: {height2}, Width: {width2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667b8733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:44.391131Z",
     "iopub.status.busy": "2024-07-31T22:10:44.390709Z",
     "iopub.status.idle": "2024-07-31T22:10:44.438684Z",
     "shell.execute_reply": "2024-07-31T22:10:44.436968Z"
    },
    "papermill": {
     "duration": 0.056737,
     "end_time": "2024-07-31T22:10:44.441478",
     "exception": false,
     "start_time": "2024-07-31T22:10:44.384741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n",
      "<class 'list'> 4\n",
      "<class 'torch.Tensor'> torch.Size([8, 1, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "#inspect the structure of a batch from the DataLoader\n",
    "for batch in training_loader:\n",
    "    print(type(batch))\n",
    "    print(len(batch))\n",
    "    for item in batch:\n",
    "        print(type(item), item.shape if isinstance(item, torch.Tensor) else len(item))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "408a742e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:44.454501Z",
     "iopub.status.busy": "2024-07-31T22:10:44.454106Z",
     "iopub.status.idle": "2024-07-31T22:10:44.483955Z",
     "shell.execute_reply": "2024-07-31T22:10:44.482458Z"
    },
    "papermill": {
     "duration": 0.039727,
     "end_time": "2024-07-31T22:10:44.486562",
     "exception": false,
     "start_time": "2024-07-31T22:10:44.446835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from /kaggle/input/arc-prize-2024/arc-agi_test_challenges.json.\n",
      "Number of keys in the dataset: 100\n"
     ]
    }
   ],
   "source": [
    "#define the path to test data\n",
    "test_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "\n",
    "#load test data\n",
    "def load_json_data(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        #print out some information for debugging purposes\n",
    "        print(f\"Successfully loaded data from {file_path}.\")\n",
    "        print(f\"Number of keys in the dataset: {len(data.keys())}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} does not exist.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file {file_path} is not a valid JSON file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "test_challenges = load_json_data(test_challenges_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54169a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:44.497993Z",
     "iopub.status.busy": "2024-07-31T22:10:44.497580Z",
     "iopub.status.idle": "2024-07-31T22:10:44.508533Z",
     "shell.execute_reply": "2024-07-31T22:10:44.507343Z"
    },
    "papermill": {
     "duration": 0.019556,
     "end_time": "2024-07-31T22:10:44.510922",
     "exception": false,
     "start_time": "2024-07-31T22:10:44.491366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#define test dataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, data, target_size=(30, 30), transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        self.keys = list(data.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        test_cases = self.data[key]['test']\n",
    "        #assuming we want to process the first test case\n",
    "        grid = test_cases[0]['input']\n",
    "        grid = np.array(grid).astype(np.float32)  #convert to numpy array\n",
    "        grid = np.expand_dims(grid, axis=0)  #add channel dimension\n",
    "\n",
    "        #pad grid to the target size\n",
    "        grid = torch.tensor(grid)  #convert to PyTorch tensor before padding\n",
    "        grid = self.pad_to_size(grid, self.target_size)\n",
    "\n",
    "        if self.transform:\n",
    "            grid = self.transform(grid)\n",
    "        return grid, key\n",
    "\n",
    "    def pad_to_size(self, grid, size):\n",
    "        _, h, w = grid.shape\n",
    "        target_h, target_w = size\n",
    "        pad_h = max(0, target_h - h)\n",
    "        pad_w = max(0, target_w - w)\n",
    "        padding = (0, pad_w, 0, pad_h)\n",
    "        #pad using torch tensor\n",
    "        padded_grid = F.pad(grid, padding, mode='constant', value=0)\n",
    "        return padded_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c8e68f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:44.522288Z",
     "iopub.status.busy": "2024-07-31T22:10:44.521878Z",
     "iopub.status.idle": "2024-07-31T22:10:44.544995Z",
     "shell.execute_reply": "2024-07-31T22:10:44.543326Z"
    },
    "papermill": {
     "duration": 0.032179,
     "end_time": "2024-07-31T22:10:44.547832",
     "exception": false,
     "start_time": "2024-07-31T22:10:44.515653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('007bbfb7', '00d62c1b', '017c7c7b', '025d127b', '045e512c', '0520fde7', '05269061', '05f2a901')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('06df4c85', '08ed6ac7', '09629e4f', '0962bcdd', '0a938d79', '0b148d64', '0ca9ddb6', '0d3d703e')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('0dfd9992', '0e206a2e', '10fcaaa3', '11852cab', '1190e5a7', '137eaa0f', '150deff5', '178fcbfb')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('1a07d186', '1b2d62fb', '1b60fb0c', '1bfc4729', '1c786137', '1caeab9d', '1cf80156', '1e0a9b12')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('1e32b0e9', '1f0c79e5', '1f642eb9', '1f85a75f', '1f876c06', '1fad071e', '2013d3e2', '2204b7a8')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('22168020', '22233c11', '2281f1f4', '228f6490', '22eb0ac0', '234bbc79', '23581191', '239be575')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('23b5c85d', '253bf280', '25d487eb', '25d8a9c8', '25ff71a9', '264363fd', '272f95fa', '27a28665')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('28bf18c6', '28e73c20', '29623171', '29c11459', '29ec7d0e', '2bcee788', '2bee17df', '2c608aff')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('2dc579da', '2dd70a9a', '2dee498d', '31aa019c', '321b1fc6', '32597951', '3345333e', '3428a4f5')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('3618c87e', '3631a71a', '363442ee', '36d67576', '36fdfd69', '3906de3d', '39a8645d', '39e1d7f9')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('3aa6fb7a', '3ac3eb23', '3af2c5a8', '3bd67248', '3bdb4ada', '3befdf3e', '3c9b0459', '3de23699')\n",
      "Batch of grids shape: torch.Size([8, 1, 30, 30])\n",
      "Keys: ('3e980e27', '3eda0437', '3f7978a0', '40853293', '4093f84a', '41e4d17e', '4258a5f9', '4290ef0e')\n",
      "Batch of grids shape: torch.Size([4, 1, 30, 30])\n",
      "Keys: ('42a50994', '4347f46a', '444801d8', '445eab21')\n"
     ]
    }
   ],
   "source": [
    "#define grid dimensions\n",
    "grid_height = 30\n",
    "grid_width = 30\n",
    "\n",
    "#create the dataset and dataloader for the test data\n",
    "test_dataset = TestDataset(data=test_challenges, target_size=(grid_height, grid_width))\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "#iterate over the DataLoader\n",
    "for grids, keys in test_loader:\n",
    "    print(f\"Batch of grids shape: {grids.shape}\")\n",
    "    print(f\"Keys: {keys}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f6a1fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:44.559816Z",
     "iopub.status.busy": "2024-07-31T22:10:44.559420Z",
     "iopub.status.idle": "2024-07-31T22:10:44.716841Z",
     "shell.execute_reply": "2024-07-31T22:10:44.715679Z"
    },
    "papermill": {
     "duration": 0.16686,
     "end_time": "2024-07-31T22:10:44.719523",
     "exception": false,
     "start_time": "2024-07-31T22:10:44.552663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[0.0887, 0.1006, 0.0852, 0.1053, 0.0806, 0.1314, 0.0929, 0.0806, 0.1543,\n",
      "         0.0806],\n",
      "        [0.0985, 0.1073, 0.0917, 0.0909, 0.1123, 0.1276, 0.0909, 0.0987, 0.0909,\n",
      "         0.0909],\n",
      "        [0.0946, 0.0989, 0.0920, 0.0846, 0.0868, 0.1119, 0.0846, 0.1352, 0.1268,\n",
      "         0.0846],\n",
      "        [0.1494, 0.0950, 0.0792, 0.1085, 0.0785, 0.1035, 0.0785, 0.0808, 0.1482,\n",
      "         0.0785],\n",
      "        [0.0895, 0.1077, 0.0895, 0.0895, 0.0895, 0.1282, 0.1090, 0.0895, 0.1181,\n",
      "         0.0895],\n",
      "        [0.0879, 0.0888, 0.0879, 0.1003, 0.0879, 0.1059, 0.0902, 0.1275, 0.1356,\n",
      "         0.0879],\n",
      "        [0.1093, 0.0892, 0.0892, 0.0892, 0.0934, 0.1071, 0.1077, 0.1098, 0.1160,\n",
      "         0.0892],\n",
      "        [0.0988, 0.1012, 0.0914, 0.0921, 0.0989, 0.1037, 0.0979, 0.1013, 0.1234,\n",
      "         0.0914]], grad_fn=<SoftmaxBackward0>)\n",
      "Bias detected: True\n",
      "Loss before backward: 2.3055713176727295\n",
      "Parameter cognitive_architecture.fc.weight requires grad: True\n",
      "Parameter cognitive_architecture.fc.weight has gradient.\n",
      "Parameter cognitive_architecture.fc.bias requires grad: True\n",
      "Parameter cognitive_architecture.fc.bias has gradient.\n",
      "Parameter meta_learning.fc.weight requires grad: True\n",
      "Parameter meta_learning.fc.weight has gradient.\n",
      "Parameter meta_learning.fc.bias requires grad: True\n",
      "Parameter meta_learning.fc.bias has gradient.\n",
      "Parameter embodied_cognition.fc.weight requires grad: True\n",
      "Parameter embodied_cognition.fc.weight has gradient.\n",
      "Parameter embodied_cognition.fc.bias requires grad: True\n",
      "Parameter embodied_cognition.fc.bias has gradient.\n",
      "Parameter final_fc.weight requires grad: True\n",
      "Parameter final_fc.weight has no gradient.\n",
      "Parameter final_fc.bias requires grad: True\n",
      "Parameter final_fc.bias has no gradient.\n",
      "Parameter output_layer.weight requires grad: True\n",
      "Parameter output_layer.weight has gradient.\n",
      "Parameter output_layer.bias requires grad: True\n",
      "Parameter output_layer.bias has gradient.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#define the Ethical Guidelines class\n",
    "class EthicalGuidelines:\n",
    "    def __init__(self, guidelines):\n",
    "        self.guidelines = guidelines\n",
    "\n",
    "    def apply_guidelines(self, predictions):\n",
    "        if self.guidelines['cultural_heritage']:\n",
    "            predictions = predictions * 1.05\n",
    "        if self.guidelines['honor_issue'] > 0.1:\n",
    "            honor_adjustment = self.guidelines['honor_issue']\n",
    "            predictions = predictions * (1 + honor_adjustment)\n",
    "        if self.guidelines['nature_related'] > 0.2:\n",
    "            nature_adjustment = self.guidelines['nature_related']\n",
    "            predictions = predictions * (1 + nature_adjustment)\n",
    "        if self.guidelines['family_involved']:\n",
    "            predictions = predictions * 1.03 \n",
    "        if self.guidelines['bravery_needed']:\n",
    "            predictions = predictions * 1.02\n",
    "        if self.guidelines['self_reliance_needed']:\n",
    "            predictions = predictions * 1.01\n",
    "        if self.guidelines['guest_involved']:\n",
    "            predictions = predictions * 1.04 \n",
    "        if self.guidelines['consensus_needed']:\n",
    "            predictions = predictions * 1.02 \n",
    "\n",
    "        #normalize predictions to ensure they are within a valid range\n",
    "        predictions = torch.clamp(predictions, min=0.0, max=1.0)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "#define the Cognitive Architecture model\n",
    "class CognitiveArchitecture(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CognitiveArchitecture, self).__init__()\n",
    "        self.fc = nn.Linear(30 * 30, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return F.relu(self.fc(x))\n",
    "\n",
    "#define the Meta Learning model\n",
    "class MetaLearning(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MetaLearning, self).__init__()\n",
    "        self.fc = nn.Linear(10, 100)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.fc(x))\n",
    "\n",
    "#define the Embodied Cognition model\n",
    "class EmbodiedCognition(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmbodiedCognition, self).__init__()\n",
    "        self.fc = nn.Linear(20, 100) \n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.fc(x))\n",
    "\n",
    "#define the Bias Detection class\n",
    "class BiasDetection:\n",
    "    def __init__(self):\n",
    "        self.bias_threshold = 0.1\n",
    "    \n",
    "    def check_bias(self, predictions):\n",
    "        bias_detected = torch.any(predictions > self.bias_threshold)\n",
    "        return bias_detected\n",
    "\n",
    "#define the Self Improvement System\n",
    "class SelfImprovementSystem:\n",
    "    def __init__(self, model, ethical_guidelines):\n",
    "        self.model = model\n",
    "        self.ethical_guidelines = ethical_guidelines\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    def detect_and_correct_errors(self, test_data, test_labels):\n",
    "        self.collect_data(test_data, test_labels)\n",
    "        self.retrain()\n",
    "\n",
    "    def collect_data(self, test_data, test_labels):\n",
    "        self.train_data = test_data\n",
    "        self.train_labels = test_labels\n",
    "\n",
    "    def retrain(self):\n",
    "        self.model.train()\n",
    "        inputs = self.train_data\n",
    "        targets = self.train_labels\n",
    "\n",
    "        image_input, text_input, audio_input = inputs\n",
    "\n",
    "        predictions = self.model(image_input, text_input, audio_input)\n",
    "        loss = self.loss_function(predictions, targets)\n",
    "\n",
    "        print(\"Loss before backward:\", loss.item())\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(f\"Parameter {name} requires grad: {param.requires_grad}\")\n",
    "                if param.grad is not None:\n",
    "                    print(f\"Parameter {name} has gradient.\")\n",
    "                else:\n",
    "                    print(f\"Parameter {name} has no gradient.\")\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.train_data = None\n",
    "        self.train_labels = None\n",
    "\n",
    "#define the Yambi (\"Welcome\" in Kikongo) model\n",
    "class Yambi(nn.Module):\n",
    "    def __init__(self, ethical_guidelines):\n",
    "        super(Yambi, self).__init__()\n",
    "        self.cognitive_architecture = CognitiveArchitecture()\n",
    "        self.meta_learning = MetaLearning()\n",
    "        self.embodied_cognition = EmbodiedCognition()\n",
    "        self.final_fc = nn.Linear(300, 10)\n",
    "        self.ethical_guidelines = ethical_guidelines\n",
    "        self.output_layer = nn.Linear(300, 10)\n",
    "        self.self_improvement = SelfImprovementSystem(self, ethical_guidelines)\n",
    "        self.bias_detection = BiasDetection()\n",
    "\n",
    "    def forward(self, image_input, text_input, audio_input):\n",
    "        cognitive_output = self.cognitive_architecture(image_input)\n",
    "        meta_output = self.meta_learning(text_input)\n",
    "        embodied_output = self.embodied_cognition(audio_input)\n",
    "\n",
    "        combined_output = torch.cat((cognitive_output, meta_output, embodied_output), dim=1)\n",
    "        combined_output = F.relu(self.output_layer(combined_output))\n",
    "\n",
    "        ethical_output = self.ethical_guidelines.apply_guidelines(combined_output)\n",
    "        final_output = F.softmax(ethical_output, dim=-1)\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    def retrain_model(self, test_data, test_labels):\n",
    "        self.self_improvement.detect_and_correct_errors(test_data, test_labels)\n",
    "\n",
    "#test Yambi\n",
    "ethical_guidelines = EthicalGuidelines({\n",
    "    'cultural_heritage': True,\n",
    "    'honor_issue': 0.1,\n",
    "    'nature_related': 0.2,\n",
    "    'family_involved': True,\n",
    "    'bravery_needed': True,\n",
    "    'self_reliance_needed': True,\n",
    "    'guest_involved': True,\n",
    "    'consensus_needed': True\n",
    "})\n",
    "\n",
    "yambi_model = Yambi(ethical_guidelines)\n",
    "optimizer = optim.Adam(yambi_model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#create test data\n",
    "test_image_data = torch.randn(8, 1, 30, 30)  \n",
    "test_text_data = torch.randn(8, 10)\n",
    "test_audio_data = torch.randn(8, 20) \n",
    "test_labels = torch.randint(0, 10, (8,))\n",
    "\n",
    "#forward pass\n",
    "output = yambi_model(test_image_data, test_text_data, test_audio_data)\n",
    "print(\"Output:\", output)\n",
    "\n",
    "#bias detection\n",
    "bias_detector = BiasDetection()\n",
    "bias_detected = bias_detector.check_bias(output)\n",
    "print(\"Bias detected:\", bias_detected.item())\n",
    "\n",
    "#retrain the model if needed\n",
    "yambi_model.retrain_model((test_image_data, test_text_data, test_audio_data), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ea6b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T22:10:44.732113Z",
     "iopub.status.busy": "2024-07-31T22:10:44.731676Z",
     "iopub.status.idle": "2024-07-31T22:10:44.749896Z",
     "shell.execute_reply": "2024-07-31T22:10:44.748666Z"
    },
    "papermill": {
     "duration": 0.027667,
     "end_time": "2024-07-31T22:10:44.752667",
     "exception": false,
     "start_time": "2024-07-31T22:10:44.725000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "  Inputs (batch size 4):\n",
      "    Type: <class 'list'> (not a tensor)\n",
      "    Sample Data: [tensor([[[[8., 6., 0.,  ..., 0., 0., 0.],\n",
      "          [6., 4., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[7., 9., 0.,  ..., 0., 0., 0.],\n",
      "          [4., 3., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[3., 2., 0.,  ..., 0., 0., 0.],\n",
      "          [7., 8., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 8., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 8., 8.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])]\n",
      "  Labels (batch size 8):\n",
      "    Type: <class 'torch.Tensor'>\n",
      "    Shape: torch.Size([8, 1, 30, 30])\n",
      "    Sample Labels: tensor([[[[8., 6., 8.,  ..., 0., 0., 0.],\n",
      "          [6., 4., 6.,  ..., 0., 0., 0.],\n",
      "          [6., 8., 6.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[7., 9., 7.,  ..., 0., 0., 0.],\n",
      "          [4., 3., 4.,  ..., 0., 0., 0.],\n",
      "          [9., 7., 9.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "def inspect_dataloader(dataloader):\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        if isinstance(batch, (tuple, list)):\n",
    "            inputs, labels = batch\n",
    "            print(f\"Batch {batch_idx+1}:\")\n",
    "            print(f\"  Inputs (batch size {len(inputs)}):\")\n",
    "            if isinstance(inputs, torch.Tensor):\n",
    "                print(f\"    Type: {type(inputs)}\")\n",
    "                print(f\"    Shape: {inputs.shape}\")\n",
    "                print(f\"    Sample Data: {inputs[:2]}\")  #print first 2 samples\n",
    "            else:\n",
    "                print(f\"    Type: {type(inputs)} (not a tensor)\")\n",
    "                print(f\"    Sample Data: {inputs[:2]}\")  #print first 2 samples if not a tensor\n",
    "\n",
    "            print(f\"  Labels (batch size {len(labels)}):\")\n",
    "            if isinstance(labels, torch.Tensor):\n",
    "                print(f\"    Type: {type(labels)}\")\n",
    "                print(f\"    Shape: {labels.shape}\")\n",
    "                print(f\"    Sample Labels: {labels[:2]}\")  #print first 2 labels\n",
    "            else:\n",
    "                print(f\"    Type: {type(labels)} (not a tensor)\")\n",
    "                print(f\"    Sample Labels: {labels[:2]}\")  #print first 2 labels if not a tensor\n",
    "        else:\n",
    "            print(f\"Batch {batch_idx+1} is not a tuple or list.\")\n",
    "        break \n",
    "\n",
    "inspect_dataloader(evaluation_loader)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.938697,
   "end_time": "2024-07-31T22:10:45.982909",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-31T22:10:34.044212",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
