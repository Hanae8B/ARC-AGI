{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a128272",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:11.388960Z",
     "iopub.status.busy": "2024-07-14T19:38:11.388480Z",
     "iopub.status.idle": "2024-07-14T19:38:12.499477Z",
     "shell.execute_reply": "2024-07-14T19:38:12.498052Z"
    },
    "papermill": {
     "duration": 1.123136,
     "end_time": "2024-07-14T19:38:12.502580",
     "exception": false,
     "start_time": "2024-07-14T19:38:11.379444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2024/sample_submission.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ba15ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:12.518472Z",
     "iopub.status.busy": "2024-07-14T19:38:12.517818Z",
     "iopub.status.idle": "2024-07-14T19:38:12.921496Z",
     "shell.execute_reply": "2024-07-14T19:38:12.920316Z"
    },
    "papermill": {
     "duration": 0.415178,
     "end_time": "2024-07-14T19:38:12.924679",
     "exception": false,
     "start_time": "2024-07-14T19:38:12.509501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json'\n",
    "evaluation_solutions_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json'\n",
    "evaluation_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json'\n",
    "sample_submission_path = '/kaggle/input/arc-prize-2024/sample_submission.json'\n",
    "training_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json'\n",
    "test_challenges_path = '/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json'\n",
    "\n",
    "#function to load JSON data\n",
    "def load_json_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "#load each dataset\n",
    "training_solutions = load_json_data(training_solutions_path)\n",
    "evaluation_solutions = load_json_data(evaluation_solutions_path)\n",
    "evaluation_challenges = load_json_data(evaluation_challenges_path)\n",
    "sample_submission = load_json_data(sample_submission_path)\n",
    "training_challenges = load_json_data(training_challenges_path)\n",
    "test_challenges = load_json_data(test_challenges_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bd0bb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:12.940898Z",
     "iopub.status.busy": "2024-07-14T19:38:12.939465Z",
     "iopub.status.idle": "2024-07-14T19:38:12.952320Z",
     "shell.execute_reply": "2024-07-14T19:38:12.950951Z"
    },
    "papermill": {
     "duration": 0.024597,
     "end_time": "2024-07-14T19:38:12.955837",
     "exception": false,
     "start_time": "2024-07-14T19:38:12.931240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Training Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Solutions:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "\n",
      "\n",
      "Inspecting Evaluation Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '00576224': {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
      "\n",
      "\n",
      "Inspecting Sample Submission:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': [{'attempt_1': [[0, 0], [0, 0]], 'attempt_2': [[0, 0], [0, 0]]}]\n",
      "\n",
      "\n",
      "Inspecting Training Challenges:\n",
      "Number of keys: 400\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n",
      "Inspecting Test Challenges:\n",
      "Number of keys: 100\n",
      "Example item under key '007bbfb7': {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#inspect the structure of the data\n",
    "def inspect_data(data, name):\n",
    "    print(f\"Inspecting {name}:\")\n",
    "    if isinstance(data, list):\n",
    "        print(f\"Number of items: {len(data)}\")\n",
    "        if len(data) > 0:\n",
    "            print(f\"Example item: {data[0]}\")\n",
    "    elif isinstance(data, dict):\n",
    "        print(f\"Number of keys: {len(data.keys())}\")\n",
    "        if len(data.keys()) > 0:\n",
    "            first_key = list(data.keys())[0]\n",
    "            print(f\"Example item under key '{first_key}': {data[first_key]}\")\n",
    "    else:\n",
    "        print(\"Unknown data type\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "inspect_data(training_solutions, \"Training Solutions\")\n",
    "inspect_data(evaluation_solutions, \"Evaluation Solutions\")\n",
    "inspect_data(evaluation_challenges, \"Evaluation Challenges\")\n",
    "inspect_data(sample_submission, \"Sample Submission\")\n",
    "inspect_data(training_challenges, \"Training Challenges\")\n",
    "inspect_data(test_challenges, \"Test Challenges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e30317",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:12.972054Z",
     "iopub.status.busy": "2024-07-14T19:38:12.971585Z",
     "iopub.status.idle": "2024-07-14T19:38:12.986581Z",
     "shell.execute_reply": "2024-07-14T19:38:12.985187Z"
    },
    "papermill": {
     "duration": 0.026439,
     "end_time": "2024-07-14T19:38:12.989350",
     "exception": false,
     "start_time": "2024-07-14T19:38:12.962911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max input size: 30x30, Max output size: 30x30\n"
     ]
    }
   ],
   "source": [
    "def get_max_grid_size(challenges, solutions):\n",
    "    max_input_height, max_input_width = 0, 0\n",
    "    max_output_height, max_output_width = 0, 0\n",
    "    \n",
    "    for key in challenges.keys():\n",
    "        challenge = challenges[key]\n",
    "        for example in challenge['train']:\n",
    "            input_grid = example['input']\n",
    "            output_grid = example['output']\n",
    "            max_input_height = max(max_input_height, len(input_grid))\n",
    "            max_input_width = max(max_input_width, len(input_grid[0]))\n",
    "            max_output_height = max(max_output_height, len(output_grid))\n",
    "            max_output_width = max(max_output_width, len(output_grid[0]))\n",
    "        for test_case in challenge['test']:\n",
    "            test_input = test_case['input']\n",
    "            max_input_height = max(max_input_height, len(test_input))\n",
    "            max_input_width = max(max_input_width, len(test_input[0]))\n",
    "            #assuming test_output size can be derived similarly\n",
    "\n",
    "    return max_input_height, max_input_width, max_output_height, max_output_width\n",
    "\n",
    "max_input_height, max_input_width, max_output_height, max_output_width = get_max_grid_size(training_challenges, training_solutions)\n",
    "print(f\"Max input size: {max_input_height}x{max_input_width}, Max output size: {max_output_height}x{max_output_width}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc99e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:13.009302Z",
     "iopub.status.busy": "2024-07-14T19:38:13.008062Z",
     "iopub.status.idle": "2024-07-14T19:38:19.227766Z",
     "shell.execute_reply": "2024-07-14T19:38:19.226440Z"
    },
    "papermill": {
     "duration": 6.233883,
     "end_time": "2024-07-14T19:38:19.230780",
     "exception": false,
     "start_time": "2024-07-14T19:38:12.996897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class ARCDataset(Dataset):\n",
    "    def __init__(self, challenges, solutions, max_size, transform=None):\n",
    "        self.data = []\n",
    "        self.max_size = max_size\n",
    "        self.transform = transform\n",
    "        for key in challenges.keys():\n",
    "            challenge = challenges[key]\n",
    "            solution = solutions[key]\n",
    "            for example in challenge['train']:\n",
    "                input_grid = example['input']\n",
    "                output_grid = example['output']\n",
    "                self.data.append((input_grid, output_grid))\n",
    "            for test_case in challenge['test']:\n",
    "                test_input = test_case['input']\n",
    "                #use the corresponding solution as the target output\n",
    "                test_output = solution[len(self.data) % len(solution)]\n",
    "                self.data.append((test_input, test_output))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def pad_grid(self, grid):\n",
    "        padded_grid = np.zeros(self.max_size)\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                padded_grid[i][j] = grid[i][j]\n",
    "        return padded_grid\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_grid, output_grid = self.data[idx]\n",
    "        input_grid = self.pad_grid(input_grid)\n",
    "        output_grid = self.pad_grid(output_grid)\n",
    "        input_grid = torch.tensor(input_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        output_grid = torch.tensor(output_grid, dtype=torch.float32).unsqueeze(0)\n",
    "        if self.transform:\n",
    "            input_grid = self.transform(input_grid)\n",
    "            output_grid = self.transform(output_grid)\n",
    "        return input_grid, output_grid\n",
    "\n",
    "#define the maximum size\n",
    "max_size = (30, 30)\n",
    "\n",
    "#create datasets with padding\n",
    "transform = transforms.Compose([transforms.Lambda(lambda x: x)])  #no additional transform needed\n",
    "training_dataset = ARCDataset(training_challenges, training_solutions, max_size, transform=transform)\n",
    "evaluation_dataset = ARCDataset(evaluation_challenges, evaluation_solutions, max_size, transform=transform)\n",
    "\n",
    "#create dataloaders\n",
    "training_loader = DataLoader(training_dataset, batch_size=1, shuffle=True)\n",
    "evaluation_loader = DataLoader(evaluation_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d04a4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.246523Z",
     "iopub.status.busy": "2024-07-14T19:38:19.245905Z",
     "iopub.status.idle": "2024-07-14T19:38:19.258603Z",
     "shell.execute_reply": "2024-07-14T19:38:19.257413Z"
    },
    "papermill": {
     "duration": 0.024394,
     "end_time": "2024-07-14T19:38:19.262000",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.237606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#perception module\n",
    "class PerceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(PerceptionModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(32 * 7 * 7, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  #flatten the tensor\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5fc20e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.279610Z",
     "iopub.status.busy": "2024-07-14T19:38:19.279148Z",
     "iopub.status.idle": "2024-07-14T19:38:19.290290Z",
     "shell.execute_reply": "2024-07-14T19:38:19.288947Z"
    },
    "papermill": {
     "duration": 0.023299,
     "end_time": "2024-07-14T19:38:19.293282",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.269983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#memory module\n",
    "class MemoryModule(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(MemoryModule, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc1 = nn.Linear(hidden_size, 256)\n",
    "        self.fc2 = nn.Linear(256, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_output, _ = self.lstm(x)\n",
    "        \n",
    "        #ensure lstm_output has the correct shape\n",
    "        if lstm_output.ndim == 2:  #handle the case when lstm_output is 2D\n",
    "            lstm_output = lstm_output.unsqueeze(1)  #add a dummy dimension\n",
    "        last_hidden_state = lstm_output[:, -1, :]\n",
    "\n",
    "        x = F.relu(self.fc1(last_hidden_state))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08472f70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.310347Z",
     "iopub.status.busy": "2024-07-14T19:38:19.309879Z",
     "iopub.status.idle": "2024-07-14T19:38:19.319027Z",
     "shell.execute_reply": "2024-07-14T19:38:19.317566Z"
    },
    "papermill": {
     "duration": 0.021586,
     "end_time": "2024-07-14T19:38:19.322189",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.300603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creativity module\n",
    "class CreativityModule(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CreativityModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f794681f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.338679Z",
     "iopub.status.busy": "2024-07-14T19:38:19.338143Z",
     "iopub.status.idle": "2024-07-14T19:38:19.347539Z",
     "shell.execute_reply": "2024-07-14T19:38:19.346257Z"
    },
    "papermill": {
     "duration": 0.021976,
     "end_time": "2024-07-14T19:38:19.351307",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.329331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reasoning module\n",
    "class ReasoningModule(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ReasoningModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb59f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.366983Z",
     "iopub.status.busy": "2024-07-14T19:38:19.366554Z",
     "iopub.status.idle": "2024-07-14T19:38:19.375364Z",
     "shell.execute_reply": "2024-07-14T19:38:19.374065Z"
    },
    "papermill": {
     "duration": 0.019462,
     "end_time": "2024-07-14T19:38:19.377742",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.358280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compassionate module\n",
    "class CompassionateModule(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(CompassionateModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, output_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce2dd81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.393346Z",
     "iopub.status.busy": "2024-07-14T19:38:19.392968Z",
     "iopub.status.idle": "2024-07-14T19:38:19.401524Z",
     "shell.execute_reply": "2024-07-14T19:38:19.400383Z"
    },
    "papermill": {
     "duration": 0.019623,
     "end_time": "2024-07-14T19:38:19.404269",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.384646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bias detection and mitigation module\n",
    "class BiasDetectionMitigationModule(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(BiasDetectionMitigationModule, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, input_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2517a7e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.421269Z",
     "iopub.status.busy": "2024-07-14T19:38:19.420874Z",
     "iopub.status.idle": "2024-07-14T19:38:19.432498Z",
     "shell.execute_reply": "2024-07-14T19:38:19.431125Z"
    },
    "papermill": {
     "duration": 0.023618,
     "end_time": "2024-07-14T19:38:19.435245",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.411627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Yambi(nn.Module):\n",
    "    \"\"\"\n",
    "    Yambi is an AI model designed to solve abstract reasoning tasks by integrating various cognitive abilities. \n",
    "    It consists of six main modules:\n",
    "    \n",
    "    1. Perception Module: Processes and understands input grids using convolutional neural networks.\n",
    "    2. Memory Module: Stores and recalls information about previously seen tasks using LSTM networks.\n",
    "    3. Creativity Module: Generates creative solutions and explores novel approaches using a latent space.\n",
    "    4. Reasoning Module: Applies logical reasoning to infer solutions based on perceived information.\n",
    "    5. Compassionate Module: Analyzes emotional context and adjusts responses accordingly.\n",
    "    6. Bias Detection and Mitigation Module: Detects and mitigates biases in the reasoning output.\n",
    "\n",
    "    These modules work together to perceive, remember, create, reason, empathize, and ensure fairness in solving\n",
    "    abstract reasoning tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, perception_model, memory_model, creativity_model, reasoning_model, compassionate_model, bias_detection_mitigation_model):\n",
    "        super(Yambi, self).__init__()\n",
    "        self.perception_model = perception_model\n",
    "        self.memory_model = memory_model\n",
    "        self.creativity_model = creativity_model\n",
    "        self.reasoning_model = reasoning_model\n",
    "        self.compassionate_model = compassionate_model\n",
    "        self.bias_detection_mitigation_model = bias_detection_mitigation_model\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Perception Module\n",
    "        perception_output = self.perception_model(x)\n",
    "\n",
    "        # Memory Module\n",
    "        memory_output = self.memory_model(perception_output)\n",
    "\n",
    "        # Creativity Module\n",
    "        creativity_output = self.creativity_model(memory_output)\n",
    "\n",
    "        # Reasoning Module\n",
    "        reasoning_output = self.reasoning_model(creativity_output)\n",
    "\n",
    "        # Bias Detection and Mitigation Module\n",
    "        unbiased_reasoning_output = self.bias_detection_mitigation_model(reasoning_output)\n",
    "\n",
    "        # Compassionate Module\n",
    "        compassionate_output = self.compassionate_model(unbiased_reasoning_output)\n",
    "\n",
    "        return unbiased_reasoning_output, compassionate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c98ba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.451733Z",
     "iopub.status.busy": "2024-07-14T19:38:19.451324Z",
     "iopub.status.idle": "2024-07-14T19:38:19.457958Z",
     "shell.execute_reply": "2024-07-14T19:38:19.456532Z"
    },
    "papermill": {
     "duration": 0.01854,
     "end_time": "2024-07-14T19:38:19.461074",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.442534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44743351",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.477638Z",
     "iopub.status.busy": "2024-07-14T19:38:19.476727Z",
     "iopub.status.idle": "2024-07-14T19:38:19.555551Z",
     "shell.execute_reply": "2024-07-14T19:38:19.554133Z"
    },
    "papermill": {
     "duration": 0.090381,
     "end_time": "2024-07-14T19:38:19.558722",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.468341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yambi(\n",
       "  (perception_model): PerceptionModule(\n",
       "    (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=1568, out_features=128, bias=True)\n",
       "  )\n",
       "  (memory_model): MemoryModule(\n",
       "    (lstm): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
       "    (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (creativity_model): CreativityModule(\n",
       "    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (reasoning_model): ReasoningModule(\n",
       "    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (compassionate_model): CompassionateModule(\n",
       "    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (bias_detection_mitigation_model): BiasDetectionMitigationModule(\n",
       "    (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate modules\n",
    "perception_model = PerceptionModule(in_channels=1)\n",
    "memory_model = MemoryModule(input_size=128, hidden_size=128, output_size=128, num_layers=2)\n",
    "creativity_model = CreativityModule(input_size=128)\n",
    "reasoning_model = ReasoningModule(input_size=128, output_size=128)\n",
    "compassionate_model = CompassionateModule(input_size=128, output_size=10)\n",
    "bias_detection_mitigation_model = BiasDetectionMitigationModule(input_size=128)\n",
    "\n",
    "#move models to device\n",
    "perception_model.to(device)\n",
    "memory_model.to(device)\n",
    "creativity_model.to(device)\n",
    "reasoning_model.to(device)\n",
    "compassionate_model.to(device)\n",
    "bias_detection_mitigation_model.to(device)\n",
    "\n",
    "#instantiate the Yambi model\n",
    "yambi_model = Yambi(perception_model, memory_model, creativity_model, reasoning_model, compassionate_model, bias_detection_mitigation_model)\n",
    "yambi_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca97216c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.574780Z",
     "iopub.status.busy": "2024-07-14T19:38:19.574404Z",
     "iopub.status.idle": "2024-07-14T19:38:19.584004Z",
     "shell.execute_reply": "2024-07-14T19:38:19.582560Z"
    },
    "papermill": {
     "duration": 0.021165,
     "end_time": "2024-07-14T19:38:19.587122",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.565957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train the Yambi model\n",
    "def train_model(yambi_model, train_loader, optimizer, criterion, device, num_epochs=10):\n",
    "    yambi_model.train()  #set the yambi_model to training mode\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            #zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward pass\n",
    "            unbiased_reasoning_output, compassionate_output = yambi_model(inputs)\n",
    "\n",
    "            #compute the loss\n",
    "            loss = criterion(unbiased_reasoning_output, labels)\n",
    "\n",
    "            #backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c75c4fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T19:38:19.604928Z",
     "iopub.status.busy": "2024-07-14T19:38:19.604502Z",
     "iopub.status.idle": "2024-07-14T19:38:24.488929Z",
     "shell.execute_reply": "2024-07-14T19:38:24.487602Z"
    },
    "papermill": {
     "duration": 4.897119,
     "end_time": "2024-07-14T19:38:24.491936",
     "exception": false,
     "start_time": "2024-07-14T19:38:19.594817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARC Score: 0.00%\n"
     ]
    }
   ],
   "source": [
    "def calculate_arc_score(model, evaluation_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in evaluation_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).squeeze(1)\n",
    "\n",
    "            reasoning_output, compassionate_output = model(inputs)\n",
    "            predicted_output = torch.argmax(reasoning_output, dim=1)\n",
    "\n",
    "            correct += (predicted_output == labels).sum().item()\n",
    "            total += labels.numel()\n",
    "\n",
    "    model.train() \n",
    "    \n",
    "    return correct / total\n",
    "\n",
    "#evaluate the model on the evaluation dataset\n",
    "arc_score = calculate_arc_score(yambi_model, evaluation_loader, device)\n",
    "print(f'ARC Score: {arc_score * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.278186,
   "end_time": "2024-07-14T19:38:26.230243",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-14T19:38:07.952057",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
