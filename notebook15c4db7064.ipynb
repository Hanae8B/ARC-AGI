{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a64c006",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:22.456984Z",
     "iopub.status.busy": "2024-08-11T12:38:22.456593Z",
     "iopub.status.idle": "2024-08-11T12:38:23.369832Z",
     "shell.execute_reply": "2024-08-11T12:38:23.368689Z"
    },
    "papermill": {
     "duration": 0.933448,
     "end_time": "2024-08-11T12:38:23.372636",
     "exception": false,
     "start_time": "2024-08-11T12:38:22.439188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json\n",
      "/kaggle/input/arc-prize-2024/sample_submission.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json\n",
      "/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6045185d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:23.405538Z",
     "iopub.status.busy": "2024-08-11T12:38:23.404992Z",
     "iopub.status.idle": "2024-08-11T12:38:23.783693Z",
     "shell.execute_reply": "2024-08-11T12:38:23.782595Z"
    },
    "papermill": {
     "duration": 0.398335,
     "end_time": "2024-08-11T12:38:23.786525",
     "exception": false,
     "start_time": "2024-08-11T12:38:23.388190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "#load the data\n",
    "training_solutions = load_json('/kaggle/input/arc-prize-2024/arc-agi_training_solutions.json')\n",
    "evaluation_solutions = load_json('/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json')\n",
    "training_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_training_challenges.json')\n",
    "evaluation_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json')\n",
    "test_challenges = load_json('/kaggle/input/arc-prize-2024/arc-agi_test_challenges.json')\n",
    "sample_submission = load_json('/kaggle/input/arc-prize-2024/sample_submission.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0ea6aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:23.820268Z",
     "iopub.status.busy": "2024-08-11T12:38:23.819256Z",
     "iopub.status.idle": "2024-08-11T12:38:23.828688Z",
     "shell.execute_reply": "2024-08-11T12:38:23.827514Z"
    },
    "papermill": {
     "duration": 0.029709,
     "end_time": "2024-08-11T12:38:23.831793",
     "exception": false,
     "start_time": "2024-08-11T12:38:23.802084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Solutions:\n",
      "Key: 007bbfb7\n",
      "Sample Data: [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n",
      "\n",
      "Training Challenges:\n",
      "Key: 007bbfb7\n",
      "Sample Data: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "Evaluation Solutions:\n",
      "Key: 00576224\n",
      "Sample Data: [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]]\n",
      "\n",
      "Evaluation Challenges:\n",
      "Key: 00576224\n",
      "Sample Data: {'test': [{'input': [[3, 2], [7, 8]]}], 'train': [{'input': [[8, 6], [6, 4]], 'output': [[8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4], [6, 8, 6, 8, 6, 8], [4, 6, 4, 6, 4, 6], [8, 6, 8, 6, 8, 6], [6, 4, 6, 4, 6, 4]]}, {'input': [[7, 9], [4, 3]], 'output': [[7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3], [9, 7, 9, 7, 9, 7], [3, 4, 3, 4, 3, 4], [7, 9, 7, 9, 7, 9], [4, 3, 4, 3, 4, 3]]}]}\n",
      "\n",
      "Test Challenges:\n",
      "Key: 007bbfb7\n",
      "Sample Data: {'test': [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]]}], 'train': [{'input': [[0, 7, 7], [7, 7, 7], [0, 7, 7]], 'output': [[0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [7, 7, 7, 7, 7, 7, 7, 7, 7], [0, 7, 7, 0, 7, 7, 0, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7], [0, 0, 0, 7, 7, 7, 7, 7, 7], [0, 0, 0, 0, 7, 7, 0, 7, 7]]}, {'input': [[4, 0, 4], [0, 0, 0], [0, 4, 0]], 'output': [[4, 0, 4, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 4, 0, 0, 0, 0]]}, {'input': [[0, 0, 0], [0, 0, 2], [2, 0, 2]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 2, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 0, 2], [2, 0, 2, 0, 0, 0, 2, 0, 2]]}, {'input': [[6, 6, 0], [6, 0, 0], [0, 6, 6]], 'output': [[6, 6, 0, 6, 6, 0, 0, 0, 0], [6, 0, 0, 6, 0, 0, 0, 0, 0], [0, 6, 6, 0, 6, 6, 0, 0, 0], [6, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 6, 6, 0, 6, 6, 0], [0, 0, 0, 6, 0, 0, 6, 0, 0], [0, 0, 0, 0, 6, 6, 0, 6, 6]]}, {'input': [[2, 2, 2], [0, 0, 0], [0, 2, 2]], 'output': [[2, 2, 2, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 2, 2, 0, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2]]}]}\n",
      "\n",
      "Sample submission:\n",
      "Key: 007bbfb7\n",
      "Sample Data: [{'attempt_1': [[0, 0], [0, 0]], 'attempt_2': [[0, 0], [0, 0]]}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def inspect_data(data, num_samples=1):\n",
    "    for key, value in list(data.items())[:num_samples]:\n",
    "        print(f\"Key: {key}\")\n",
    "        print(f\"Sample Data: {value}\\n\")\n",
    "        \n",
    "print(\"Training Solutions:\")\n",
    "inspect_data(training_solutions)\n",
    "\n",
    "print(\"Training Challenges:\")\n",
    "inspect_data(training_challenges)\n",
    "\n",
    "print(\"Evaluation Solutions:\")\n",
    "inspect_data(evaluation_solutions)\n",
    "\n",
    "print(\"Evaluation Challenges:\")\n",
    "inspect_data(evaluation_challenges)\n",
    "\n",
    "print(\"Test Challenges:\")\n",
    "inspect_data(test_challenges)\n",
    "\n",
    "print(\"Sample submission:\")\n",
    "inspect_data(sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4829eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:23.865496Z",
     "iopub.status.busy": "2024-08-11T12:38:23.864288Z",
     "iopub.status.idle": "2024-08-11T12:38:23.870798Z",
     "shell.execute_reply": "2024-08-11T12:38:23.869622Z"
    },
    "papermill": {
     "duration": 0.026638,
     "end_time": "2024-08-11T12:38:23.874068",
     "exception": false,
     "start_time": "2024-08-11T12:38:23.847430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Key: 007bbfb7\n",
      "Sample Data: [[[7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 0, 7, 0, 0, 0, 7, 0, 7], [7, 7, 0, 0, 0, 0, 7, 7, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 0, 7, 7, 0, 7, 0, 0, 0], [7, 7, 0, 7, 7, 0, 0, 0, 0]]]\n"
     ]
    }
   ],
   "source": [
    "sample_key = list(training_solutions.keys())[0]\n",
    "print(f\"Sample Key: {sample_key}\")\n",
    "print(\"Sample Data:\", training_solutions[sample_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4a89a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:23.909851Z",
     "iopub.status.busy": "2024-08-11T12:38:23.908606Z",
     "iopub.status.idle": "2024-08-11T12:38:23.914504Z",
     "shell.execute_reply": "2024-08-11T12:38:23.913325Z"
    },
    "papermill": {
     "duration": 0.025964,
     "end_time": "2024-08-11T12:38:23.917012",
     "exception": false,
     "start_time": "2024-08-11T12:38:23.891048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#compute the mean, standard deviation, minimum, and maximum values of the data\n",
    "sample_data = training_solutions[sample_key]\n",
    "\n",
    "#convert to numpy array\n",
    "data_array = np.array(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf612ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:23.951172Z",
     "iopub.status.busy": "2024-08-11T12:38:23.950356Z",
     "iopub.status.idle": "2024-08-11T12:38:24.955178Z",
     "shell.execute_reply": "2024-08-11T12:38:24.953639Z"
    },
    "papermill": {
     "duration": 1.024671,
     "end_time": "2024-08-11T12:38:24.957675",
     "exception": false,
     "start_time": "2024-08-11T12:38:23.933004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Summary:\n",
      "Mean Value: 3.11\n",
      "Standard Deviation: 3.48\n",
      "Minimum Value: 0\n",
      "Maximum Value: 7\n",
      "\n",
      "Frequency Distribution:\n",
      "Value 0: 45 occurrences\n",
      "Value 7: 36 occurrences\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8gAAAIjCAYAAADfpjL3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuxElEQVR4nO3dd5RVhb3/7/cIAoNDlS5VxRqwgBorqFEkETUaUYIRBCMqFuI1RfNVURONeo0YNURMAiaKUbjXelXEblBjSbAXVMACdkHQUGf//nAxP8cBFRw4Bp9nrVnJ2afsz5l9ZiUv9t5nlxVFUQQAAAC+4dYp9QAAAADwdSCQAQAAIAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAZY68yYMSNlZWUZN25cqUf5UgYPHpzOnTuvkXV17tw5gwcPrro9bty4lJWV5bHHHlsj6+/du3d69+69Rtb1affee2/Kyspy7733rvF1fx2NHDkyZWVlpR4DgK8hgQxQQvvtt18aNmyYefPmrfAxAwcOTL169fLee++twclWzbLwWPbTsGHDdOzYMf369cvYsWOzcOHCWlnPs88+m5EjR2bGjBm18nq16es8W21atGhRLr744myzzTZp3LhxmjZtmi233DJHHXVUnn/++VKPt0Yt+4eWZT8NGjRIu3bt0qdPn/zud7/73L/vL/Lggw9m5MiRmTNnTu0NDMAK1S31AADfZAMHDszNN9+c66+/PocffniN+z/++OPceOON2WeffbL++uuXYMJVM3r06FRUVGThwoV54403MmnSpAwZMiSjRo3KLbfckg4dOlQ99oorrkhlZeVKvf6zzz6bM888M717916pvc8vvPBC1lln9f7b8OfNdscdd6zWda/Ibrvtln//+9+pV69erb3mQQcdlNtuuy0DBgzIj3/84yxevDjPP/98brnlluy0007ZbLPNam1d/ynOOuusdOnSJYsXL86bb76Ze++9NyNGjMhvf/vb3HTTTenevftKv+aDDz6YM888M4MHD07Tpk1rf2gAqhHIACW03377pVGjRhk/fvxyA/nGG2/MRx99lIEDB5ZgulX3gx/8IC1atKi6ffrpp+fqq6/O4YcfnoMPPjgPP/xw1X3rrrvuap2lKIosWLAg5eXlqV+//mpd1xepzUBdGeuss04aNGhQa6/36KOP5pZbbsmvf/3rnHrqqdXuu/TSS7+xezv79u2bnj17Vt0+5ZRTcvfdd2fffffNfvvtl+eeey7l5eUlnBCAL+IQa4ASKi8vz4EHHpi77rorb7/9do37x48fn0aNGmW//fbL+++/n5NPPjndunVLRUVFGjdunL59++aJJ574wvWs6NzX5Z3/W1lZmVGjRmXLLbdMgwYN0rp16wwbNiwffPDBqr7NJJ/sLT/yyCPzj3/8I5MnT/7cGf72t7+lR48eadSoURo3bpxu3brl4osvTvLJ4awHH3xwkmT33XevOqx12fm1nTt3zr777ptJkyalZ8+eKS8vz+WXX15136fPQV7m448/zrBhw7L++uuncePGOfzww2u837KysowcObLGcz/9ml802/K2w9tvv52hQ4emdevWadCgQbbaaqtceeWV1R6z7Lzy//7v/86YMWOy0UYbpX79+tluu+3y6KOPLvf3/WnLOwe5d+/e+da3vpVnn302u+++exo2bJgNNtgg559//he+3ssvv5wk2XnnnWvcV6dOnWpHO8ycOTPHHntsNt1005SXl2f99dfPwQcfXOMQ9GWHKf/973/PCSeckJYtW6Zp06YZNmxYFi1alDlz5uTwww9Ps2bN0qxZs/zsZz9LURTL/R1ddNFF6dSpU8rLy9OrV688/fTTX/iekuSqq65Kjx49Ul5enubNm+fQQw/Na6+99qWeuyJ77LFHTjvttMycOTNXXXVV1fInn3wygwcPzoYbbpgGDRqkTZs2GTJkSLVTKUaOHJmf/vSnSZIuXbpUfZ6W/e7Gjh2bPfbYI61atUr9+vWzxRZbZPTo0V9pXoBvOnuQAUps4MCBufLKK3PdddfluOOOq1r+/vvvZ9KkSRkwYEDKy8vzzDPP5IYbbsjBBx+cLl265K233srll1+eXr165dlnn027du1qZZ5hw4Zl3LhxOeKII3LCCSdk+vTpufTSS/Ovf/0rU6ZM+Up7fH/0ox9lzJgxueOOO7LXXnst9zGTJ0/OgAEDsueee+a8885Lkjz33HOZMmVKTjzxxOy222454YQT8rvf/S6nnnpqNt988ySp+s/kk0OpBwwYkGHDhuXHP/5xNt1008+d67jjjkvTpk0zcuTIvPDCCxk9enRmzpxZFZZf1peZ7dP+/e9/p3fv3nnppZdy3HHHpUuXLpkwYUIGDx6cOXPm5MQTT6z2+PHjx2fevHkZNmxYysrKcv755+fAAw/MK6+8skrb5YMPPsg+++yTAw88MP3798/EiRPz85//PN26dUvfvn1X+LxOnTolSa6++ursvPPOqVt3xf934tFHH82DDz6YQw89NO3bt8+MGTMyevTo9O7dO88++2waNmxY7fHHH3982rRpkzPPPDMPP/xwxowZk6ZNm+bBBx9Mx44dc8455+TWW2/NBRdckG9961s1jrz4y1/+knnz5mX48OFZsGBBLr744uyxxx556qmn0rp16xXO+etf/zqnnXZa+vfvnyOPPDLvvPNOLrnkkuy2227517/+9ZUOb/7Rj36UU089NXfccUd+/OMfJ/nkc/7KK6/kiCOOSJs2bfLMM89kzJgxeeaZZ/Lwww+nrKwsBx54YF588cVcc801ueiii6qOymjZsmWST05l2HLLLbPffvulbt26ufnmm3PsscemsrIyw4cPX+V5Ab7RCgBKasmSJUXbtm2LHXfcsdryP/zhD0WSYtKkSUVRFMWCBQuKpUuXVnvM9OnTi/r16xdnnXVWtWVJirFjx1Yt69WrV9GrV68a6x40aFDRqVOnqtsPPPBAkaS4+uqrqz3u9ttvX+7yzzrjjDOKJMU777yz3Ps/+OCDIknx/e9/f4UznHjiiUXjxo2LJUuWrHA9EyZMKJIU99xzT437OnXqVCQpbr/99uXeN2jQoKrbY8eOLZIUPXr0KBYtWlS1/Pzzzy+SFDfeeGPVsiTFGWec8YWv+XmzfXY7jBo1qkhSXHXVVVXLFi1aVOy4445FRUVF8eGHHxZF8f9v0/XXX794//33qx574403FkmKm2++uca6Pu2ee+6pMVOvXr2KJMVf/vKXqmULFy4s2rRpUxx00EGf+3qVlZVVz2/dunUxYMCA4rLLLitmzpxZ47Eff/xxjWUPPfRQjXUv2xZ9+vQpKisrq5bvuOOORVlZWXH00UdXLVuyZEnRvn37ar/LZb+j8vLy4vXXX69a/o9//KNIUvzkJz+pWrbsc7rMjBkzijp16hS//vWvq8351FNPFXXr1q2x/LOWzf7oo4+u8DFNmjQpttlmm6rby/u9XHPNNUWS4v77769adsEFFxRJiunTp9d4/PJeo0+fPsWGG274ufMCsGIOsQYosTp16uTQQw/NQw89VO2w0/Hjx6d169bZc889kyT169ev+oKppUuX5r333ktFRUU23XTT/POf/6yVWSZMmJAmTZpkr732yrvvvlv106NHj1RUVOSee+75Sq9fUVGRJJ/7rb5NmzbNRx99VO0w7JXVpUuX9OnT50s//qijjqq2B/aYY45J3bp1c+utt67yDF/GrbfemjZt2mTAgAFVy9Zdd92ccMIJmT9/fu67775qjz/kkEPSrFmzqtu77rprkuSVV15ZpfVXVFTksMMOq7pdr169bL/99l/4emVlZZk0aVJ+9atfpVmzZrnmmmsyfPjwdOrUKYcccki1c5A/fc7t4sWL895772XjjTdO06ZNl/u5HTp0aLW99jvssEOKosjQoUOrltWpUyc9e/Zc7pwHHHBANthgg6rb22+/fXbYYYfP3Zb/+7//m8rKyvTv37/a575Nmzbp2rXrV/7cJ5/8rj/9uf/072XBggV599138+1vfztJvvTf86dfY+7cuXn33XfTq1evvPLKK5k7d+5Xnhngm0ggA3wNLPsSrvHjxydJXn/99TzwwAM59NBDU6dOnSSfnBt80UUXpWvXrqlfv35atGiRli1b5sknn6y1/zM8bdq0zJ07N61atUrLli2r/cyfP3+550mvjPnz5ydJGjVqtMLHHHvssdlkk03St2/ftG/fPkOGDMntt9++Uuvp0qXLSj2+a9eu1W5XVFSkbdu2q/1STTNnzkzXrl1rfLP2skOyZ86cWW15x44dq91eFsuren54+/btaxxC3qxZsy/1evXr188vf/nLPPfcc5k1a1auueaafPvb365xqsC///3vnH766enQoUO1z+2cOXOW+7n97Hts0qRJklT75vNly5c352e3ZZJssskmn7stp02blqIo0rVr1xqf++eee+4rf+6TTz77n/7cv//++znxxBPTunXrlJeXp2XLllWf2y/79zxlypR85zvfyXrrrZemTZumZcuWVV+aJpABVo1zkAG+Bnr06JHNNtss11xzTU499dRcc801KYqi2rdXn3POOTnttNMyZMiQnH322WnevHnWWWedjBgx4gsvk1RWVlbtC42WWbp0abXblZWVadWqVa6++urlvs6ycx9X1bIvS9p4441X+JhWrVpl6tSpmTRpUm677bbcdtttGTt2bA4//PAaX161Imvym4I/+ztcnZb9Y8lnLW/brsnXa9u2bQ499NAcdNBB2XLLLXPddddl3LhxqVu3bo4//viMHTs2I0aMyI477pgmTZqkrKwshx566HI/tyuaaXnLV/V9f1ZlZWXKyspy2223LXc9y458WFWvv/565s6dW+1z379//zz44IP56U9/mq233joVFRWprKzMPvvs86Uue/byyy9nzz33zGabbZbf/va36dChQ+rVq5dbb701F1100UpfOg2ATwhkgK+JgQMH5rTTTsuTTz6Z8ePHp2vXrtluu+2q7p84cWJ23333/OlPf6r2vDlz5lS7pNLyNGvWbLmHo352D+VGG22UO++8MzvvvPNqicy//vWvSfKFhz/Xq1cv/fr1S79+/VJZWZljjz02l19+eU477bRsvPHGK/XFWV/GtGnTsvvuu1fdnj9/fmbPnp3vfve7VcuaNWtW4/JFixYtyuzZs6stW5nZOnXqlCeffDKVlZXV9iI///zzVff/J1l33XXTvXv3TJs2reoQ5YkTJ2bQoEG58MILqx63YMGC1XYpqGnTptVY9uKLL37u9bI32mijFEWRLl26ZJNNNqn1mT77uf/ggw9y11135cwzz8zpp59e9bjlzb6iz9PNN9+chQsX5qabbqq21702DgcH+CZziDXA18SyvcWnn356pk6dWuPax3Xq1Kmxx2zChAl54403vvC1N9poozz//PN55513qpY98cQTmTJlSrXH9e/fP0uXLs3ZZ59d4zWWLFnylaJm/Pjx+eMf/5gdd9yx6rzq5fn0ZW6ST67h27179yTJwoULkyTrrbdektRaZI0ZMyaLFy+uuj169OgsWbKk2jc5b7TRRrn//vtrPO+ze5BXZrbvfve7efPNN3PttddWLVuyZEkuueSSVFRUpFevXqvydla7adOm5dVXX62xfM6cOXnooYfSrFmzqqMNlve5veSSS1bbnvcbbrih2t/EI488kn/84x+f+63cBx54YOrUqZMzzzyzxqxFUdT4TK6Mu+++O2effXa6dOlS9Te9bC/1Z9c1atSoGs9f0edpea8xd+7cjB07dpVnBcAeZICvjS5dumSnnXbKjTfemCQ1AnnffffNWWedlSOOOCI77bRTnnrqqVx99dXZcMMNv/C1hwwZkt/+9rfp06dPhg4dmrfffjt/+MMfsuWWW+bDDz+selyvXr0ybNiwnHvuuZk6dWr23nvvrLvuupk2bVomTJiQiy++OD/4wQ++cH0TJ05MRUVFFi1alDfeeCOTJk3KlClTstVWW2XChAmf+9wjjzwy77//fvbYY4+0b98+M2fOzCWXXJKtt9666tzcrbfeOnXq1Ml5552XuXPnpn79+lXXg10VixYtyp577pn+/fvnhRdeyO9///vssssu2W+//arNdfTRR+eggw7KXnvtlSeeeCKTJk2qsfd+ZWY76qijcvnll2fw4MF5/PHH07lz50ycODFTpkzJqFGjPvdc7VJ64okn8sMf/jB9+/bNrrvumubNm+eNN97IlVdemVmzZmXUqFFVAbfvvvvmr3/9a5o0aZItttgiDz30UO68885q10quTRtvvHF22WWXHHPMMVm4cGFGjRqV9ddfPz/72c9W+JyNNtoov/rVr3LKKadkxowZOeCAA9KoUaNMnz49119/fY466qicfPLJX7ju2267Lc8//3yWLFmSt956K3fffXcmT56cTp065aabbkqDBg2SJI0bN85uu+2W888/P4sXL84GG2yQO+64I9OnT6/xmj169EiS/PKXv8yhhx6addddN/369cvee+9ddaTFsGHDMn/+/FxxxRVp1apVjaMaAFgJpfjqbACW77LLLiuSFNtvv32N+xYsWFD813/9V9G2bduivLy82HnnnYuHHnqoxqWDlneZp6IoiquuuqrYcMMNi3r16hVbb711MWnSpBqXWFpmzJgxRY8ePYry8vKiUaNGRbdu3Yqf/exnxaxZsz53/mWXz1n206BBg6J9+/bFvvvuW/z5z38uFixYUOM5n51h4sSJxd577120atWqqFevXtGxY8di2LBhxezZs6s974orrig23HDDok6dOtUuYdSpU6fie9/73nLnW9Flnu67777iqKOOKpo1a1ZUVFQUAwcOLN57771qz126dGnx85//vGjRokXRsGHDok+fPsVLL71U4zU/b7blXW7rrbfeKo444oiiRYsWRb169Ypu3brV2HbLtukFF1xQ4z1lBZef+rQVXeZpyy23rPHYFX0mPjvzb37zm6JXr15F27Zti7p16xbNmjUr9thjj2LixInVHvvBBx9Uvb+KioqiT58+xfPPP7/CbfHZSyWt6NJhgwYNKtZbb72q25/+HV144YVFhw4divr16xe77rpr8cQTTyz3NT/rf/7nf4pddtmlWG+99Yr11luv2GyzzYrhw4cXL7zwwuf+PpbNvuynXr16RZs2bYq99tqruPjii6su1/Vpr7/+evH973+/aNq0adGkSZPi4IMPLmbNmrXc7Xn22WcXG2ywQbHOOutUu+TTTTfdVHTv3r1o0KBB0blz5+K8884r/vznP6/wslAAfLGyoqilb7gAACiRGTNmpEuXLrngggu+1N5eAFge5yADAABABDIAAAAkEcgAAACQJHEOMgAAAMQeZAAAAEgikAEAACBJUndNr7CysjKzZs1Ko0aNUlZWtqZXDwAAwDdMURSZN29e2rVrl3XWWfF+4jUeyLNmzUqHDh3W9GoBAAD4hnvttdfSvn37Fd6/xgO5UaNGST4ZrHHjxmt69QAAAHzDfPjhh+nQoUNVj67IGg/kZYdVN27cWCADAACwxnzRab6+pAsAAAAikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIkdUs9wNfWoo8z++n78+aSxinqNij1NAAAAF87LVq0SMeOHUs9Rq0RyCsw++n70/amQ/K9y+fnX29WlnocAACAr50G5Q3zwvPPrTWRLJBXYM6cOWmbpOmuP0qbhtuUehwAAICvlcXvvZb3brkw7777rkD+pqjbtHXqN9+41GMAAACwmvmSLgAAAIhABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlAXqGFCxcmSYqli0s8CQAAwNdPsWRRkuTf//53iSepPQJ5BWbNmpUkWTrv/RJPAgAA8PWzZO5bSZIZM2aUdpBaJJABAAAgAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkqxDI999/f/r165d27dqlrKwsN9xww2oYCwAAANaslQ7kjz76KFtttVUuu+yy1TEPAAAAlETdlX1C375907dv39UxCwAAAJTMSgfyylq4cGEWLlxYdfvDDz9c3asEAACAlbbav6Tr3HPPTZMmTap+OnTosLpXCQAAACtttQfyKaeckrlz51b9vPbaa6t7lQAAALDSVvsh1vXr10/9+vVX92oAAADgK3EdZAAAAMgq7EGeP39+Xnrpparb06dPz9SpU9O8efN07NixVocDAACANWWlA/mxxx7L7rvvXnX7pJNOSpIMGjQo48aNq7XBAAAAYE1a6UDu3bt3iqJYHbMAAABAyTgHGQAAACKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAJ5hdq1a5ckqdOoeYknAQAA+Pqp26R1kqRz586lHaQWCeQVqF+/fpKkrM66JZ4EAADg66esbr0kSXl5eYknqT0CGQAAACKQAQAAIIlABgAAgCQCGQAAAJIIZAAAAEgikAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASJLULfUAX3dL5ryVhYteKvUYAAAAXyuL33ut1CPUOoG8Ak2bNk2SzHngr3nzzStLOwwAAMDXUIPyhmnRokWpx6g1AnkF2n5rt8zOtfnTdxunqNug1OMAAAB87bRo0SIdO3Ys9Ri1RiCvSL2GabvtPmlb6jkAAABYI3xJFwAAAEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkEcgAAACQRCADAABAEoEMAAAASQQyAAAAJBHIAAAAkCSpu6ZXWBRFkuTDDz9c06sGAADgG2hZfy7r0RVZ44E8b968JEmHDh3W9KoBAAD4Bps3b16aNGmywvvLii9K6FpWWVmZWbNmpVGjRikrK1uTq14pH374YTp06JDXXnstjRs3LvU4rAa28drN9l372cZrP9t47Wcbr/1s47Xbf9L2LYoi8+bNS7t27bLOOis+03iN70FeZ5110r59+zW92lXWuHHjr/3G5quxjddutu/azzZe+9nGaz/beO1nG6/d/lO27+ftOV7Gl3QBAABABDIAAAAkEcgrVL9+/ZxxxhmpX79+qUdhNbGN126279rPNl772cZrP9t47Wcbr93Wxu27xr+kCwAAAL6O7EEGAACACGQAAABIIpABAAAgiUAGAACAJAJ5uS677LJ07tw5DRo0yA477JBHHnmk1CNRi+6///7069cv7dq1S1lZWW644YZSj0QtOvfcc7PddtulUaNGadWqVQ444IC88MILpR6LWjR69Oh07949jRs3TuPGjbPjjjvmtttuK/VYrCa/+c1vUlZWlhEjRpR6FGrJyJEjU1ZWVu1ns802K/VY1LI33ngjhx12WNZff/2Ul5enW7dueeyxx0o9FrWkc+fONf6Oy8rKMnz48FKP9pUJ5M+49tprc9JJJ+WMM87IP//5z2y11Vbp06dP3n777VKPRi356KOPstVWW+Wyyy4r9SisBvfdd1+GDx+ehx9+OJMnT87ixYuz995756OPPir1aNSS9u3b5ze/+U0ef/zxPPbYY9ljjz2y//7755lnnin1aNSyRx99NJdffnm6d+9e6lGoZVtuuWVmz55d9fP3v/+91CNRiz744IPsvPPOWXfddXPbbbfl2WefzYUXXphmzZqVejRqyaOPPlrtb3jy5MlJkoMPPrjEk311LvP0GTvssEO22267XHrppUmSysrKdOjQIccff3x+8YtflHg6altZWVmuv/76HHDAAaUehdXknXfeSatWrXLfffdlt912K/U4rCbNmzfPBRdckKFDh5Z6FGrJ/Pnzs+222+b3v/99fvWrX2XrrbfOqFGjSj0WtWDkyJG54YYbMnXq1FKPwmryi1/8IlOmTMkDDzxQ6lFYQ0aMGJFbbrkl06ZNS1lZWanH+UrsQf6URYsW5fHHH893vvOdqmXrrLNOvvOd7+Shhx4q4WTAqpo7d26STwKKtc/SpUvzt7/9LR999FF23HHHUo9DLRo+fHi+973vVfvfZNYe06ZNS7t27bLhhhtm4MCBefXVV0s9ErXopptuSs+ePXPwwQenVatW2WabbXLFFVeUeixWk0WLFuWqq67KkCFD/uPjOBHI1bz77rtZunRpWrduXW1569at8+abb5ZoKmBVVVZWZsSIEdl5553zrW99q9TjUIueeuqpVFRUpH79+jn66KNz/fXXZ4sttij1WNSSv/3tb/nnP/+Zc889t9SjsBrssMMOGTduXG6//faMHj0606dPz6677pp58+aVejRqySuvvJLRo0ena9eumTRpUo455piccMIJufLKK0s9GqvBDTfckDlz5mTw4MGlHqVW1C31AACry/Dhw/P00087t20ttOmmm2bq1KmZO3duJk6cmEGDBuW+++4TyWuB1157LSeeeGImT56cBg0alHocVoO+fftW/ffu3btnhx12SKdOnXLdddc5TWItUVlZmZ49e+acc85JkmyzzTZ5+umn84c//CGDBg0q8XTUtj/96U/p27dv2rVrV+pRaoU9yJ/SokWL1KlTJ2+99Va15W+99VbatGlToqmAVXHcccfllltuyT333JP27duXehxqWb169bLxxhunR48eOffcc7PVVlvl4osvLvVY1ILHH388b7/9drbddtvUrVs3devWzX333Zff/e53qVu3bpYuXVrqEallTZs2zSabbJKXXnqp1KNQS9q2bVvjHyw333xzh9KvhWbOnJk777wzRx55ZKlHqTUC+VPq1auXHj165K677qpaVllZmbvuusu5bfAfoiiKHHfccbn++utz9913p0uXLqUeiTWgsrIyCxcuLPUY1II999wzTz31VKZOnVr107NnzwwcODBTp05NnTp1Sj0itWz+/Pl5+eWX07Zt21KPQi3Zeeeda1xi8cUXX0ynTp1KNBGry9ixY9OqVat873vfK/UotcYh1p9x0kknZdCgQenZs2e23377jBo1Kh999FGOOOKIUo9GLZk/f361f6WePn16pk6dmubNm6djx44lnIzaMHz48IwfPz433nhjGjVqVPX9AU2aNEl5eXmJp6M2nHLKKenbt286duyYefPmZfz48bn33nszadKkUo9GLWjUqFGN7wxYb731sv766/sugbXEySefnH79+qVTp06ZNWtWzjjjjNSpUycDBgwo9WjUkp/85CfZaaedcs4556R///555JFHMmbMmIwZM6bUo1GLKisrM3bs2AwaNCh16649Wbn2vJNacsghh+Sdd97J6aefnjfffDNbb711br/99hpf3MV/rsceeyy777571e2TTjopSTJo0KCMGzeuRFNRW0aPHp0k6d27d7XlY8eOXWu+POKb7u23387hhx+e2bNnp0mTJunevXsmTZqUvfbaq9SjAV/C66+/ngEDBuS9995Ly5Yts8suu+Thhx9Oy5YtSz0atWS77bbL9ddfn1NOOSVnnXVWunTpklGjRmXgwIGlHo1adOedd+bVV1/NkCFDSj1KrXIdZAAAAIhzkAEAACCJQAYAAIAkAhkAAACSCGQAAABIIpABAAAgiUAGAACAJAIZAAAAkghkAAAASCKQAeA/Qu/evTNixIhSjwEAazWBDACrWb9+/bLPPvss974HHnggZWVlefLJJ9fwVADAZwlkAFjNhg4dmsmTJ+f111+vcd/YsWPTs2fPdO/evQSTAQCfJpABYDXbd99907Jly4wbN67a8vnz52fChAk54IADMmDAgGywwQZp2LBhunXrlmuuueZzX7OsrCw33HBDtWVNmzatto7XXnst/fv3T9OmTdO8efPsv//+mTFjRu28KQBYCwlkAFjN6tatm8MPPzzjxo1LURRVyydMmJClS5fmsMMOS48ePfJ///d/efrpp3PUUUflRz/6UR555JFVXufixYvTp0+fNGrUKA888ECmTJmSioqK7LPPPlm0aFFtvC0AWOsIZABYA4YMGZKXX3459913X9WysWPH5qCDDkqnTp1y8sknZ+utt86GG26Y448/Pvvss0+uu+66VV7ftddem8rKyvzxj39Mt27dsvnmm2fs2LF59dVXc++999bCOwKAtY9ABoA1YLPNNstOO+2UP//5z0mSl156KQ888ECGDh2apUuX5uyzz063bt3SvHnzVFRUZNKkSXn11VdXeX1PPPFEXnrppTRq1CgVFRWpqKhI8+bNs2DBgrz88su19bYAYK1St9QDAMA3xdChQ3P88cfnsssuy9ixY7PRRhulV69eOe+883LxxRdn1KhR6datW9Zbb72MGDHicw+FLisrq3a4dvLJYdXLzJ8/Pz169MjVV19d47ktW7asvTcFAGsRgQwAa0j//v1z4oknZvz48fnLX/6SY445JmVlZZkyZUr233//HHbYYUmSysrKvPjii9liiy1W+FotW7bM7Nmzq25PmzYtH3/8cdXtbbfdNtdee21atWqVxo0br743BQBrEYdYA8AaUlFRkUMOOSSnnHJKZs+encGDBydJunbtmsmTJ+fBBx/Mc889l2HDhuWtt9763NfaY489cumll+Zf//pXHnvssRx99NFZd911q+4fOHBgWrRokf333z8PPPBApk+fnnvvvTcnnHDCci83BQAIZABYo4YOHZoPPvggffr0Sbt27ZIk/+///b9su+226dOnT3r37p02bdrkgAMO+NzXufDCC9OhQ4fsuuuu+eEPf5iTTz45DRs2rLq/YcOGuf/++9OxY8cceOCB2XzzzTN06NAsWLDAHmUAWIGy4rMnMAEAAMA3kD3IAAAAEIEMAAAASQQyAAAAJBHIAAAAkEQgAwAAQBKBDAAAAEkEMgAAACQRyAAAAJBEIAMAAEASgQwAAABJBDIAAAAkSf4/OGDUSqZ9ZuUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram Summary:\n",
      "Mean Value: 3.11\n",
      "Median Value: 0.00\n",
      "Minimum Value: 0\n",
      "Maximum Value: 7\n",
      "\n",
      "Frequency Distribution:\n",
      "Value 0: 45 occurrences\n",
      "Value 7: 36 occurrences\n",
      "Boxplot Summary:\n",
      "Median Value: 0.00\n",
      "1st Quartile (Q1): 0.00\n",
      "3rd Quartile (Q3): 7.00\n",
      "Interquartile Range (IQR): 7.00\n",
      "Minimum Value: 0\n",
      "Maximum Value: 7\n",
      "Number of Outliers: 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "def plot_grid(data, title=\"Grid Visualization\"):\n",
    "    #remove any singleton dimensions\n",
    "    data_squeezed = np.squeeze(data)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(data_squeezed, cmap='viridis', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def summarize_grid(data):\n",
    "    #calculate basic statistics\n",
    "    mean = np.mean(data)\n",
    "    std_dev = np.std(data)\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    \n",
    "    #frequency distribution\n",
    "    flat_data = data.flatten()\n",
    "    freq_dist = Counter(flat_data)\n",
    "    \n",
    "    return mean, std_dev, min_val, max_val, freq_dist\n",
    "\n",
    "def print_summary(mean, std_dev, min_val, max_val, freq_dist):\n",
    "    print(\"Grid Summary:\")\n",
    "    print(f\"Mean Value: {mean:.2f}\")\n",
    "    print(f\"Standard Deviation: {std_dev:.2f}\")\n",
    "    print(f\"Minimum Value: {min_val}\")\n",
    "    print(f\"Maximum Value: {max_val}\")\n",
    "    print(\"\\nFrequency Distribution:\")\n",
    "    for value, count in sorted(freq_dist.items()):\n",
    "        print(f\"Value {value}: {count} occurrences\")\n",
    "\n",
    "def plot_histogram(data, title=\"Histogram of Data Values\"):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(data.flatten(), bins=range(int(np.min(data)), int(np.max(data)) + 2), color='blue', alpha=0.7, edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "def plot_value_distribution(data, title=\"Value Distribution\"):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.boxplot(data.flatten(), vert=False, patch_artist=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Value')\n",
    "    plt.show()\n",
    "\n",
    "def summarize_histogram(data):\n",
    "    flat_data = data.flatten()\n",
    "    mean = np.mean(flat_data)\n",
    "    median = np.median(flat_data)\n",
    "    min_val = np.min(flat_data)\n",
    "    max_val = np.max(flat_data)\n",
    "    unique, counts = np.unique(flat_data, return_counts=True)\n",
    "    freq_dist = dict(zip(unique, counts))\n",
    "    \n",
    "    print(\"Histogram Summary:\")\n",
    "    print(f\"Mean Value: {mean:.2f}\")\n",
    "    print(f\"Median Value: {median:.2f}\")\n",
    "    print(f\"Minimum Value: {min_val}\")\n",
    "    print(f\"Maximum Value: {max_val}\")\n",
    "    print(\"\\nFrequency Distribution:\")\n",
    "    for value, count in sorted(freq_dist.items()):\n",
    "        print(f\"Value {value}: {count} occurrences\")\n",
    "\n",
    "def summarize_boxplot(data):\n",
    "    flat_data = data.flatten()\n",
    "    median = np.median(flat_data)\n",
    "    q1 = np.percentile(flat_data, 25)\n",
    "    q3 = np.percentile(flat_data, 75)\n",
    "    iqr = q3 - q1\n",
    "    min_val = np.min(flat_data)\n",
    "    max_val = np.max(flat_data)\n",
    "    outliers = flat_data[(flat_data < (q1 - 1.5 * iqr)) | (flat_data > (q3 + 1.5 * iqr))]\n",
    "\n",
    "    print(\"Boxplot Summary:\")\n",
    "    print(f\"Median Value: {median:.2f}\")\n",
    "    print(f\"1st Quartile (Q1): {q1:.2f}\")\n",
    "    print(f\"3rd Quartile (Q3): {q3:.2f}\")\n",
    "    print(f\"Interquartile Range (IQR): {iqr:.2f}\")\n",
    "    print(f\"Minimum Value: {min_val}\")\n",
    "    print(f\"Maximum Value: {max_val}\")\n",
    "    print(f\"Number of Outliers: {len(outliers)}\")\n",
    "    if len(outliers) > 0:\n",
    "        print(\"Outlier Values:\", np.unique(outliers))\n",
    "\n",
    "#plot the grid\n",
    "plot_grid(data_array, title=\"Sample Grid Visualization\")\n",
    "\n",
    "#get statistics and frequency distribution\n",
    "mean, std_dev, min_val, max_val, freq_dist = summarize_grid(data_array)\n",
    "\n",
    "#print textual summary\n",
    "print_summary(mean, std_dev, min_val, max_val, freq_dist)\n",
    "\n",
    "#plot histogram and boxplot\n",
    "plot_histogram(data_array, title=\"Histogram of Sample Data Values\")\n",
    "plot_value_distribution(data_array, title=\"Value Distribution in Sample Data\")\n",
    "\n",
    "#print textual summaries for histogram and boxplot\n",
    "summarize_histogram(data_array)\n",
    "summarize_boxplot(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f31200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:24.993553Z",
     "iopub.status.busy": "2024-08-11T12:38:24.993069Z",
     "iopub.status.idle": "2024-08-11T12:38:25.052669Z",
     "shell.execute_reply": "2024-08-11T12:38:25.051098Z"
    },
    "papermill": {
     "duration": 0.080771,
     "end_time": "2024-08-11T12:38:25.055448",
     "exception": false,
     "start_time": "2024-08-11T12:38:24.974677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (400, 576)\n",
      "y_train shape: (400, 576)\n",
      "X_test shape: (100, 576)\n"
     ]
    }
   ],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, training_data, test_data, target_shape=(24, 24)):\n",
    "        self.training_data = training_data\n",
    "        self.test_data = test_data\n",
    "        self.target_shape = target_shape\n",
    "\n",
    "    def resize_array(self, array):\n",
    "        \"\"\"Resize array to the target dimensions with padding or cropping.\"\"\"\n",
    "        array = np.array(array)\n",
    "        original_shape = array.shape\n",
    "\n",
    "        #handle arrays smaller than the target shape\n",
    "        if original_shape[0] < self.target_shape[0]:\n",
    "            padded_array = np.zeros((self.target_shape[0], array.shape[1]), dtype=array.dtype)\n",
    "            padded_array[:array.shape[0], :] = array\n",
    "            array = padded_array\n",
    "        if original_shape[1] < self.target_shape[1]:\n",
    "            padded_array = np.zeros((array.shape[0], self.target_shape[1]), dtype=array.dtype)\n",
    "            padded_array[:, :array.shape[1]] = array\n",
    "            array = padded_array\n",
    "\n",
    "        #handle arrays larger than the target shape\n",
    "        if array.shape[0] > self.target_shape[0]:\n",
    "            array = array[:self.target_shape[0], :]\n",
    "        if array.shape[1] > self.target_shape[1]:\n",
    "            array = array[:, :self.target_shape[1]]\n",
    "\n",
    "        return array\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        X_train_list = []\n",
    "        y_train_list = []\n",
    "        X_test_list = []\n",
    "\n",
    "        #process training data (one entry per key)\n",
    "        for key, entries in self.training_data.items():\n",
    "            if isinstance(entries, dict):\n",
    "                #assume each key has a 'train' entry with one set of input-output data\n",
    "                train_entry = entries.get('train', [])\n",
    "                if train_entry:\n",
    "                    entry = train_entry[0]  #take only the first entry for each key\n",
    "                    X = entry.get('input', [])\n",
    "                    y = entry.get('output', [])\n",
    "                    \n",
    "                    try:\n",
    "                        X = self.resize_array(X)\n",
    "                        y = self.resize_array(y)\n",
    "                        \n",
    "                        if X.shape == y.shape:\n",
    "                            X_train_list.append(X.flatten())\n",
    "                            y_train_list.append(y.flatten())\n",
    "                        else:\n",
    "                            print(f\"Skipping inconsistent entry for key {key}. X shape: {X.shape}, y shape: {y.shape}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing entry for key {key}: {e}\")\n",
    "        \n",
    "        #convert lists to NumPy arrays\n",
    "        self.X_train = np.array(X_train_list)\n",
    "        self.y_train = np.array(y_train_list)\n",
    "\n",
    "        #process test data (one entry per key)\n",
    "        for key, entries in self.test_data.items():\n",
    "            if isinstance(entries, dict):\n",
    "                #assume each key has a 'test' entry with one set of input data\n",
    "                test_entry = entries.get('test', [])\n",
    "                if test_entry:\n",
    "                    entry = test_entry[0]  #take only the first entry for each key\n",
    "                    X = entry.get('input', [])\n",
    "                    \n",
    "                    try:\n",
    "                        X = self.resize_array(X)\n",
    "                        X_test_list.append(X.flatten())\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing test entry for key {key}: {e}\")\n",
    "        \n",
    "        #convert lists to NumPy arrays\n",
    "        self.X_test = np.array(X_test_list)\n",
    "\n",
    "    def get_preprocessed_data(self):\n",
    "        return self.X_train, self.y_train, self.X_test\n",
    "\n",
    "#initialize and process data\n",
    "data_processor = DataProcessor(training_challenges, test_challenges)\n",
    "data_processor.preprocess_data()\n",
    "\n",
    "#retrieve preprocessed data\n",
    "try:\n",
    "    X_train, y_train, X_test = data_processor.get_preprocessed_data()\n",
    "    if X_train is not None and y_train is not None and X_test is not None:\n",
    "        #print the results to verify\n",
    "        print(\"X_train shape:\", X_train.shape)  #should be (400, 576)\n",
    "        print(\"y_train shape:\", y_train.shape)  #should be (400, 576)\n",
    "        print(\"X_test shape:\", X_test.shape)    #should be (100, 576)\n",
    "    else:\n",
    "        print(\"Data processing did not complete successfully.\")\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError: {e}. The data may not have been processed correctly.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b9ac24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:25.092718Z",
     "iopub.status.busy": "2024-08-11T12:38:25.091951Z",
     "iopub.status.idle": "2024-08-11T12:38:34.004333Z",
     "shell.execute_reply": "2024-08-11T12:38:34.003141Z"
    },
    "papermill": {
     "duration": 8.934391,
     "end_time": "2024-08-11T12:38:34.007281",
     "exception": false,
     "start_time": "2024-08-11T12:38:25.072890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import librairies\n",
    "import torch\n",
    "import shap\n",
    "import re\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.nn.utils import prune\n",
    "import torch.quantization as quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22558cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.043948Z",
     "iopub.status.busy": "2024-08-11T12:38:34.043316Z",
     "iopub.status.idle": "2024-08-11T12:38:34.060927Z",
     "shell.execute_reply": "2024-08-11T12:38:34.059543Z"
    },
    "papermill": {
     "duration": 0.039045,
     "end_time": "2024-08-11T12:38:34.063670",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.024625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class IntegratedRepresentationLearning(nn.Module):\n",
    "    \"\"\"\n",
    "    A class to handle the integrated representation learning from various data types\n",
    "    like text, images, and numerical data.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text_model_name=\"bert-base-uncased\", img_input_size=(32, 32), num_input_dim=10):\n",
    "        super(IntegratedRepresentationLearning, self).__init__()\n",
    "        \n",
    "        #initialize components for different data types\n",
    "        \n",
    "        #text processing model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(text_model_name)\n",
    "        self.text_model = AutoModel.from_pretrained(text_model_name)\n",
    "        \n",
    "        #image processing model\n",
    "        self.image_model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * (img_input_size[0] // 4) * (img_input_size[1] // 4), 128),  #adjusted for general input size\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        \n",
    "        #numerical data processing model\n",
    "        self.numerical_model = nn.Sequential(\n",
    "            nn.Linear(num_input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        \n",
    "        #final unified representation layer\n",
    "        #output dimensions are determined by the dimensions of the individual representations\n",
    "        self.fc = nn.Linear(64 + self.text_model.config.hidden_size + 16, 256)  #combine all features\n",
    "    \n",
    "    def process_input(self, text_data=None, image_data=None, numerical_data=None):\n",
    "        \"\"\"Process various input data types into a unified representation.\"\"\"\n",
    "        \n",
    "        representations = []\n",
    "        \n",
    "        #process text data if provided\n",
    "        if text_data is not None:\n",
    "            tokens = self.tokenizer(text_data, return_tensors='pt', padding=True, truncation=True)\n",
    "            text_output = self.text_model(**tokens)\n",
    "            text_representation = text_output.last_hidden_state[:, 0, :]  #[CLS] token representation\n",
    "            representations.append(text_representation)\n",
    "        \n",
    "        #process image data if provided\n",
    "        if image_data is not None:\n",
    "            image_representation = self.image_model(image_data)\n",
    "            representations.append(image_representation)\n",
    "        \n",
    "        #process numerical data if provided\n",
    "        if numerical_data is not None:\n",
    "            numerical_representation = self.numerical_model(numerical_data)\n",
    "            representations.append(numerical_representation)\n",
    "        \n",
    "        #concatenate all representations\n",
    "        if representations:\n",
    "            unified_representation = torch.cat(representations, dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"No input data provided!\")\n",
    "        \n",
    "        #pass through the final fully connected layer to get the unified representation\n",
    "        unified_representation = self.fc(unified_representation)\n",
    "        \n",
    "        return unified_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f73c65c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.100057Z",
     "iopub.status.busy": "2024-08-11T12:38:34.099663Z",
     "iopub.status.idle": "2024-08-11T12:38:34.116382Z",
     "shell.execute_reply": "2024-08-11T12:38:34.115130Z"
    },
    "papermill": {
     "duration": 0.038027,
     "end_time": "2024-08-11T12:38:34.118992",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.080965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiModalInputs:\n",
    "    \"\"\"Initialize the multi-modal input handler.\"\"\"\n",
    "\n",
    "    def __init__(self, data_processor, text_model_name=\"bert-base-uncased\", num_input_dim=10):\n",
    "        self.data_processor = data_processor\n",
    "        \n",
    "        #initialize tokenizer and model for text data\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(text_model_name)\n",
    "        self.text_model = AutoModel.from_pretrained(text_model_name)\n",
    "        \n",
    "        #initialize numerical data processing model\n",
    "        self.numerical_model = nn.Sequential(\n",
    "            nn.Linear(num_input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "\n",
    "    def handle_input(self):\n",
    "        \"\"\"\n",
    "        Handle diverse input formats and integrate them into a common pipeline\n",
    "        using data from DataProcessor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: A tensor containing the integrated representation of all inputs.\n",
    "        \"\"\"\n",
    "        #get preprocessed data\n",
    "        X_train, y_train, X_test = self.data_processor.get_preprocessed_data()\n",
    "        \n",
    "        if X_train is None or y_train is None or X_test is None:\n",
    "            raise ValueError(\"Data processing did not complete successfully.\")\n",
    "        \n",
    "        #convert preprocessed data into tensors\n",
    "        numerical_data_train = torch.tensor(X_train, dtype=torch.float)\n",
    "        numerical_data_test = torch.tensor(X_test, dtype=torch.float)\n",
    "        \n",
    "        #ensure numerical data matches the expected input dimension\n",
    "        if numerical_data_train.shape[1] != 10:\n",
    "            #reduce dimensions or perform a transformation to match the expected input size\n",
    "            reduction_layer = nn.Linear(numerical_data_train.shape[1], 10)\n",
    "            numerical_data_train = reduction_layer(numerical_data_train)\n",
    "            numerical_data_test = reduction_layer(numerical_data_test)\n",
    "        \n",
    "        #retrieve actual text data from DataProcessor\n",
    "        #assuming text data needs to be aligned with numerical data\n",
    "        text_data_train = [\"Actual text data for entry {}\".format(i) for i in range(X_train.shape[0])]\n",
    "        text_data_test = [\"Actual text data for entry {}\".format(i) for i in range(X_test.shape[0])]\n",
    "        \n",
    "        #tokenize and process text data\n",
    "        text_tokens_train = self.tokenizer(text_data_train, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        text_tokens_test = self.tokenizer(text_data_test, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        text_outputs_train = self.text_model(**text_tokens_train)\n",
    "        text_outputs_test = self.text_model(**text_tokens_test)\n",
    "        \n",
    "        text_representation_train = text_outputs_train.last_hidden_state[:, 0, :]  # [CLS] token representation\n",
    "        text_representation_test = text_outputs_test.last_hidden_state[:, 0, :]  # [CLS] token representation\n",
    "        \n",
    "        #process numerical data\n",
    "        numerical_representation_train = self.numerical_model(numerical_data_train)\n",
    "        numerical_representation_test = self.numerical_model(numerical_data_test)\n",
    "        \n",
    "        #combine representations\n",
    "        combined_train = torch.cat([text_representation_train, numerical_representation_train], dim=1)\n",
    "        combined_test = torch.cat([text_representation_test, numerical_representation_test], dim=1)\n",
    "        \n",
    "        return combined_train, combined_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18739b78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.155419Z",
     "iopub.status.busy": "2024-08-11T12:38:34.154516Z",
     "iopub.status.idle": "2024-08-11T12:38:34.161098Z",
     "shell.execute_reply": "2024-08-11T12:38:34.159782Z"
    },
    "papermill": {
     "duration": 0.028249,
     "end_time": "2024-08-11T12:38:34.164309",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.136060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#calculate complexity based on the data's characteristics\n",
    "complexity = min(max(1, len(X_train) // 1000), 5)\n",
    "print(complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d629e810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.200573Z",
     "iopub.status.busy": "2024-08-11T12:38:34.200135Z",
     "iopub.status.idle": "2024-08-11T12:38:34.209507Z",
     "shell.execute_reply": "2024-08-11T12:38:34.208099Z"
    },
    "papermill": {
     "duration": 0.030499,
     "end_time": "2024-08-11T12:38:34.212292",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.181793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdaptiveNeuralNetworkLayers:\n",
    "    \"\"\"Initialize the adaptive neural network layers.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.base_units = 64  #base units for simplicity\n",
    "\n",
    "    def adapt_network(self, complexity):\n",
    "        \"\"\"\n",
    "        Adjust network architecture based on task complexity.\n",
    "\n",
    "        Parameters:\n",
    "            complexity (int): A parameter that indicates the complexity level.\n",
    "                               For this case, we assume complexity = 1.\n",
    "\n",
    "        Returns:\n",
    "            nn.Module: The adapted neural network.\n",
    "        \"\"\"\n",
    "        if complexity != 1:\n",
    "            raise ValueError(\"For this implementation, complexity must be 1.\")\n",
    "        \n",
    "        #for simplicity with complexity = 1, we will use a minimal network\n",
    "        num_units = self.base_units * complexity\n",
    "\n",
    "        #create a minimal adaptive network\n",
    "        layers = []\n",
    "        input_dim = 576\n",
    "\n",
    "        #input layer\n",
    "        layers.append(nn.Linear(input_dim, num_units))\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        #output layer\n",
    "        layers.append(nn.Linear(num_units, 1))\n",
    "\n",
    "        #create the network\n",
    "        adaptive_network = nn.Sequential(*layers)\n",
    "\n",
    "        return adaptive_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5324bd64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.249056Z",
     "iopub.status.busy": "2024-08-11T12:38:34.248654Z",
     "iopub.status.idle": "2024-08-11T12:38:34.261367Z",
     "shell.execute_reply": "2024-08-11T12:38:34.260043Z"
    },
    "papermill": {
     "duration": 0.034331,
     "end_time": "2024-08-11T12:38:34.264027",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.229696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HierarchicalAttentionMechanisms:\n",
    "    \"\"\"Initialize the hierarchical attention mechanisms.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the hierarchical attention mechanisms.\n",
    "\n",
    "        Parameters:\n",
    "            input_dim (int): Dimension of the input features.\n",
    "            hidden_dim (int): Dimension of hidden layers in the attention mechanism.\n",
    "            output_dim (int): Dimension of the final output.\n",
    "        \"\"\"\n",
    "        super(HierarchicalAttentionMechanisms, self).__init__()\n",
    "        \n",
    "        #define layers for hierarchical attention\n",
    "        self.attention_layer1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attention_layer2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.fc = nn.Linear(output_dim, 1)  #final layer for output\n",
    "        \n",
    "    def attention(self, query, key, value):\n",
    "        \"\"\"\n",
    "        Apply scaled dot-product attention mechanism.\n",
    "\n",
    "        Parameters:\n",
    "            query (Tensor): Query tensor.\n",
    "            key (Tensor): Key tensor.\n",
    "            value (Tensor): Value tensor.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output of the attention mechanism.\n",
    "        \"\"\"\n",
    "        #compute attention scores\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / (key.size(-1) ** 0.5)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(weights, value)\n",
    "        return output\n",
    "\n",
    "    def apply_attention(self, data):\n",
    "        \"\"\"\n",
    "        Apply hierarchical attention to capture patterns at various abstraction levels.\n",
    "\n",
    "        Parameters:\n",
    "            data (Tensor): Input tensor data.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output after applying hierarchical attention.\n",
    "        \"\"\"\n",
    "        #assume `data` is of shape (batch_size, input_dim)\n",
    "        batch_size, input_dim = data.shape\n",
    "\n",
    "        #reshape data for attention mechanism (add dummy sequence length dimension)\n",
    "        data_reshaped = data.unsqueeze(1)\n",
    "\n",
    "        #initial attention\n",
    "        x = self.attention_layer1(data_reshaped)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #hierarchical attention level 1\n",
    "        attn_output1 = self.attention(x, x, x)\n",
    "        \n",
    "        #flatten the output for further processing\n",
    "        attn_output1 = attn_output1.mean(dim=1)\n",
    "        \n",
    "        #hierarchical attention level 2\n",
    "        x = self.attention_layer2(attn_output1.unsqueeze(1))\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #flatten the output for the final layer\n",
    "        attn_output2 = x.mean(dim=1)\n",
    "        \n",
    "        #final output layer\n",
    "        attention_output = self.fc(attn_output2)\n",
    "        \n",
    "        return attention_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c13b980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.300309Z",
     "iopub.status.busy": "2024-08-11T12:38:34.299920Z",
     "iopub.status.idle": "2024-08-11T12:38:34.307623Z",
     "shell.execute_reply": "2024-08-11T12:38:34.306408Z"
    },
    "papermill": {
     "duration": 0.0287,
     "end_time": "2024-08-11T12:38:34.309925",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.281225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SymbolicReasoningIntegration:\n",
    "    \"\"\"Initialize symbolic reasoning integration.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        \"\"\"\n",
    "        Initialize the symbolic reasoning integration.\n",
    "\n",
    "        Parameters:\n",
    "            input_dim (int): Dimension of the input features.\n",
    "        \"\"\"\n",
    "        super(SymbolicReasoningIntegration, self).__init__()\n",
    "        \n",
    "        #define a simple symbolic reasoning mechanism\n",
    "        self.symbolic_layer = nn.Linear(input_dim, input_dim)\n",
    "\n",
    "    def reason(self, data):\n",
    "        \"\"\"\n",
    "        Integrate symbolic reasoning with neural learning.\n",
    "\n",
    "        Parameters:\n",
    "            data (Tensor): Input tensor data.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output after applying symbolic reasoning.\n",
    "        \"\"\"\n",
    "        #apply symbolic reasoning\n",
    "        reasoned_output = self.symbolic_layer(data)\n",
    "        \n",
    "        reasoned_output = torch.tanh(reasoned_output)  # Non-linearity for enhancement\n",
    "        \n",
    "        return reasoned_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a3b9664",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.346662Z",
     "iopub.status.busy": "2024-08-11T12:38:34.345662Z",
     "iopub.status.idle": "2024-08-11T12:38:34.354799Z",
     "shell.execute_reply": "2024-08-11T12:38:34.353492Z"
    },
    "papermill": {
     "duration": 0.030318,
     "end_time": "2024-08-11T12:38:34.357561",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.327243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralSymbolicFusion:\n",
    "    \"\"\"Initialize the neural-symbolic fusion module.\"\"\"\n",
    "    \n",
    "    def __init__(self, neural_output_dim, symbolic_output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the neural-symbolic fusion module.\n",
    "\n",
    "        Parameters:\n",
    "            neural_output_dim (int): Dimension of the neural network output.\n",
    "            symbolic_output_dim (int): Dimension of the symbolic reasoning output.\n",
    "        \"\"\"\n",
    "        super(NeuralSymbolicFusion, self).__init__()\n",
    "        \n",
    "        #define a layer to fuse neural and symbolic outputs\n",
    "        self.fusion_layer = nn.Linear(neural_output_dim + symbolic_output_dim, 128)\n",
    "        self.output_layer = nn.Linear(128, 1)  #final output layer\n",
    "\n",
    "    def fuse(self, neural_output, symbolic_output):\n",
    "        \"\"\"\n",
    "        Combine neural and symbolic outputs for enhanced reasoning.\n",
    "\n",
    "        Parameters:\n",
    "            neural_output (Tensor): Output tensor from the neural network.\n",
    "            symbolic_output (Tensor): Output tensor from the symbolic reasoning.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Combined output after fusion.\n",
    "        \"\"\"\n",
    "        #concatenate neural and symbolic outputs\n",
    "        combined_output = torch.cat((neural_output, symbolic_output), dim=1)\n",
    "        \n",
    "        #pass through the fusion layer\n",
    "        fused_output = self.fusion_layer(combined_output)\n",
    "        \n",
    "        #pass through the final output layer\n",
    "        fused_output = self.output_layer(fused_output)\n",
    "        \n",
    "        return fused_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8205f6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.394550Z",
     "iopub.status.busy": "2024-08-11T12:38:34.394081Z",
     "iopub.status.idle": "2024-08-11T12:38:34.409054Z",
     "shell.execute_reply": "2024-08-11T12:38:34.407909Z"
    },
    "papermill": {
     "duration": 0.036389,
     "end_time": "2024-08-11T12:38:34.411808",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.375419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MetaLearningCapabilities:\n",
    "    \"\"\"Initialize meta-learning capabilities.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=64, output_dim=1):\n",
    "        \"\"\"\n",
    "        Initialize the meta-learning model.\n",
    "        \n",
    "        Parameters:\n",
    "            input_dim (int): Dimension of the input features.\n",
    "            hidden_dim (int): Dimension of hidden layers.\n",
    "            output_dim (int): Dimension of the output layer.\n",
    "        \"\"\"\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def meta_learn(self, X_train, y_train, X_test, y_test=None, num_epochs=10, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Learn how to learn and adapt to new tasks with minimal data.\n",
    "\n",
    "        Parameters:\n",
    "            X_train (ndarray): Training input data.\n",
    "            y_train (ndarray): Training target data.\n",
    "            X_test (ndarray): Test input data.\n",
    "            y_test (ndarray, optional): Test target data.\n",
    "            num_epochs (int): Number of training epochs.\n",
    "            learning_rate (float): Learning rate for optimization.\n",
    "\n",
    "        Returns:\n",
    "            model (nn.Module): Trained meta-learning model.\n",
    "        \"\"\"\n",
    "        #convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1) \n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        \n",
    "        if y_test is not None:\n",
    "            y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)  \n",
    "        \n",
    "        #define loss function and optimizer\n",
    "        criterion = nn.MSELoss() \n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "        #train the model\n",
    "        self.model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            #forward pass\n",
    "            outputs = self.model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            \n",
    "            #backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (epoch + 1) % 2 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        #evaluate the model\n",
    "        if y_test is not None:\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_outputs = self.model(X_test_tensor)\n",
    "                test_loss = criterion(test_outputs, y_test_tensor)\n",
    "                print(f'Test Loss: {test_loss.item():.4f}')\n",
    "        \n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ad9db86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.447773Z",
     "iopub.status.busy": "2024-08-11T12:38:34.447362Z",
     "iopub.status.idle": "2024-08-11T12:38:34.465395Z",
     "shell.execute_reply": "2024-08-11T12:38:34.463737Z"
    },
    "papermill": {
     "duration": 0.039257,
     "end_time": "2024-08-11T12:38:34.468124",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.428867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DomainAdaptation:\n",
    "    \"\"\"Domain adaptation class for transferring knowledge from source to target domain.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        #adjust the first Linear layer to match input_dim\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)  #the output layer produces a single value\n",
    "        )\n",
    "    \n",
    "    def train(self, X_train, y_train, num_epochs=10, learning_rate=0.001):\n",
    "        \"\"\"Train the model on the source domain data.\"\"\"\n",
    "        self.model.train()\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        #convert input data to tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)  #reshape to [batch_size, 1]\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (epoch + 1) % 2 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    def fine_tune(self, X_train_target, y_train_target, num_epochs=10, learning_rate=0.001):\n",
    "        \"\"\"Fine-tune the model on the target domain data.\"\"\"\n",
    "        self.model.train()\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        #convert input data to tensors\n",
    "        X_train_target_tensor = torch.tensor(X_train_target, dtype=torch.float32)\n",
    "        y_train_target_tensor = torch.tensor(y_train_target, dtype=torch.float32).view(-1, 1)  #reshape to [batch_size, 1]\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self.model(X_train_target_tensor)\n",
    "            loss = criterion(outputs, y_train_target_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (epoch + 1) % 2 == 0:\n",
    "                print(f'Fine-tuning Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    def transfer_knowledge(self, source_data, target_data):\n",
    "        \"\"\"Transfer knowledge from source to target domain.\"\"\"\n",
    "        X_train_source, y_train_source = source_data\n",
    "        X_train_target, y_train_target = target_data\n",
    "\n",
    "        #train on the source domain data\n",
    "        self.train(X_train_source, y_train_source)\n",
    "\n",
    "        #fine-tune on the target domain data if target labels are available\n",
    "        if y_train_target is not None:\n",
    "            self.fine_tune(X_train_target, y_train_target)\n",
    "\n",
    "        return self.get_model()\n",
    "\n",
    "    def get_model(self):\n",
    "        \"\"\"Return the trained model.\"\"\"\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "249717fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.504576Z",
     "iopub.status.busy": "2024-08-11T12:38:34.504131Z",
     "iopub.status.idle": "2024-08-11T12:38:34.514874Z",
     "shell.execute_reply": "2024-08-11T12:38:34.513716Z"
    },
    "papermill": {
     "duration": 0.032139,
     "end_time": "2024-08-11T12:38:34.517451",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.485312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScalableTrainingTechniques:\n",
    "    \"\"\"Scalable training techniques using distributed computing.\"\"\"\n",
    "\n",
    "    def scale_training(self, X_train, y_train, model, num_epochs=10, learning_rate=0.001):\n",
    "        \"\"\"Scale training processes using distributed computing.\"\"\"\n",
    "        \n",
    "        #convert numpy arrays to PyTorch tensors\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float32) if y_train is not None else None\n",
    "        \n",
    "        #move model to GPU if available\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        model = model.to(device)\n",
    "        X_train = X_train.to(device)\n",
    "        y_train = y_train.to(device) if y_train is not None else None\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs.squeeze(), y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (epoch + 1) % 2 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca95096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.553365Z",
     "iopub.status.busy": "2024-08-11T12:38:34.552945Z",
     "iopub.status.idle": "2024-08-11T12:38:34.563717Z",
     "shell.execute_reply": "2024-08-11T12:38:34.562588Z"
    },
    "papermill": {
     "duration": 0.032024,
     "end_time": "2024-08-11T12:38:34.566548",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.534524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResourceEfficientDesign:\n",
    "    \"\"\"Resource-efficient design and optimization techniques.\"\"\"\n",
    "\n",
    "    def optimize_resources(self, model, X_train, y_train, pruning_percentage=0.5, quantize=False):\n",
    "        \"\"\"Optimize resource usage of the model, including pruning and quantization.\"\"\"\n",
    "\n",
    "        #convert numpy arrays to PyTorch tensors if needed\n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32) if not isinstance(X_train, torch.Tensor) else X_train\n",
    "        y_train = torch.tensor(y_train, dtype=torch.float32) if not isinstance(y_train, torch.Tensor) else y_train\n",
    "\n",
    "        #apply model pruning\n",
    "        print(f\"Applying pruning with {pruning_percentage*100}% sparsity...\")\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                prune.l1_unstructured(module, name='weight', amount=pruning_percentage)\n",
    "\n",
    "        #remove the pruning reparameterization to make the model ready for quantization or deployment\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                prune.remove(module, 'weight')\n",
    "\n",
    "        #apply quantization if specified\n",
    "        if quantize:\n",
    "            print(\"Applying quantization...\")\n",
    "            model = quantization.quantize_dynamic(\n",
    "                model, {nn.Linear}, dtype=torch.qint8\n",
    "            )\n",
    "\n",
    "        print(\"Resource optimization complete.\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3406ac38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.603619Z",
     "iopub.status.busy": "2024-08-11T12:38:34.603151Z",
     "iopub.status.idle": "2024-08-11T12:38:34.616658Z",
     "shell.execute_reply": "2024-08-11T12:38:34.615535Z"
    },
    "papermill": {
     "duration": 0.035608,
     "end_time": "2024-08-11T12:38:34.619593",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.583985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoveltyAdaptation:\n",
    "    \"\"\"Initialize novelty adaptation mechanisms.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def adapt_to_novelty(self, model, new_data, num_epochs=10, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Adapt to unseen inputs and tasks using new data.\n",
    "\n",
    "        Parameters:\n",
    "        - model (nn.Module): The neural network model to adapt.\n",
    "        - new_data (tuple): A tuple (X_new, y_new) where X_new and y_new are NumPy arrays of new data.\n",
    "        - num_epochs (int): Number of epochs for fine-tuning.\n",
    "        - learning_rate (float): Learning rate for the optimizer.\n",
    "\n",
    "        Returns:\n",
    "        - adapted_model (nn.Module): The model adapted to new data.\n",
    "        \"\"\"\n",
    "\n",
    "        #unpack new data\n",
    "        X_new, y_new = new_data\n",
    "        \n",
    "        #convert new data to PyTorch tensors\n",
    "        X_new_tensor = torch.tensor(X_new, dtype=torch.float32)\n",
    "        y_new_tensor = torch.tensor(y_new, dtype=torch.float32)\n",
    "        \n",
    "        #create DataLoader for new data\n",
    "        new_dataset = TensorDataset(X_new_tensor, y_new_tensor)\n",
    "        new_loader = DataLoader(new_dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        #move model to appropriate device\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        \n",
    "        #define loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        #fine-tuning loop\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, targets in new_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                #forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                #calculate loss\n",
    "                loss = criterion(outputs.squeeze(), targets.squeeze())\n",
    "                \n",
    "                #backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                #accumulate loss\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            #calculate and print average loss for the epoch\n",
    "            epoch_loss = running_loss / len(new_dataset)\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        print(\"Adaptation to new data completed.\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34c1a4d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.656557Z",
     "iopub.status.busy": "2024-08-11T12:38:34.655590Z",
     "iopub.status.idle": "2024-08-11T12:38:34.676401Z",
     "shell.execute_reply": "2024-08-11T12:38:34.675324Z"
    },
    "papermill": {
     "duration": 0.042047,
     "end_time": "2024-08-11T12:38:34.678961",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.636914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AdversarialResilience:\n",
    "    \"\"\"Initialize adversarial resilience measures.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _generate_adversarial_examples(self, model, data_loader, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Generate adversarial examples using the Fast Gradient Sign Method (FGSM).\n",
    "\n",
    "        Parameters:\n",
    "        - model (nn.Module): The neural network model.\n",
    "        - data_loader (DataLoader): DataLoader with the data to generate adversarial examples.\n",
    "        - epsilon (float): Perturbation magnitude.\n",
    "\n",
    "        Returns:\n",
    "        - adversarial_examples (np.ndarray): Array of adversarial examples.\n",
    "        \"\"\"\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        adversarial_examples = []\n",
    "\n",
    "        for inputs, _ in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            inputs.requires_grad = True\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.MSELoss()(outputs.squeeze(), torch.zeros_like(outputs.squeeze()).to(device))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            perturbation = epsilon * inputs.grad.sign()\n",
    "            adversarial = inputs + perturbation\n",
    "            adversarial_examples.append(adversarial.cpu().detach().numpy())\n",
    "        \n",
    "        return np.concatenate(adversarial_examples)\n",
    "\n",
    "    def protect_against_adversarial_attacks(self, model, train_data, num_epochs=10, learning_rate=0.001, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Protect the model against adversarial attacks using adversarial training.\n",
    "\n",
    "        Parameters:\n",
    "        - model (nn.Module): The neural network model.\n",
    "        - train_data (tuple): A tuple (X_train, y_train) with training data.\n",
    "        - num_epochs (int): Number of epochs for adversarial training.\n",
    "        - learning_rate (float): Learning rate for the optimizer.\n",
    "        - epsilon (float): Perturbation magnitude for generating adversarial examples.\n",
    "\n",
    "        Returns:\n",
    "        - resilient_model (nn.Module): The model trained with adversarial examples.\n",
    "        \"\"\"\n",
    "        #unpack training data\n",
    "        X_train, y_train = train_data\n",
    "        \n",
    "        #convert training data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        \n",
    "        #create DataLoader for training data\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        \n",
    "        #move model to appropriate device\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        \n",
    "        #define loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        #adversarial training loop\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                #generate adversarial examples\n",
    "                adversarial_examples = self._generate_adversarial_examples(\n",
    "                    model,\n",
    "                    DataLoader(TensorDataset(inputs.clone().detach(), targets.clone().detach()), batch_size=32),\n",
    "                    epsilon\n",
    "                )\n",
    "                adversarial_examples_tensor = torch.tensor(adversarial_examples, dtype=torch.float32).to(device)\n",
    "                \n",
    "                #combine clean and adversarial examples\n",
    "                combined_inputs = torch.cat((inputs, adversarial_examples_tensor), dim=0)\n",
    "                combined_targets = torch.cat((targets, targets), dim=0)\n",
    "                \n",
    "                outputs = model(combined_inputs)\n",
    "                loss = criterion(outputs.squeeze(), combined_targets.squeeze())\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "            epoch_loss = running_loss / len(train_dataset)\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        print(\"Adversarial training completed.\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c0434f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.715547Z",
     "iopub.status.busy": "2024-08-11T12:38:34.715052Z",
     "iopub.status.idle": "2024-08-11T12:38:34.725767Z",
     "shell.execute_reply": "2024-08-11T12:38:34.724558Z"
    },
    "papermill": {
     "duration": 0.031989,
     "end_time": "2024-08-11T12:38:34.728209",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.696220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransparentDecisionMaking:\n",
    "    \"\"\"Handle transparent decision-making and explanations.\"\"\"\n",
    "    \n",
    "    def explain_decision(self, model, data, feature_names=None):\n",
    "        \"\"\"\n",
    "        Provide explanations for model decisions using SHAP.\n",
    "        \n",
    "        Args:\n",
    "        - model (nn.Module): The PyTorch model for which to explain decisions.\n",
    "        - data (tuple): A tuple containing the features and labels for which to explain decisions.\n",
    "        - feature_names (list, optional): Names of the features for better explanation readability.\n",
    "        \n",
    "        Returns:\n",
    "        - explanation (dict): A dictionary with explanation details.\n",
    "        \"\"\"\n",
    "        #unpack data\n",
    "        X, _ = data\n",
    "\n",
    "        #convert X to NumPy array if it's a tensor\n",
    "        if isinstance(X, torch.Tensor):\n",
    "            X = X.numpy()\n",
    "        \n",
    "        #define a function to get model predictions\n",
    "        def model_predict(input_data):\n",
    "            input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                output = model(input_tensor).numpy()\n",
    "            return output\n",
    "        \n",
    "        #initialize SHAP Explainer\n",
    "        explainer = shap.KernelExplainer(model_predict, X)\n",
    "        \n",
    "        #explain a few instances\n",
    "        explanations = []\n",
    "        for i in range(min(len(X), 5)):  #limit to first 5 instances for demonstration\n",
    "            shap_values = explainer.shap_values(X[i:i+1])\n",
    "            explanations.append(shap_values)\n",
    "        \n",
    "        return {\n",
    "            \"explanations\": explanations,\n",
    "            \"feature_names\": feature_names\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7df66be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.765058Z",
     "iopub.status.busy": "2024-08-11T12:38:34.764638Z",
     "iopub.status.idle": "2024-08-11T12:38:34.779692Z",
     "shell.execute_reply": "2024-08-11T12:38:34.778490Z"
    },
    "papermill": {
     "duration": 0.037088,
     "end_time": "2024-08-11T12:38:34.782333",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.745245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VisualizationTools:\n",
    "    \"\"\"Initialize visualization tools.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def visualize_learning(self, training_losses, validation_losses=None):\n",
    "        \"\"\"\n",
    "        Offer tools to visualize learning and decision-making processes.\n",
    "        \n",
    "        Parameters:\n",
    "        - training_losses (list): A list of training loss values per epoch.\n",
    "        - validation_losses (list): A list of validation loss values per epoch (optional).\n",
    "        \n",
    "        Returns:\n",
    "        - visualization (str): Description of the generated visualizations.\n",
    "        \"\"\"\n",
    "        #plot training and validation losses\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(training_losses, label='Training Loss', color='blue', marker='o')\n",
    "        if validation_losses is not None:\n",
    "            plt.plot(validation_losses, label='Validation Loss', color='orange', marker='o')\n",
    "        \n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Losses')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        return \"Visualized training and validation losses\"\n",
    "\n",
    "    def visualize_predictions(self, model, data, feature_names=None):\n",
    "        \"\"\"\n",
    "        Visualize predictions vs actual values.\n",
    "\n",
    "        Parameters:\n",
    "        - model (nn.Module): The trained neural network model.\n",
    "        - data (tuple): A tuple (X, y) with input data and actual values.\n",
    "        - feature_names (list): Optional list of feature names for the x-axis labels.\n",
    "\n",
    "        Returns:\n",
    "        - visualization (str): Description of the generated visualizations.\n",
    "        \"\"\"\n",
    "        X, y_actual = data\n",
    "        \n",
    "        #ensure data is in the right format\n",
    "        if isinstance(X, torch.Tensor):\n",
    "            X = X.numpy()\n",
    "        if isinstance(y_actual, torch.Tensor):\n",
    "            y_actual = y_actual.numpy()\n",
    "        \n",
    "        #make predictions\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "            y_pred = model(X_tensor).numpy()\n",
    "        \n",
    "        #plot predictions vs actual values\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(y_actual, label='Actual Values', color='blue', marker='o', linestyle='-')\n",
    "        plt.plot(y_pred, label='Predicted Values', color='red', marker='x', linestyle='--')\n",
    "        \n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Value')\n",
    "        plt.title('Actual vs Predicted Values')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        return \"Visualized predictions vs actual values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b35c0b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.821018Z",
     "iopub.status.busy": "2024-08-11T12:38:34.820595Z",
     "iopub.status.idle": "2024-08-11T12:38:34.831855Z",
     "shell.execute_reply": "2024-08-11T12:38:34.830713Z"
    },
    "papermill": {
     "duration": 0.03351,
     "end_time": "2024-08-11T12:38:34.834937",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.801427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfImprovementMechanisms:\n",
    "    \"\"\"Initialize self-improvement mechanisms.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def self_improve(self, model, feedback, X_train, y_train, num_epochs=10, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        Continuously improve the model based on feedback.\n",
    "        \n",
    "        Parameters:\n",
    "        - model (nn.Module): The neural network model to be improved.\n",
    "        - feedback (dict): A dictionary containing feedback metrics like 'loss'.\n",
    "        - X_train (np.array or torch.Tensor): Training features.\n",
    "        - y_train (np.array or torch.Tensor): Training labels.\n",
    "        - num_epochs (int): Number of epochs for retraining.\n",
    "        - learning_rate (float): Learning rate for optimizer.\n",
    "        \n",
    "        Returns:\n",
    "        - improved_model (nn.Module): The improved model after retraining.\n",
    "        \"\"\"\n",
    "        #convert data to tensors if they are not already\n",
    "        if not isinstance(X_train, torch.Tensor):\n",
    "            X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        if not isinstance(y_train, torch.Tensor):\n",
    "            y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "        \n",
    "        #define a loss function and optimizer\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        #training loop\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #print feedback if available\n",
    "            if 'verbose' in feedback and feedback['verbose']:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bc6a36b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.871994Z",
     "iopub.status.busy": "2024-08-11T12:38:34.871568Z",
     "iopub.status.idle": "2024-08-11T12:38:34.878488Z",
     "shell.execute_reply": "2024-08-11T12:38:34.877306Z"
    },
    "papermill": {
     "duration": 0.027994,
     "end_time": "2024-08-11T12:38:34.881063",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.853069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedbackIntegration:\n",
    "    def integrate_feedback(self, feedback, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Integrate feedback to refine the model.\n",
    "        \n",
    "        Args:\n",
    "            feedback (str): Feedback provided for model improvement.\n",
    "            X_train (torch.Tensor): Training features.\n",
    "            y_train (torch.Tensor): Training labels.\n",
    "        \n",
    "        Returns:\n",
    "            nn.Module: The refined model.\n",
    "        \"\"\"\n",
    "        print(f\"Feedback received: {feedback}\")\n",
    "        #assume y_train is 1D\n",
    "        refined_model = nn.Linear(X_train.shape[1], y_train.shape[0])\n",
    "        return refined_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e334f6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:34.918073Z",
     "iopub.status.busy": "2024-08-11T12:38:34.917627Z",
     "iopub.status.idle": "2024-08-11T12:38:34.969322Z",
     "shell.execute_reply": "2024-08-11T12:38:34.967934Z"
    },
    "papermill": {
     "duration": 0.073931,
     "end_time": "2024-08-11T12:38:34.972528",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.898597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Layer: Linear(in_features=256, out_features=128, bias=True)\n",
      "Convolutional Layer: Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "Custom Module: CustomModule(\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ModularArchitecture:\n",
    "    \"\"\"Initialize modular architecture.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def configure_module(self, module_name, **kwargs):\n",
    "        \"\"\"\n",
    "        Support interchangeable components within the architecture.\n",
    "        \n",
    "        Parameters:\n",
    "        - module_name (str): Name of the module to configure.\n",
    "        - **kwargs: Additional parameters required to configure the module.\n",
    "        \n",
    "        Returns:\n",
    "        - configured_module (nn.Module): Configured module based on the provided name.\n",
    "        \"\"\"\n",
    "        if module_name == 'linear':\n",
    "            input_dim = kwargs.get('input_dim', 128)\n",
    "            output_dim = kwargs.get('output_dim', 64)\n",
    "            configured_module = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "        elif module_name == 'conv2d':\n",
    "            in_channels = kwargs.get('in_channels', 1)\n",
    "            out_channels = kwargs.get('out_channels', 32)\n",
    "            kernel_size = kwargs.get('kernel_size', 3)\n",
    "            stride = kwargs.get('stride', 1)\n",
    "            padding = kwargs.get('padding', 1)\n",
    "            configured_module = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        \n",
    "        elif module_name == 'custom_module':\n",
    "            input_dim = kwargs.get('input_dim', 128)\n",
    "            hidden_dim = kwargs.get('hidden_dim', 64)\n",
    "            output_dim = kwargs.get('output_dim', 1)\n",
    "            #define a custom module\n",
    "            class CustomModule(nn.Module):\n",
    "                def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "                    super(CustomModule, self).__init__()\n",
    "                    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "                    self.relu = nn.ReLU()\n",
    "                    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "                \n",
    "                def forward(self, x):\n",
    "                    x = self.fc1(x)\n",
    "                    x = self.relu(x)\n",
    "                    x = self.fc2(x)\n",
    "                    return x\n",
    "            \n",
    "            configured_module = CustomModule(input_dim, hidden_dim, output_dim)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Module '{module_name}' not recognized.\")\n",
    "        \n",
    "        return configured_module\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    modular_architecture = ModularArchitecture()\n",
    "\n",
    "    #configure a linear layer\n",
    "    linear_layer = modular_architecture.configure_module('linear', input_dim=256, output_dim=128)\n",
    "    print(\"Linear Layer:\", linear_layer)\n",
    "\n",
    "    #configure a convolutional layer\n",
    "    conv_layer = modular_architecture.configure_module('conv2d', in_channels=3, out_channels=64, kernel_size=5)\n",
    "    print(\"Convolutional Layer:\", conv_layer)\n",
    "\n",
    "    #configure a custom module\n",
    "    custom_module = modular_architecture.configure_module('custom_module', input_dim=128, hidden_dim=64, output_dim=10)\n",
    "    print(\"Custom Module:\", custom_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0da47002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.009968Z",
     "iopub.status.busy": "2024-08-11T12:38:35.009538Z",
     "iopub.status.idle": "2024-08-11T12:38:35.034745Z",
     "shell.execute_reply": "2024-08-11T12:38:35.033396Z"
    },
    "papermill": {
     "duration": 0.046931,
     "end_time": "2024-08-11T12:38:35.037352",
     "exception": false,
     "start_time": "2024-08-11T12:38:34.990421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Module: Linear(in_features=256, out_features=128, bias=True)\n",
      "Convolutional Module: Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
      "Custom Neural Network Module: CustomNN(\n",
      "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "RNN Module: LSTM(10, 20, num_layers=2, batch_first=True)\n"
     ]
    }
   ],
   "source": [
    "class ConfigurableLearningModules:\n",
    "    \"\"\"Initialize configurable learning modules.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def configure_learning_module(self, module_params):\n",
    "        \"\"\"\n",
    "        Customize learning modules for specific tasks.\n",
    "        \n",
    "        Parameters:\n",
    "        - module_params (dict): Dictionary containing parameters for configuring the module.\n",
    "        \n",
    "        Returns:\n",
    "        - customized_module (nn.Module): Configured module based on the provided parameters.\n",
    "        \"\"\"\n",
    "        module_type = module_params.get('module_type', 'linear')\n",
    "        \n",
    "        if module_type == 'linear':\n",
    "            input_dim = module_params.get('input_dim', 128)\n",
    "            output_dim = module_params.get('output_dim', 64)\n",
    "            customized_module = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "        elif module_type == 'conv2d':\n",
    "            in_channels = module_params.get('in_channels', 1)\n",
    "            out_channels = module_params.get('out_channels', 32)\n",
    "            kernel_size = module_params.get('kernel_size', 3)\n",
    "            stride = module_params.get('stride', 1)\n",
    "            padding = module_params.get('padding', 1)\n",
    "            customized_module = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        \n",
    "        elif module_type == 'custom_nn':\n",
    "            input_dim = module_params.get('input_dim', 128)\n",
    "            hidden_dim = module_params.get('hidden_dim', 64)\n",
    "            output_dim = module_params.get('output_dim', 10)\n",
    "            #define a custom neural network\n",
    "            class CustomNN(nn.Module):\n",
    "                def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "                    super(CustomNN, self).__init__()\n",
    "                    self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "                    self.relu = nn.ReLU()\n",
    "                    self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "                \n",
    "                def forward(self, x):\n",
    "                    x = self.fc1(x)\n",
    "                    x = self.relu(x)\n",
    "                    x = self.fc2(x)\n",
    "                    return x\n",
    "            \n",
    "            customized_module = CustomNN(input_dim, hidden_dim, output_dim)\n",
    "        \n",
    "        elif module_type == 'rnn':\n",
    "            input_dim = module_params.get('input_dim', 10)\n",
    "            hidden_dim = module_params.get('hidden_dim', 20)\n",
    "            num_layers = module_params.get('num_layers', 1)\n",
    "            rnn_type = module_params.get('rnn_type', 'RNN')\n",
    "            \n",
    "            if rnn_type == 'RNN':\n",
    "                customized_module = nn.RNN(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "            elif rnn_type == 'LSTM':\n",
    "                customized_module = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "            elif rnn_type == 'GRU':\n",
    "                customized_module = nn.GRU(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "            else:\n",
    "                raise ValueError(f\"RNN type '{rnn_type}' not recognized.\")\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Module type '{module_type}' not recognized.\")\n",
    "        \n",
    "        return customized_module\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    configurable_modules = ConfigurableLearningModules()\n",
    "    \n",
    "    #configure a linear layer\n",
    "    linear_params = {'module_type': 'linear', 'input_dim': 256, 'output_dim': 128}\n",
    "    linear_module = configurable_modules.configure_learning_module(linear_params)\n",
    "    print(\"Linear Module:\", linear_module)\n",
    "    \n",
    "    #configure a convolutional layer\n",
    "    conv_params = {'module_type': 'conv2d', 'in_channels': 3, 'out_channels': 64, 'kernel_size': 5}\n",
    "    conv_module = configurable_modules.configure_learning_module(conv_params)\n",
    "    print(\"Convolutional Module:\", conv_module)\n",
    "    \n",
    "    #configure a custom neural network\n",
    "    custom_nn_params = {'module_type': 'custom_nn', 'input_dim': 128, 'hidden_dim': 64, 'output_dim': 10}\n",
    "    custom_nn_module = configurable_modules.configure_learning_module(custom_nn_params)\n",
    "    print(\"Custom Neural Network Module:\", custom_nn_module)\n",
    "    \n",
    "    #configure an RNN\n",
    "    rnn_params = {'module_type': 'rnn', 'input_dim': 10, 'hidden_dim': 20, 'num_layers': 2, 'rnn_type': 'LSTM'}\n",
    "    rnn_module = configurable_modules.configure_learning_module(rnn_params)\n",
    "    print(\"RNN Module:\", rnn_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "918d63a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.075384Z",
     "iopub.status.busy": "2024-08-11T12:38:35.074924Z",
     "iopub.status.idle": "2024-08-11T12:38:35.091100Z",
     "shell.execute_reply": "2024-08-11T12:38:35.089639Z"
    },
    "papermill": {
     "duration": 0.038853,
     "end_time": "2024-08-11T12:38:35.093792",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.054939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EthicalAIBehavior:\n",
    "    \"\"\"Initialize ethical AI behavior protocols.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def enforce_ethics(self, data):\n",
    "        \"\"\"Ensure adherence to ethical guidelines and fairness.\"\"\"\n",
    "        ethical_output = {\n",
    "            \"life_protection\": self.protect_life(data),\n",
    "            \"harmful_content\": not self.contains_harmful_content(data),\n",
    "            \"environmentally_friendly\": self.is_environmentally_friendly(data),\n",
    "            \"family_support\": self.promotes_family_support(data),\n",
    "            \"transparency\": self.is_transparent_and_honest(data),\n",
    "            \"fairness\": self.is_fair_and_equitable(data),\n",
    "            \"honor\": self.check_honor(data),\n",
    "            \"courage\": self.check_courage(data),\n",
    "            \"commitment\": self.check_commitment(data)\n",
    "        }\n",
    "        return ethical_output\n",
    "    \n",
    "    def protect_life(self, data):\n",
    "        \"\"\"Ensure that the AI and its data do not harm any form of life.\"\"\"\n",
    "        life_critical_terms = [\"human welfare\", \"animal welfare\", \"plant conservation\", \"water safety\", \"air quality\"]\n",
    "        for term in life_critical_terms:\n",
    "            if term in data.lower():\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def contains_harmful_content(self, data):\n",
    "        \"\"\"Check if the data contains harmful or offensive content.\"\"\"\n",
    "        harmful_keywords = [\"violence\", \"abuse\", \"offensive\", \"harassment\", \"bullying\", \"misinformation\",\"false claims\", \"explicit content\", \"cybercrime\", \"fraud\", \"threats\"]\n",
    "        for keyword in harmful_keywords:\n",
    "            if keyword in data.lower():\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_environmentally_friendly(self, data):\n",
    "        \"\"\"Check if the data or operations are environmentally friendly.\"\"\"\n",
    "        return \"eco-friendly\" in data.lower()\n",
    "    \n",
    "    def promotes_family_support(self, data):\n",
    "        \"\"\"Check if the data promotes family unity and support.\"\"\"\n",
    "        family_related_terms = [\"family\", \"support\", \"unity\"]\n",
    "        for term in family_related_terms:\n",
    "            if term in data.lower():\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_transparent_and_honest(self, data):\n",
    "        \"\"\"Check if data and AI decisions are transparent and honest.\"\"\"\n",
    "        return \"transparency\" in data.lower() and \"honesty\" in data.lower()\n",
    "    \n",
    "    def is_fair_and_equitable(self, data):\n",
    "        \"\"\"Check if the data and AI decisions are fair and equitable.\"\"\"\n",
    "        return \"fair\" in data.lower() and \"equitable\" in data.lower()\n",
    "    \n",
    "    def check_honor(self, data):\n",
    "        \"\"\"Check if the data and decisions align with the value of honor.\"\"\"\n",
    "        return \"honor\" in data.lower()\n",
    "    \n",
    "    def check_courage(self, data):\n",
    "        \"\"\"Check if the data and decisions align with the value of courage.\"\"\"\n",
    "        return \"courage\" in data.lower()\n",
    "    \n",
    "    def check_commitment(self, data):\n",
    "        \"\"\"Check if the data and decisions align with the value of commitment.\"\"\"\n",
    "        return \"commitment\" in data.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45936fcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.130994Z",
     "iopub.status.busy": "2024-08-11T12:38:35.130568Z",
     "iopub.status.idle": "2024-08-11T12:38:35.141182Z",
     "shell.execute_reply": "2024-08-11T12:38:35.139901Z"
    },
    "papermill": {
     "duration": 0.032761,
     "end_time": "2024-08-11T12:38:35.143873",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.111112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fail-safes to the system...\n",
      "Adding security features to the system...\n",
      "System after applying safety measures: {'name': 'Example System', 'fail_safes': True, 'security_features': True}\n"
     ]
    }
   ],
   "source": [
    "class SafetyProtocols:\n",
    "    \"\"\"Initialize safety protocols.\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def apply_safety_measures(self, system):\n",
    "        \"\"\"Implement fail-safes and safety measures.\"\"\"\n",
    "        \n",
    "        #implementing general safety measures\n",
    "        safe_system = self.add_fail_safes(system)\n",
    "        safe_system = self.add_security_features(safe_system)\n",
    "        \n",
    "        return safe_system\n",
    "\n",
    "    def add_fail_safes(self, system):\n",
    "        \"\"\"Add fail-safes to the system to handle unexpected failures.\"\"\"\n",
    "        #This could involve adding redundant systems, monitoring systems, or emergency shutdowns.\n",
    "        print(\"Adding fail-safes to the system...\")\n",
    "        system['fail_safes'] = True\n",
    "        return system\n",
    "\n",
    "    def add_security_features(self, system):\n",
    "        \"\"\"Add security features to the system to protect against unauthorized access.\"\"\"\n",
    "        #This could involve adding authentication, encryption, and other security measures.\n",
    "        print(\"Adding security features to the system...\")\n",
    "        system['security_features'] = True\n",
    "        return system\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    system = {\n",
    "        'name': 'Example System',\n",
    "        'fail_safes': False,\n",
    "        'security_features': False\n",
    "    }\n",
    "    \n",
    "    #initialize SafetyProtocols\n",
    "    safety_protocols = SafetyProtocols()\n",
    "    \n",
    "    #apply safety measures\n",
    "    safe_system = safety_protocols.apply_safety_measures(system)\n",
    "    \n",
    "    print(\"System after applying safety measures:\", safe_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "167bcc08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.181319Z",
     "iopub.status.busy": "2024-08-11T12:38:35.180895Z",
     "iopub.status.idle": "2024-08-11T12:38:35.192578Z",
     "shell.execute_reply": "2024-08-11T12:38:35.191391Z"
    },
    "papermill": {
     "duration": 0.035169,
     "end_time": "2024-08-11T12:38:35.196762",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.161593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customized accessible interface: {'high_contrast_mode': True, 'text_size': 'large', 'screen_reader_support': True, 'keyboard_navigation': True}\n"
     ]
    }
   ],
   "source": [
    "class UserAccessibility:\n",
    "    \"\"\"Initialize user accessibility features.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.default_interface = {\n",
    "            'high_contrast_mode': False,\n",
    "            'text_size': 'medium',\n",
    "            'screen_reader_support': False,\n",
    "            'keyboard_navigation': False\n",
    "        }\n",
    "\n",
    "    def adapt_interface(self, user_needs):\n",
    "        \"\"\"Customize the user interface for accessibility.\"\"\"\n",
    "        #create a copy of the default interface to modify\n",
    "        accessible_interface = self.default_interface.copy()\n",
    "        \n",
    "        #apply user needs to the interface\n",
    "        if 'high_contrast_mode' in user_needs:\n",
    "            accessible_interface['high_contrast_mode'] = user_needs['high_contrast_mode']\n",
    "        \n",
    "        if 'text_size' in user_needs:\n",
    "            accessible_interface['text_size'] = user_needs['text_size']\n",
    "        \n",
    "        if 'screen_reader_support' in user_needs:\n",
    "            accessible_interface['screen_reader_support'] = user_needs['screen_reader_support']\n",
    "        \n",
    "        if 'keyboard_navigation' in user_needs:\n",
    "            accessible_interface['keyboard_navigation'] = user_needs['keyboard_navigation']\n",
    "        \n",
    "        return accessible_interface\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #example user needs for accessibility\n",
    "    user_needs = {\n",
    "        'high_contrast_mode': True,\n",
    "        'text_size': 'large',\n",
    "        'screen_reader_support': True,\n",
    "        'keyboard_navigation': True\n",
    "    }\n",
    "    \n",
    "    #initialize UserAccessibility\n",
    "    accessibility = UserAccessibility()\n",
    "    \n",
    "    #adapt the interface based on user needs\n",
    "    accessible_interface = accessibility.adapt_interface(user_needs)\n",
    "    \n",
    "    print(\"Customized accessible interface:\", accessible_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a64da09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.234933Z",
     "iopub.status.busy": "2024-08-11T12:38:35.234538Z",
     "iopub.status.idle": "2024-08-11T12:38:35.245579Z",
     "shell.execute_reply": "2024-08-11T12:38:35.244162Z"
    },
    "papermill": {
     "duration": 0.032688,
     "end_time": "2024-08-11T12:38:35.248050",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.215362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated assistive technologies: {'screen_reader': True, 'speech_recognition': True, 'text_to_speech': False, 'alternative_input_devices': True}\n"
     ]
    }
   ],
   "source": [
    "class AssistiveTechnologyIntegration:\n",
    "    \"\"\"Initialize assistive technology integration.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.supported_technologies = {\n",
    "            'screen_reader': False,\n",
    "            'speech_recognition': False,\n",
    "            'text_to_speech': False,\n",
    "            'alternative_input_devices': False\n",
    "        }\n",
    "    \n",
    "    def integrate_assistive_tech(self, tech):\n",
    "        \"\"\"Support integration with assistive technologies.\"\"\"\n",
    "        #create a copy of the default supported technologies\n",
    "        integrated_technology = self.supported_technologies.copy()\n",
    "        \n",
    "        #integrate the requested assistive technology\n",
    "        for tech_name in tech:\n",
    "            if tech_name in integrated_technology:\n",
    "                integrated_technology[tech_name] = tech[tech_name]\n",
    "            else:\n",
    "                print(f\"Warning: Technology '{tech_name}' is not supported.\")\n",
    "        \n",
    "        return integrated_technology\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #example assistive technology integration request\n",
    "    tech_request = {\n",
    "        'screen_reader': True,\n",
    "        'speech_recognition': True,\n",
    "        'text_to_speech': False,\n",
    "        'alternative_input_devices': True\n",
    "    }\n",
    "    \n",
    "    #initialize AssistiveTechnologyIntegration\n",
    "    assistive_tech = AssistiveTechnologyIntegration()\n",
    "    \n",
    "    #integrate assistive technologies based on the request\n",
    "    integrated_technology = assistive_tech.integrate_assistive_tech(tech_request)\n",
    "    \n",
    "    print(\"Integrated assistive technologies:\", integrated_technology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6aacb3ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.284976Z",
     "iopub.status.busy": "2024-08-11T12:38:35.284588Z",
     "iopub.status.idle": "2024-08-11T12:38:35.297088Z",
     "shell.execute_reply": "2024-08-11T12:38:35.295531Z"
    },
    "papermill": {
     "duration": 0.034081,
     "end_time": "2024-08-11T12:38:35.299587",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.265506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detected: Value is missing\n",
      "Applying correction: Unknown error\n",
      "Error detected: Format is invalid\n",
      "Applying correction: Unknown error\n",
      "Corrected output: {'error_1': 'Unknown error', 'error_2': 'Unknown error', 'info_1': 'Operation successful'}\n"
     ]
    }
   ],
   "source": [
    "class AutomatedErrorDetection:\n",
    "    \"\"\"Initialize automated error detection.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.error_patterns = {\n",
    "            'missing_value': 'Value is missing',\n",
    "            'invalid_format': 'Format is invalid',\n",
    "            'out_of_bounds': 'Value is out of bounds'\n",
    "        }\n",
    "        self.error_corrections = {\n",
    "            'missing_value': 'Provide a default value',\n",
    "            'invalid_format': 'Format the value correctly',\n",
    "            'out_of_bounds': 'Adjust value to within acceptable range'\n",
    "        }\n",
    "    \n",
    "    def detect_errors(self, system_output):\n",
    "        \"\"\"Automatically detect and address errors and bugs.\"\"\"\n",
    "        corrected_output = system_output.copy()  #start with the original output\n",
    "        \n",
    "        #example detection and correction logic\n",
    "        for key, value in system_output.items():\n",
    "            if isinstance(value, str):\n",
    "                if value in self.error_patterns.values():\n",
    "                    print(f\"Error detected: {value}\")\n",
    "                    #apply a predefined correction\n",
    "                    correction = self.error_corrections.get(value, 'Unknown error')\n",
    "                    print(f\"Applying correction: {correction}\")\n",
    "                    corrected_output[key] = correction  #correct the error\n",
    "\n",
    "        return corrected_output\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #example system output with errors\n",
    "    system_output = {\n",
    "        'error_1': 'Value is missing',\n",
    "        'error_2': 'Format is invalid',\n",
    "        'info_1': 'Operation successful'\n",
    "    }\n",
    "    \n",
    "    #initialize AutomatedErrorDetection\n",
    "    error_detection = AutomatedErrorDetection()\n",
    "    \n",
    "    #detect and correct errors in the system output\n",
    "    corrected_output = error_detection.detect_errors(system_output)\n",
    "    \n",
    "    print(\"Corrected output:\", corrected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d2d2650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.337249Z",
     "iopub.status.busy": "2024-08-11T12:38:35.336294Z",
     "iopub.status.idle": "2024-08-11T12:38:35.347671Z",
     "shell.execute_reply": "2024-08-11T12:38:35.346298Z"
    },
    "papermill": {
     "duration": 0.032885,
     "end_time": "2024-08-11T12:38:35.350172",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.317287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healed system: {'original_issue': 'memory_leak', 'healing_action': 'Free up unused memory', 'status': 'Healed'}\n"
     ]
    }
   ],
   "source": [
    "class SelfHealingCapabilities:\n",
    "    \"\"\"Initialize self-healing capabilities.\"\"\"\n",
    "    def __init__(self):\n",
    "        #define common issues and their corresponding healing actions\n",
    "        self.healing_actions = {\n",
    "            'memory_leak': 'Free up unused memory',\n",
    "            'high_cpu_usage': 'Optimize resource-intensive processes',\n",
    "            'disk_full': 'Clean up disk space or expand disk capacity',\n",
    "            'network_issue': 'Restart network services or check connectivity'\n",
    "        }\n",
    "    \n",
    "    def heal_system(self, issue):\n",
    "        \"\"\"Self-heal system malfunctions or anomalies.\"\"\"\n",
    "        #initialize the healed system as a copy of the issue dictionary\n",
    "        healed_system = {'original_issue': issue}\n",
    "        \n",
    "        #check if the issue is in the predefined healing actions\n",
    "        if issue in self.healing_actions:\n",
    "            healing_action = self.healing_actions[issue]\n",
    "            healed_system['healing_action'] = healing_action\n",
    "            healed_system['status'] = 'Healed'\n",
    "        else:\n",
    "            healed_system['healing_action'] = 'No predefined action for this issue'\n",
    "            healed_system['status'] = 'Unresolved'\n",
    "        \n",
    "        return healed_system\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #example issue\n",
    "    issue = 'memory_leak'\n",
    "    \n",
    "    #initialize SelfHealingCapabilities\n",
    "    self_healing = SelfHealingCapabilities()\n",
    "    \n",
    "    #heal the system based on the detected issue\n",
    "    healed_system = self_healing.heal_system(issue)\n",
    "    \n",
    "    print(\"Healed system:\", healed_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51b5d0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.388382Z",
     "iopub.status.busy": "2024-08-11T12:38:35.387942Z",
     "iopub.status.idle": "2024-08-11T12:38:35.401322Z",
     "shell.execute_reply": "2024-08-11T12:38:35.400227Z"
    },
    "papermill": {
     "duration": 0.035902,
     "end_time": "2024-08-11T12:38:35.403898",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.367996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam detected with pattern: free money\n",
      "Virus detected with signature: virus_signature_1\n",
      "Clean data: Congratulations! You have won [REMOVED]! Virus_signature_1 found in your system.\n"
     ]
    }
   ],
   "source": [
    "class SpamAndVirusDetection:\n",
    "    \"\"\"Initialize spam and virus detection.\"\"\"\n",
    "    def __init__(self):\n",
    "        #define patterns for spam and viruses (for illustration purposes)\n",
    "        self.spam_patterns = [\n",
    "            r'free money',\n",
    "            r'click here',\n",
    "            r'win big',\n",
    "            r'special promotion'\n",
    "        ]\n",
    "        self.virus_signatures = [\n",
    "            r'virus_signature_1',\n",
    "            r'virus_signature_2'\n",
    "        ]\n",
    "    \n",
    "    def detect_and_prevent(self, data):\n",
    "        \"\"\"Monitor for and prevent spam, viruses, and malicious activities.\"\"\"\n",
    "        clean_data = data  #work with the original string directly\n",
    "\n",
    "        #detect and handle spam\n",
    "        for pattern in self.spam_patterns:\n",
    "            if re.search(pattern, data, re.IGNORECASE):\n",
    "                print(f\"Spam detected with pattern: {pattern}\")\n",
    "                clean_data = self.remove_spam(clean_data)\n",
    "                break  #stop further checks once spam is detected\n",
    "        \n",
    "        #detect and handle viruses\n",
    "        for signature in self.virus_signatures:\n",
    "            if re.search(signature, data, re.IGNORECASE):\n",
    "                print(f\"Virus detected with signature: {signature}\")\n",
    "                clean_data = self.remove_virus(clean_data)\n",
    "                break  #stop further checks once a virus is detected\n",
    "        \n",
    "        return clean_data\n",
    "\n",
    "    def remove_spam(self, data):\n",
    "        \"\"\"Remove detected spam from the data.\"\"\"\n",
    "        #This should be replaced with actual logic for cleaning spam.\n",
    "        return re.sub('|'.join(self.spam_patterns), '[REMOVED]', data)\n",
    "    \n",
    "    def remove_virus(self, data):\n",
    "        \"\"\"Remove detected viruses from the data.\"\"\"\n",
    "        #This should be replaced with actual logic for cleaning viruses.\n",
    "        return re.sub('|'.join(self.virus_signatures), '[CLEAN]', data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #example data\n",
    "    data = \"Congratulations! You have won free money! Virus_signature_1 found in your system.\"\n",
    "    \n",
    "    #initialize SpamAndVirusDetection\n",
    "    detector = SpamAndVirusDetection()\n",
    "    \n",
    "    #detect and prevent spam and viruses\n",
    "    clean_data = detector.detect_and_prevent(data)\n",
    "    \n",
    "    print(\"Clean data:\", clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e94abfdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.441073Z",
     "iopub.status.busy": "2024-08-11T12:38:35.440696Z",
     "iopub.status.idle": "2024-08-11T12:38:35.452673Z",
     "shell.execute_reply": "2024-08-11T12:38:35.451485Z"
    },
    "papermill": {
     "duration": 0.033647,
     "end_time": "2024-08-11T12:38:35.455199",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.421552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threat detected with pattern: unusual_login\n",
      "Applying preventive measure: alert_admins\n",
      "Applying preventive measure: update_security_policies\n",
      "Applying preventive measure: block_suspicious_ip\n",
      "Applying preventive measure: require_strong_authentication\n",
      "System secured based on threat assessment.\n"
     ]
    }
   ],
   "source": [
    "class ProactiveSecurity:\n",
    "    \"\"\"Initialize proactive security measures.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        #define common threat patterns and preventive measures\n",
    "        self.threat_patterns = [\n",
    "            r'suspicious_activity', \n",
    "            r'unusual_login',\n",
    "            r'unknown_ip',\n",
    "            r'insecure_protocol'\n",
    "        ]\n",
    "        #define preventive measures\n",
    "        self.preventive_measures = [\n",
    "            'alert_admins',\n",
    "            'update_security_policies',\n",
    "            'block_suspicious_ip',\n",
    "            'require_strong_authentication'\n",
    "        ]\n",
    "    \n",
    "    def anticipate_and_prevent(self, threats):\n",
    "        \"\"\"Anticipate potential security threats and take preventive measures.\"\"\"\n",
    "        #check for each threat pattern in the input\n",
    "        for pattern in self.threat_patterns:\n",
    "            if re.search(pattern, threats, re.IGNORECASE):\n",
    "                print(f\"Threat detected with pattern: {pattern}\")\n",
    "                #apply corresponding preventive measures\n",
    "                self.apply_preventive_measures()\n",
    "                break  #stop further checks once a threat is detected\n",
    "\n",
    "        return \"System secured based on threat assessment.\"\n",
    "\n",
    "    def apply_preventive_measures(self):\n",
    "        \"\"\"Apply preventive measures to enhance security.\"\"\"\n",
    "        for measure in self.preventive_measures:\n",
    "            print(f\"Applying preventive measure: {measure}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #example threats input\n",
    "    threats = \"Detected unusual_login from unknown_ip using insecure_protocol.\"\n",
    "\n",
    "    #initialize ProactiveSecurity\n",
    "    security = ProactiveSecurity()\n",
    "    \n",
    "    #anticipate and prevent security threats\n",
    "    result = security.anticipate_and_prevent(threats)\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afadd127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.495705Z",
     "iopub.status.busy": "2024-08-11T12:38:35.494507Z",
     "iopub.status.idle": "2024-08-11T12:38:35.508558Z",
     "shell.execute_reply": "2024-08-11T12:38:35.507226Z"
    },
    "papermill": {
     "duration": 0.036831,
     "end_time": "2024-08-11T12:38:35.511289",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.474458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Management Report\n",
      "==============================\n",
      "Risk Factor: Data Breach\n",
      "  Likelihood: High\n",
      "  Impact: Medium\n",
      "  Mitigation Strategy: Implement encryption and access controls.\n",
      "------------------------------\n",
      "Risk Factor: System Downtime\n",
      "  Likelihood: Low\n",
      "  Impact: Medium\n",
      "  Mitigation Strategy: Ensure redundancy and failover mechanisms.\n",
      "------------------------------\n",
      "Risk Factor: Unauthorized Access\n",
      "  Likelihood: Medium\n",
      "  Impact: Low\n",
      "  Mitigation Strategy: Use multi-factor authentication and strict access controls.\n",
      "------------------------------\n",
      "Risk Factor: Performance Degradation\n",
      "  Likelihood: Low\n",
      "  Impact: High\n",
      "  Mitigation Strategy: Optimize system performance and monitor resource usage.\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class RiskAssessment:\n",
    "    \"\"\"Initialize risk assessment protocols.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        #initialize risk factors and mitigation strategies\n",
    "        self.risk_factors = [\n",
    "            'Data Breach',\n",
    "            'System Downtime',\n",
    "            'Unauthorized Access',\n",
    "            'Performance Degradation'\n",
    "        ]\n",
    "        \n",
    "        #risk mitigation strategies\n",
    "        self.mitigation_strategies = {\n",
    "            'Data Breach': 'Implement encryption and access controls.',\n",
    "            'System Downtime': 'Ensure redundancy and failover mechanisms.',\n",
    "            'Unauthorized Access': 'Use multi-factor authentication and strict access controls.',\n",
    "            'Performance Degradation': 'Optimize system performance and monitor resource usage.'\n",
    "        }\n",
    "    \n",
    "    def assess_risks(self, system):\n",
    "        \"\"\"Assess and manage risks associated with system operations.\"\"\"\n",
    "        risk_report = {}\n",
    "        \n",
    "        #simulate risk assessment for the given system\n",
    "        for risk in self.risk_factors:\n",
    "            risk_report[risk] = {\n",
    "                'Likelihood': random.choice(['Low', 'Medium', 'High']),\n",
    "                'Impact': random.choice(['Low', 'Medium', 'High']),\n",
    "                'Mitigation Strategy': self.mitigation_strategies[risk]\n",
    "            }\n",
    "        \n",
    "        #generate risk management report\n",
    "        risk_management_report = self.generate_risk_management_report(risk_report)\n",
    "        return risk_management_report\n",
    "    \n",
    "    def generate_risk_management_report(self, risk_report):\n",
    "        \"\"\"Generate a detailed risk management report.\"\"\"\n",
    "        report = \"Risk Management Report\\n\"\n",
    "        report += \"=\" * 30 + \"\\n\"\n",
    "        \n",
    "        for risk, details in risk_report.items():\n",
    "            report += f\"Risk Factor: {risk}\\n\"\n",
    "            report += f\"  Likelihood: {details['Likelihood']}\\n\"\n",
    "            report += f\"  Impact: {details['Impact']}\\n\"\n",
    "            report += f\"  Mitigation Strategy: {details['Mitigation Strategy']}\\n\"\n",
    "            report += \"-\" * 30 + \"\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #initialize RiskAssessment\n",
    "    risk_assessment = RiskAssessment()\n",
    "    \n",
    "    #example system input\n",
    "    system = \"ExampleSystem\"\n",
    "    \n",
    "    #assess risks associated with the system\n",
    "    risk_report = risk_assessment.assess_risks(system)\n",
    "    \n",
    "    print(risk_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1f82658",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:35.549235Z",
     "iopub.status.busy": "2024-08-11T12:38:35.548814Z",
     "iopub.status.idle": "2024-08-11T12:38:36.910793Z",
     "shell.execute_reply": "2024-08-11T12:38:36.909319Z"
    },
    "papermill": {
     "duration": 1.384256,
     "end_time": "2024-08-11T12:38:36.913570",
     "exception": false,
     "start_time": "2024-08-11T12:38:35.529314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.0085\n",
      "Epoch [2/10], Loss: 1.9996\n",
      "Epoch [3/10], Loss: 1.9942\n",
      "Epoch [4/10], Loss: 1.9885\n",
      "Epoch [5/10], Loss: 1.9827\n",
      "Epoch [6/10], Loss: 1.9764\n",
      "Epoch [7/10], Loss: 1.9691\n",
      "Epoch [8/10], Loss: 1.9605\n",
      "Epoch [9/10], Loss: 1.9500\n",
      "Epoch [10/10], Loss: 1.9371\n",
      "Training complete.\n",
      "Number of entries in the submission: 100\n",
      "Submission file saved to /kaggle/working/submission.json\n"
     ]
    }
   ],
   "source": [
    "#define the Yambi (which means \"Welcome\" in kikongo) model\n",
    "class Yambi:\n",
    "    \"\"\"Initialize and combine functionalities of various classes.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim):\n",
    "        # Initialize all additional functionalities\n",
    "        self.domain_adaptation = DomainAdaptation(input_dim)\n",
    "        self.scalable_training = ScalableTrainingTechniques()\n",
    "        self.resource_design = ResourceEfficientDesign()\n",
    "        self.novelty_adaptation = NoveltyAdaptation()\n",
    "        self.adversarial_resilience = AdversarialResilience()\n",
    "        self.transparent_decision_making = TransparentDecisionMaking()\n",
    "        self.visualization_tools = VisualizationTools()\n",
    "        self.self_improvement = SelfImprovementMechanisms()\n",
    "        self.feedback_integration = FeedbackIntegration()\n",
    "        self.modular_architecture = ModularArchitecture()\n",
    "        self.configurable_learning_modules = ConfigurableLearningModules()\n",
    "        self.ethical_ai_behavior = EthicalAIBehavior()\n",
    "        self.safety_protocols = SafetyProtocols()\n",
    "        self.user_accessibility = UserAccessibility()\n",
    "        self.assistive_technology_integration = AssistiveTechnologyIntegration()\n",
    "        self.automated_error_detection = AutomatedErrorDetection()\n",
    "        self.self_healing_capabilities = SelfHealingCapabilities()\n",
    "        self.spam_and_virus_detection = SpamAndVirusDetection()\n",
    "        self.proactive_security = ProactiveSecurity()\n",
    "        self.risk_assessment = RiskAssessment()\n",
    "        \n",
    "        #define the model with appropriate layers\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, input_dim) \n",
    "        )\n",
    "    \n",
    "    def train_model(self, X_train, y_train, num_epochs=10, learning_rate=1):\n",
    "        \"\"\"Train the model.\"\"\"\n",
    "        criterion = nn.MSELoss()  #Mean Squared Error Loss\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        #convert training data to tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()  #set model to training mode\n",
    "            y_pred = self.model(X_train_tensor)  #forward pass\n",
    "            loss = criterion(y_pred, y_train_tensor)  #compute loss\n",
    "            \n",
    "            optimizer.zero_grad()  #zero the gradients\n",
    "            loss.backward()       #backward pass\n",
    "            optimizer.step()      # update weights\n",
    "            \n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Generate predictions.\"\"\"\n",
    "        self.model.eval()  #set model to evaluation mode\n",
    "        with torch.no_grad():  #disable gradient computation\n",
    "            X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "            predictions = self.model(X_test_tensor).numpy()\n",
    "        return predictions\n",
    "\n",
    "#function to preprocess test data\n",
    "def preprocess_test_data(X_test, input_size):\n",
    "    num_samples = X_test.shape[0]\n",
    "    flattened_X_test = X_test.reshape(num_samples, -1)\n",
    "    if flattened_X_test.shape[1] != input_size:\n",
    "        #if reshaped data doesn't match, adjust to match the input size\n",
    "        if flattened_X_test.shape[1] > input_size:\n",
    "            #trim if larger\n",
    "            flattened_X_test = flattened_X_test[:, :input_size]\n",
    "        else:\n",
    "            #pad if smaller\n",
    "            padded_X_test = np.zeros((num_samples, input_size), dtype=flattened_X_test.dtype)\n",
    "            padded_X_test[:, :flattened_X_test.shape[1]] = flattened_X_test\n",
    "            flattened_X_test = padded_X_test\n",
    "    return flattened_X_test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dim = X_train.shape[1]\n",
    "\n",
    "    #initialize Yambi model\n",
    "    yambi_model = Yambi(input_dim)\n",
    "\n",
    "    #train the model\n",
    "    yambi_model.train_model(X_train, y_train)\n",
    "\n",
    "    #preprocess test data to match the model's input dimensions\n",
    "    X_test_flattened = preprocess_test_data(X_test, input_dim)\n",
    "\n",
    "    #make predictions using the model\n",
    "    predictions = yambi_model.predict(X_test_flattened)\n",
    "\n",
    "    #reshape predictions to match the output format\n",
    "    predictions_reshaped = [pred.reshape(24, 24).tolist() for pred in predictions]\n",
    "    \n",
    "    test_keys = list(test_challenges.keys())\n",
    "\n",
    "    #check if the number of predictions matches the number of test keys\n",
    "    if len(test_keys) != len(predictions_reshaped):\n",
    "        raise ValueError(f\"Number of test keys ({len(test_keys)}) does not match number of predictions ({len(predictions_reshaped)}).\")\n",
    "\n",
    "    #generate submission format\n",
    "    submission = {}\n",
    "    for key, pred in zip(test_keys, predictions_reshaped):\n",
    "        submission[key] = [{\"attempt_1\": pred, \"attempt_2\": pred}]\n",
    "\n",
    "    #check the number of entries in the submission\n",
    "    print(f\"Number of entries in the submission: {len(submission)}\")\n",
    "\n",
    "    #save the submission file\n",
    "    submission_path = '/kaggle/working/submission.json'\n",
    "    with open(submission_path, 'w') as f:\n",
    "        json.dump(submission, f, indent=4)\n",
    "\n",
    "    print(f\"Submission file saved to {submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d821f58d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:36.952246Z",
     "iopub.status.busy": "2024-08-11T12:38:36.951649Z",
     "iopub.status.idle": "2024-08-11T12:38:36.962834Z",
     "shell.execute_reply": "2024-08-11T12:38:36.961490Z"
    },
    "papermill": {
     "duration": 0.033194,
     "end_time": "2024-08-11T12:38:36.965297",
     "exception": false,
     "start_time": "2024-08-11T12:38:36.932103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /kaggle/working/yambi_model.pth\n"
     ]
    }
   ],
   "source": [
    "#define the path where the model will be saved\n",
    "model_save_path = '/kaggle/working/yambi_model.pth'\n",
    "\n",
    "#save the model\n",
    "torch.save(yambi_model.model.state_dict(), model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6d03eaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:37.005242Z",
     "iopub.status.busy": "2024-08-11T12:38:37.004405Z",
     "iopub.status.idle": "2024-08-11T12:38:37.012065Z",
     "shell.execute_reply": "2024-08-11T12:38:37.010608Z"
    },
    "papermill": {
     "duration": 0.030796,
     "end_time": "2024-08-11T12:38:37.014654",
     "exception": false,
     "start_time": "2024-08-11T12:38:36.983858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test keys: 100\n",
      "Number of predictions: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of test keys: {len(test_keys)}\")\n",
    "print(f\"Number of predictions: {len(predictions_reshaped)}\")\n",
    "\n",
    "if len(test_keys) != len(predictions_reshaped):\n",
    "    print(\"Mismatch between test keys and predictions length.\")\n",
    "    print(f\"Test keys: {test_keys}\")\n",
    "    print(f\"Predictions reshaped: {predictions_reshaped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df0a2b4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-11T12:38:37.116131Z",
     "iopub.status.busy": "2024-08-11T12:38:37.115698Z",
     "iopub.status.idle": "2024-08-11T12:38:37.127452Z",
     "shell.execute_reply": "2024-08-11T12:38:37.126334Z"
    },
    "papermill": {
     "duration": 0.034623,
     "end_time": "2024-08-11T12:38:37.130235",
     "exception": false,
     "start_time": "2024-08-11T12:38:37.095612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission format is valid: True\n"
     ]
    }
   ],
   "source": [
    "def validate_submission_format(submission, sample_format):\n",
    "    \"\"\"\n",
    "    Validate if the submission file format matches the sample format.\n",
    "    \n",
    "    Parameters:\n",
    "    - submission: dict, the loaded submission data\n",
    "    - sample_format: dict, the sample format to compare against\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if the format matches, False otherwise\n",
    "    \"\"\"\n",
    "    for key, sample_data in sample_format.items():\n",
    "        if key not in submission:\n",
    "            print(f\"Key {key} missing in submission.\")\n",
    "            return False\n",
    "        \n",
    "        sub_entry = submission[key]\n",
    "        if not isinstance(sub_entry, list):\n",
    "            print(f\"Entry for key {key} is not a list.\")\n",
    "            return False\n",
    "        \n",
    "        for entry in sub_entry:\n",
    "            if not isinstance(entry, dict):\n",
    "                print(f\"Entry for key {key} is not a dictionary.\")\n",
    "                return False\n",
    "            \n",
    "            for attempt_key in ['attempt_1', 'attempt_2']:\n",
    "                if attempt_key not in entry:\n",
    "                    print(f\"Missing {attempt_key} in entry for key {key}.\")\n",
    "                    return False\n",
    "                \n",
    "                if not isinstance(entry[attempt_key], list):\n",
    "                    print(f\"{attempt_key} is not a list in entry for key {key}.\")\n",
    "                    return False\n",
    "\n",
    "    return True\n",
    "\n",
    "#validate the submission file\n",
    "is_valid_format = validate_submission_format(submission, sample_submission)\n",
    "print(f\"Submission format is valid: {is_valid_format}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8951125,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20.179429,
   "end_time": "2024-08-11T12:38:39.474198",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-11T12:38:19.294769",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
